{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "np.random.seed(0)\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "sys.path.append(r'C:\\lior\\studies\\master\\projects\\calibration\\regression calibration\\regression_calibration')\n",
    "os.chdir(r'C:\\lior\\studies\\master\\projects\\calibration\\regression calibration\\regression_calibration')\n",
    "from src.data.data_generator_oct import OCTDataset\n",
    "from models import BreastPathQModel\n",
    "from uce import uceloss\n",
    "from src.features.calibration_plots import plot_uncert, plot_frequency, plot_uncert_multi\n",
    "from utils import nll_criterion_gaussian, avg_len\n",
    "\n",
    "matplotlib.rcParams['font.size'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'efficientnetb4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert base_model in ['resnet101', 'densenet201', 'efficientnetb4']\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([850])\n",
      "torch.Size([850])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "resize_to = (256, 256)\n",
    "\n",
    "data_dir = 'C:/lior/studies/master/projects/calibration/regression calibration/3doct-pose-dataset/data/'\n",
    "data_set = OCTDataset(data_dir=data_dir, augment=False, resize_to=resize_to)\n",
    "assert len(data_set) > 0\n",
    "\n",
    "calib_indices = torch.load('./data_indices/oct_valid_indices.pth')\n",
    "test_indices = torch.load('./data_indices/oct_test_indices.pth')\n",
    "\n",
    "print(calib_indices.shape)\n",
    "print(test_indices.shape)\n",
    "\n",
    "calib_loader = torch.utils.data.DataLoader(data_set, batch_size=batch_size,\n",
    "                                           sampler=SubsetRandomSampler(calib_indices))\n",
    "test_loader = torch.utils.data.DataLoader(data_set, batch_size=batch_size,\n",
    "                                          sampler=SubsetRandomSampler(test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous weights at epoch 499 from\n",
      "C:\\lior\\studies\\master\\projects\\calibration/regression calibration/regression_calibration\\models\\snapshots\\efficientnetb4_gaussian_oct_499.pth.tar\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "model = BreastPathQModel(base_model, out_channels=6).to(device)\n",
    "\n",
    "# checkpoint_path = glob(f\"C:\\lior\\studies\\master\\projects\\calibration/regression calibration/regression_calibration\\models\\snapshots\\{base_model}_gaussian_oct_best_freeze_lr_0.0003_nll.pth.tar\")[0]\n",
    "checkpoint_path = glob(f\"C:\\lior\\studies\\master\\projects\\calibration/regression calibration/regression_calibration\\models\\snapshots\\{base_model}_gaussian_oct_499.pth.tar\")[0]\n",
    "# checkpoint_path = glob(f\"C:\\lior\\studies\\master\\projects\\calibration/regression calibration/regression_calibration\\models\\snapshots\\{base_model}_gaussian_oct_315.pth.tar\")[0]\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"Loading previous weights at epoch \" + str(checkpoint['epoch']) + \" from\\n\" + checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [01:43<00:00,  1.91s/it]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_p_calib = []\n",
    "vars_calib = []\n",
    "logvars_calib = []\n",
    "targets_calib = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(calib_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        y_p, logvar, var_bayesian = model(data, dropout=True, mc_dropout=True, test=True)\n",
    "\n",
    "        y_p_calib.append(y_p.detach())\n",
    "        vars_calib.append(var_bayesian.detach())\n",
    "        logvars_calib.append(logvar.detach())\n",
    "        targets_calib.append(target.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([850, 25, 6])\n"
     ]
    }
   ],
   "source": [
    "y_p_calib = torch.cat(y_p_calib, dim=1).clamp(0, 1).permute(1,0,2)\n",
    "print(y_p_calib.shape)\n",
    "mu_calib = y_p_calib.mean(dim=1)\n",
    "var_calib = torch.cat(vars_calib, dim=0)\n",
    "logvars_calib = torch.cat(logvars_calib, dim=1).permute(1,0,2)\n",
    "logvar_calib = logvars_calib.mean(dim=1)\n",
    "target_calib = torch.cat(targets_calib, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "save_path = 'C:/lior/studies/master/projects/calibration/regression calibration/well-calibrated-regression-uncertainty/var_and_mse_calib/'\n",
    "with open(save_path + f'{base_model}_gaussian_oct_best_freeze_lr_0.0003_nll_mu_target_calib.pickle', 'wb') as handle:\n",
    "    pickle.dump({'mu_calib': mu_calib, \n",
    "                 'target_calib': target_calib}\n",
    "                , handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "save_path = 'C:/lior/studies/master/projects/calibration/regression calibration/well-calibrated-regression-uncertainty/var_and_mse_calib/'\n",
    "with open(save_path + f'{base_model}_gaussian_oct_best_freeze_lr_0.0003_nll_mu_target_calib.pickle', 'rb') as handle:\n",
    "    mu_dict = pickle.load(handle)\n",
    "    mu_calib = mu_dict['mu_calib']\n",
    "    target_calib = mu_dict['target_calib']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_calib = (target_calib-mu_calib).pow(2).mean(dim=1, keepdim=True).sqrt()\n",
    "errvar_calib = (y_p_calib-target_calib.unsqueeze(1).repeat(1,25,1)).pow(2).mean(dim=(1,2)).unsqueeze(-1)\n",
    "\n",
    "uncertainty = 'aleatoric'\n",
    "\n",
    "uncert_calib_aleatoric = logvar_calib.exp().mean(dim=1, keepdim=True)\n",
    "uncert_calib_epistemic = var_calib.mean(dim=1, keepdim=True)\n",
    "\n",
    "if uncertainty == 'aleatoric':\n",
    "    uncert_calib = uncert_calib_aleatoric.sqrt().clamp(0, 1)\n",
    "    uncert_calib_laves = (uncert_calib_aleatoric + uncert_calib_epistemic).sqrt().clamp(0, 1)  # total\n",
    "elif uncertainty == 'epistemic':\n",
    "    uncert_calib = uncert_calib_epistemic.sqrt().clamp(0, 1)\n",
    "else:\n",
    "    uncert_calib = (uncert_calib_aleatoric + uncert_calib_epistemic).sqrt().clamp(0, 1)  # total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0015, device='cuda:1')\n",
      "tensor(0.0016, device='cuda:1')\n",
      "tensor(0.0002, device='cuda:1')\n",
      "tensor(0.0144, device='cuda:1')\n",
      "tensor(0.0135, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "print((err_calib**2).mean())\n",
    "print(errvar_calib.mean())\n",
    "print((uncert_calib**2).mean())\n",
    "print(uncert_calib_aleatoric.sqrt().mean())\n",
    "print(uncert_calib_epistemic.sqrt().mean())\n",
    "\n",
    "#err_calib = errvar_calib.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "/* Put everything inside the global mpl namespace */\nwindow.mpl = {};\n\n\nmpl.get_websocket_type = function() {\n    if (typeof(WebSocket) !== 'undefined') {\n        return WebSocket;\n    } else if (typeof(MozWebSocket) !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert('Your browser does not have WebSocket support. ' +\n              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n              'Firefox 4 and 5 are also supported but you ' +\n              'have to enable WebSockets in about:config.');\n    };\n}\n\nmpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = (this.ws.binaryType != undefined);\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById(\"mpl-warnings\");\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent = (\n                \"This browser does not support binary websocket messages. \" +\n                    \"Performance may be slow.\");\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = $('<div/>');\n    this._root_extra_style(this.root)\n    this.root.attr('style', 'display: inline-block');\n\n    $(parent_element).append(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen =  function () {\n            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n            fig.send_message(\"send_image_mode\", {});\n            if (mpl.ratio != 1) {\n                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n            }\n            fig.send_message(\"refresh\", {});\n        }\n\n    this.imageObj.onload = function() {\n            if (fig.image_mode == 'full') {\n                // Full images could contain transparency (where diff images\n                // almost always do), so we need to clear the canvas so that\n                // there is no ghosting.\n                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n            }\n            fig.context.drawImage(fig.imageObj, 0, 0);\n        };\n\n    this.imageObj.onunload = function() {\n        fig.ws.close();\n    }\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n}\n\nmpl.figure.prototype._init_header = function() {\n    var titlebar = $(\n        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n        'ui-helper-clearfix\"/>');\n    var titletext = $(\n        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n        'text-align: center; padding: 3px;\"/>');\n    titlebar.append(titletext)\n    this.root.append(titlebar);\n    this.header = titletext[0];\n}\n\n\n\nmpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n\n}\n\n\nmpl.figure.prototype._root_extra_style = function(canvas_div) {\n\n}\n\nmpl.figure.prototype._init_canvas = function() {\n    var fig = this;\n\n    var canvas_div = $('<div/>');\n\n    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n\n    function canvas_keyboard_event(event) {\n        return fig.key_event(event, event['data']);\n    }\n\n    canvas_div.keydown('key_press', canvas_keyboard_event);\n    canvas_div.keyup('key_release', canvas_keyboard_event);\n    this.canvas_div = canvas_div\n    this._canvas_extra_style(canvas_div)\n    this.root.append(canvas_div);\n\n    var canvas = $('<canvas/>');\n    canvas.addClass('mpl-canvas');\n    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n\n    this.canvas = canvas[0];\n    this.context = canvas[0].getContext(\"2d\");\n\n    var backingStore = this.context.backingStorePixelRatio ||\n\tthis.context.webkitBackingStorePixelRatio ||\n\tthis.context.mozBackingStorePixelRatio ||\n\tthis.context.msBackingStorePixelRatio ||\n\tthis.context.oBackingStorePixelRatio ||\n\tthis.context.backingStorePixelRatio || 1;\n\n    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband = $('<canvas/>');\n    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n\n    var pass_mouse_events = true;\n\n    canvas_div.resizable({\n        start: function(event, ui) {\n            pass_mouse_events = false;\n        },\n        resize: function(event, ui) {\n            fig.request_resize(ui.size.width, ui.size.height);\n        },\n        stop: function(event, ui) {\n            pass_mouse_events = true;\n            fig.request_resize(ui.size.width, ui.size.height);\n        },\n    });\n\n    function mouse_event_fn(event) {\n        if (pass_mouse_events)\n            return fig.mouse_event(event, event['data']);\n    }\n\n    rubberband.mousedown('button_press', mouse_event_fn);\n    rubberband.mouseup('button_release', mouse_event_fn);\n    // Throttle sequential mouse events to 1 every 20ms.\n    rubberband.mousemove('motion_notify', mouse_event_fn);\n\n    rubberband.mouseenter('figure_enter', mouse_event_fn);\n    rubberband.mouseleave('figure_leave', mouse_event_fn);\n\n    canvas_div.on(\"wheel\", function (event) {\n        event = event.originalEvent;\n        event['data'] = 'scroll'\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        mouse_event_fn(event);\n    });\n\n    canvas_div.append(canvas);\n    canvas_div.append(rubberband);\n\n    this.rubberband = rubberband;\n    this.rubberband_canvas = rubberband[0];\n    this.rubberband_context = rubberband[0].getContext(\"2d\");\n    this.rubberband_context.strokeStyle = \"#000000\";\n\n    this._resize_canvas = function(width, height) {\n        // Keep the size of the canvas, canvas container, and rubber band\n        // canvas in synch.\n        canvas_div.css('width', width)\n        canvas_div.css('height', height)\n\n        canvas.attr('width', width * mpl.ratio);\n        canvas.attr('height', height * mpl.ratio);\n        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n\n        rubberband.attr('width', width);\n        rubberband.attr('height', height);\n    }\n\n    // Set the figure to an initial 600x600px, this will subsequently be updated\n    // upon first draw.\n    this._resize_canvas(600, 600);\n\n    // Disable right mouse context menu.\n    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n        return false;\n    });\n\n    function set_focus () {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n}\n\nmpl.figure.prototype._init_toolbar = function() {\n    var fig = this;\n\n    var nav_element = $('<div/>');\n    nav_element.attr('style', 'width: 100%');\n    this.root.append(nav_element);\n\n    // Define a callback function for later on.\n    function toolbar_event(event) {\n        return fig.toolbar_button_onclick(event['data']);\n    }\n    function toolbar_mouse_event(event) {\n        return fig.toolbar_button_onmouseover(event['data']);\n    }\n\n    for(var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            // put a spacer in here.\n            continue;\n        }\n        var button = $('<button/>');\n        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n                        'ui-button-icon-only');\n        button.attr('role', 'button');\n        button.attr('aria-disabled', 'false');\n        button.click(method_name, toolbar_event);\n        button.mouseover(tooltip, toolbar_mouse_event);\n\n        var icon_img = $('<span/>');\n        icon_img.addClass('ui-button-icon-primary ui-icon');\n        icon_img.addClass(image);\n        icon_img.addClass('ui-corner-all');\n\n        var tooltip_span = $('<span/>');\n        tooltip_span.addClass('ui-button-text');\n        tooltip_span.html(tooltip);\n\n        button.append(icon_img);\n        button.append(tooltip_span);\n\n        nav_element.append(button);\n    }\n\n    var fmt_picker_span = $('<span/>');\n\n    var fmt_picker = $('<select/>');\n    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n    fmt_picker_span.append(fmt_picker);\n    nav_element.append(fmt_picker_span);\n    this.format_dropdown = fmt_picker[0];\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = $(\n            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n        fmt_picker.append(option);\n    }\n\n    // Add hover states to the ui-buttons\n    $( \".ui-button\" ).hover(\n        function() { $(this).addClass(\"ui-state-hover\");},\n        function() { $(this).removeClass(\"ui-state-hover\");}\n    );\n\n    var status_bar = $('<span class=\"mpl-message\"/>');\n    nav_element.append(status_bar);\n    this.message = status_bar[0];\n}\n\nmpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n}\n\nmpl.figure.prototype.send_message = function(type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n}\n\nmpl.figure.prototype.send_draw_message = function() {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n    }\n}\n\n\nmpl.figure.prototype.handle_save = function(fig, msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n}\n\n\nmpl.figure.prototype.handle_resize = function(fig, msg) {\n    var size = msg['size'];\n    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1]);\n        fig.send_message(\"refresh\", {});\n    };\n}\n\nmpl.figure.prototype.handle_rubberband = function(fig, msg) {\n    var x0 = msg['x0'] / mpl.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n    var x1 = msg['x1'] / mpl.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0, 0, fig.canvas.width, fig.canvas.height);\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n}\n\nmpl.figure.prototype.handle_figure_label = function(fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n}\n\nmpl.figure.prototype.handle_cursor = function(fig, msg) {\n    var cursor = msg['cursor'];\n    switch(cursor)\n    {\n    case 0:\n        cursor = 'pointer';\n        break;\n    case 1:\n        cursor = 'default';\n        break;\n    case 2:\n        cursor = 'crosshair';\n        break;\n    case 3:\n        cursor = 'move';\n        break;\n    }\n    fig.rubberband_canvas.style.cursor = cursor;\n}\n\nmpl.figure.prototype.handle_message = function(fig, msg) {\n    fig.message.textContent = msg['message'];\n}\n\nmpl.figure.prototype.handle_draw = function(fig, msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n}\n\nmpl.figure.prototype.handle_image_mode = function(fig, msg) {\n    fig.image_mode = msg['mode'];\n}\n\nmpl.figure.prototype.updated_canvas_event = function() {\n    // Called whenever the canvas gets updated.\n    this.send_message(\"ack\", {});\n}\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function(fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            /* FIXME: We get \"Resource interpreted as Image but\n             * transferred with MIME type text/plain:\" errors on\n             * Chrome.  But how to set the MIME type?  It doesn't seem\n             * to be part of the websocket stream */\n            evt.data.type = \"image/png\";\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src);\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                evt.data);\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig[\"handle_\" + msg_type];\n        } catch (e) {\n            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n            }\n        }\n    };\n}\n\n// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\nmpl.findpos = function(e) {\n    //this section is from http://www.quirksmode.org/js/events_properties.html\n    var targ;\n    if (!e)\n        e = window.event;\n    if (e.target)\n        targ = e.target;\n    else if (e.srcElement)\n        targ = e.srcElement;\n    if (targ.nodeType == 3) // defeat Safari bug\n        targ = targ.parentNode;\n\n    // jQuery normalizes the pageX and pageY\n    // pageX,Y are the mouse positions relative to the document\n    // offset() returns the position of the element relative to the document\n    var x = e.pageX - $(targ).offset().left;\n    var y = e.pageY - $(targ).offset().top;\n\n    return {\"x\": x, \"y\": y};\n};\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * http://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys (original) {\n  return Object.keys(original).reduce(function (obj, key) {\n    if (typeof original[key] !== 'object')\n        obj[key] = original[key]\n    return obj;\n  }, {});\n}\n\nmpl.figure.prototype.mouse_event = function(event, name) {\n    var canvas_pos = mpl.findpos(event)\n\n    if (name === 'button_press')\n    {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    var x = canvas_pos.x * mpl.ratio;\n    var y = canvas_pos.y * mpl.ratio;\n\n    this.send_message(name, {x: x, y: y, button: event.button,\n                             step: event.step,\n                             guiEvent: simpleKeys(event)});\n\n    /* This prevents the web browser from automatically changing to\n     * the text insertion cursor when the button is pressed.  We want\n     * to control all of the cursor setting manually through the\n     * 'cursor' event from matplotlib */\n    event.preventDefault();\n    return false;\n}\n\nmpl.figure.prototype._key_event_extra = function(event, name) {\n    // Handle any extra behaviour associated with a key event\n}\n\nmpl.figure.prototype.key_event = function(event, name) {\n\n    // Prevent repeat events\n    if (name == 'key_press')\n    {\n        if (event.which === this._key)\n            return;\n        else\n            this._key = event.which;\n    }\n    if (name == 'key_release')\n        this._key = null;\n\n    var value = '';\n    if (event.ctrlKey && event.which != 17)\n        value += \"ctrl+\";\n    if (event.altKey && event.which != 18)\n        value += \"alt+\";\n    if (event.shiftKey && event.which != 16)\n        value += \"shift+\";\n\n    value += 'k';\n    value += event.which.toString();\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, {key: value,\n                             guiEvent: simpleKeys(event)});\n    return false;\n}\n\nmpl.figure.prototype.toolbar_button_onclick = function(name) {\n    if (name == 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message(\"toolbar_button\", {name: name});\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n    this.message.textContent = tooltip;\n};\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n\nmpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.close = function() {\n        comm.close()\n    };\n    ws.send = function(m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function(msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(msg['content']['data'])\n    });\n    return ws;\n}\n\nmpl.mpl_figure_comm = function(comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = $(\"#\" + id);\n    var ws_proxy = comm_websocket_adapter(comm)\n\n    function ondownload(figure, format) {\n        window.open(figure.imageObj.src);\n    }\n\n    var fig = new mpl.figure(id, ws_proxy,\n                           ondownload,\n                           element.get(0));\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element.get(0);\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error(\"Failed to find cell for figure\", id, fig);\n        return;\n    }\n\n    var output_index = fig.cell_info[2]\n    var cell = fig.cell_info[0];\n\n};\n\nmpl.figure.prototype.handle_close = function(fig, msg) {\n    var width = fig.canvas.width/mpl.ratio\n    fig.root.unbind('remove')\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable()\n    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n    fig.close_ws(fig, msg);\n}\n\nmpl.figure.prototype.close_ws = function(fig, msg){\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n}\n\nmpl.figure.prototype.push_to_output = function(remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width/mpl.ratio\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n}\n\nmpl.figure.prototype.updated_canvas_event = function() {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message(\"ack\", {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () { fig.push_to_output() }, 1000);\n}\n\nmpl.figure.prototype._init_toolbar = function() {\n    var fig = this;\n\n    var nav_element = $('<div/>');\n    nav_element.attr('style', 'width: 100%');\n    this.root.append(nav_element);\n\n    // Define a callback function for later on.\n    function toolbar_event(event) {\n        return fig.toolbar_button_onclick(event['data']);\n    }\n    function toolbar_mouse_event(event) {\n        return fig.toolbar_button_onmouseover(event['data']);\n    }\n\n    for(var toolbar_ind in mpl.toolbar_items){\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) { continue; };\n\n        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n        button.click(method_name, toolbar_event);\n        button.mouseover(tooltip, toolbar_mouse_event);\n        nav_element.append(button);\n    }\n\n    // Add the status bar.\n    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n    nav_element.append(status_bar);\n    this.message = status_bar[0];\n\n    // Add the close button to the window.\n    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n    button.click(function (evt) { fig.handle_close(fig, {}); } );\n    button.mouseover('Stop Interaction', toolbar_mouse_event);\n    buttongrp.append(button);\n    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n    titlebar.prepend(buttongrp);\n}\n\nmpl.figure.prototype._root_extra_style = function(el){\n    var fig = this\n    el.on(\"remove\", function(){\n\tfig.close_ws(fig, {});\n    });\n}\n\nmpl.figure.prototype._canvas_extra_style = function(el){\n    // this is important to make the div 'focusable\n    el.attr('tabindex', 0)\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    }\n    else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n\n}\n\nmpl.figure.prototype._key_event_extra = function(event, name) {\n    var manager = IPython.notebook.keyboard_manager;\n    if (!manager)\n        manager = IPython.keyboard_manager;\n\n    // Check for shift+enter\n    if (event.shiftKey && event.which == 13) {\n        this.canvas_div.blur();\n        event.shiftKey = false;\n        // Send a \"J\" for go to next cell\n        event.which = 74;\n        event.keyCode = 74;\n        manager.command_mode();\n        manager.handle_keydown(event);\n    }\n}\n\nmpl.figure.prototype.handle_save = function(fig, msg) {\n    fig.ondownload(fig, null);\n}\n\n\nmpl.find_output_cell = function(html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i=0; i<ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code'){\n            for (var j=0; j<cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] == html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n}\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel != null) {\n    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='e016e3fb-511f-42bf-bb3f-9af2235e4bee'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(uncert_calib.cpu(), err_calib.cpu()[:,0], '.')\n",
    "\n",
    "max_val = max(err_calib.max().item(), uncert_calib.max().item())\n",
    "ax.plot([0, max_val], [0, max_val], '--')\n",
    "ax.set_xlabel('uncert')\n",
    "ax.set_ylabel('err')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7532, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# calculate optimal T\n",
    "S = (err_calib**2 / uncert_calib**2).mean().sqrt()\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler(torch.nn.Module):\n",
    "    def __init__(self, init_S=1.0):\n",
    "        super().__init__()\n",
    "        self.S = torch.nn.Parameter(torch.tensor([init_S]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.S.mul(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8700129985809326\n"
     ]
    }
   ],
   "source": [
    "# find optimal S\n",
    "scaler = Scaler(init_S=S).to(device)\n",
    "s_opt = torch.optim.LBFGS([scaler.S], lr=3e-2, max_iter=200)\n",
    "\n",
    "def closure():\n",
    "    s_opt.zero_grad()\n",
    "\n",
    "    loss = nll_criterion_gaussian(mu_calib, scaler(uncert_calib).pow(2).log(), target_calib)\n",
    "\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "s_opt.step(closure)\n",
    "print(scaler.S.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6561, device='cuda:0')\n",
      "0.6560922861099243\n"
     ]
    }
   ],
   "source": [
    "# calculate optimal S Laves\n",
    "S = (err_calib**2 / uncert_calib_laves**2).mean().sqrt()\n",
    "print(S)\n",
    "\n",
    "# find optimal S Laves\n",
    "scaler_laves = Scaler(init_S=S).to(device)\n",
    "s_opt = torch.optim.LBFGS([scaler_laves.S], lr=3e-2, max_iter=200)\n",
    "\n",
    "def closure():\n",
    "    s_opt.zero_grad()\n",
    "\n",
    "    loss = nll_criterion_gaussian(mu_calib, scaler_laves(uncert_calib_laves).pow(2).log(), target_calib)\n",
    "\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "s_opt.step(closure)\n",
    "print(scaler_laves.S.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxModel(torch.nn.Module):\n",
    "    def __init__(self, channels, hidden=16):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(channels, hidden, bias=True)\n",
    "        self.fc = torch.nn.Linear(hidden, channels, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = 2*(x.log())\n",
    "        y = self.linear1(x).relu()\n",
    "        y = self.fc(y)\n",
    "        \n",
    "        if self.training:\n",
    "            return y\n",
    "        else:\n",
    "            return (0.5*y).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.485635280609131\n"
     ]
    }
   ],
   "source": [
    "# find optimal aux\n",
    "aux = AuxModel(1).to(device)\n",
    "aux_opt = torch.optim.Adam(aux.parameters(), lr=3e-3, weight_decay=0)\n",
    "lr_scheduler_net = optim.lr_scheduler.ReduceLROnPlateau(aux_opt, patience=100, factor=0.1)\n",
    "\n",
    "aux.train()\n",
    "for i in range(2000):\n",
    "    aux_opt.zero_grad()\n",
    "    loss = nll_criterion_gaussian(mu_calib, aux(uncert_calib), target_calib)\n",
    "    loss.backward()\n",
    "    aux_opt.step()\n",
    "    lr_scheduler_net.step(loss.item())\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.368274211883545\n",
      "-5.313454627990723\n",
      "-5.482476711273193\n",
      "-5.485640525817871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AuxModel(\n",
       "  (linear1): Linear(in_features=1, out_features=16, bias=True)\n",
       "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux.train()\n",
    "print(nll_criterion_gaussian(mu_calib, uncert_calib.pow(2).log(), target_calib).item())\n",
    "print(nll_criterion_gaussian(mu_calib, (S*uncert_calib).pow(2).log(), target_calib).item())\n",
    "print(nll_criterion_gaussian(mu_calib, scaler(uncert_calib).pow(2).log(), target_calib).item())\n",
    "print(nll_criterion_gaussian(mu_calib, aux(uncert_calib), target_calib).item())\n",
    "aux.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002708153333514929\n",
      "0.0013702618889510632\n",
      "0.0013702618889510632\n",
      "0.0013682662975043058\n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.functional.mse_loss(uncert_calib**2, err_calib**2, reduction='sum').item())\n",
    "print(torch.nn.functional.mse_loss((S*uncert_calib)**2, err_calib**2, reduction='sum').item())\n",
    "print(torch.nn.functional.mse_loss(scaler(uncert_calib)**2, err_calib**2, reduction='sum').item())\n",
    "print(torch.nn.functional.mse_loss(aux(uncert_calib)**2, err_calib**2, reduction='sum').item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "/* Put everything inside the global mpl namespace */\nwindow.mpl = {};\n\n\nmpl.get_websocket_type = function() {\n    if (typeof(WebSocket) !== 'undefined') {\n        return WebSocket;\n    } else if (typeof(MozWebSocket) !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert('Your browser does not have WebSocket support. ' +\n              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n              'Firefox 4 and 5 are also supported but you ' +\n              'have to enable WebSockets in about:config.');\n    };\n}\n\nmpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = (this.ws.binaryType != undefined);\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById(\"mpl-warnings\");\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent = (\n                \"This browser does not support binary websocket messages. \" +\n                    \"Performance may be slow.\");\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = $('<div/>');\n    this._root_extra_style(this.root)\n    this.root.attr('style', 'display: inline-block');\n\n    $(parent_element).append(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen =  function () {\n            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n            fig.send_message(\"send_image_mode\", {});\n            if (mpl.ratio != 1) {\n                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n            }\n            fig.send_message(\"refresh\", {});\n        }\n\n    this.imageObj.onload = function() {\n            if (fig.image_mode == 'full') {\n                // Full images could contain transparency (where diff images\n                // almost always do), so we need to clear the canvas so that\n                // there is no ghosting.\n                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n            }\n            fig.context.drawImage(fig.imageObj, 0, 0);\n        };\n\n    this.imageObj.onunload = function() {\n        fig.ws.close();\n    }\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n}\n\nmpl.figure.prototype._init_header = function() {\n    var titlebar = $(\n        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n        'ui-helper-clearfix\"/>');\n    var titletext = $(\n        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n        'text-align: center; padding: 3px;\"/>');\n    titlebar.append(titletext)\n    this.root.append(titlebar);\n    this.header = titletext[0];\n}\n\n\n\nmpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n\n}\n\n\nmpl.figure.prototype._root_extra_style = function(canvas_div) {\n\n}\n\nmpl.figure.prototype._init_canvas = function() {\n    var fig = this;\n\n    var canvas_div = $('<div/>');\n\n    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n\n    function canvas_keyboard_event(event) {\n        return fig.key_event(event, event['data']);\n    }\n\n    canvas_div.keydown('key_press', canvas_keyboard_event);\n    canvas_div.keyup('key_release', canvas_keyboard_event);\n    this.canvas_div = canvas_div\n    this._canvas_extra_style(canvas_div)\n    this.root.append(canvas_div);\n\n    var canvas = $('<canvas/>');\n    canvas.addClass('mpl-canvas');\n    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n\n    this.canvas = canvas[0];\n    this.context = canvas[0].getContext(\"2d\");\n\n    var backingStore = this.context.backingStorePixelRatio ||\n\tthis.context.webkitBackingStorePixelRatio ||\n\tthis.context.mozBackingStorePixelRatio ||\n\tthis.context.msBackingStorePixelRatio ||\n\tthis.context.oBackingStorePixelRatio ||\n\tthis.context.backingStorePixelRatio || 1;\n\n    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband = $('<canvas/>');\n    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n\n    var pass_mouse_events = true;\n\n    canvas_div.resizable({\n        start: function(event, ui) {\n            pass_mouse_events = false;\n        },\n        resize: function(event, ui) {\n            fig.request_resize(ui.size.width, ui.size.height);\n        },\n        stop: function(event, ui) {\n            pass_mouse_events = true;\n            fig.request_resize(ui.size.width, ui.size.height);\n        },\n    });\n\n    function mouse_event_fn(event) {\n        if (pass_mouse_events)\n            return fig.mouse_event(event, event['data']);\n    }\n\n    rubberband.mousedown('button_press', mouse_event_fn);\n    rubberband.mouseup('button_release', mouse_event_fn);\n    // Throttle sequential mouse events to 1 every 20ms.\n    rubberband.mousemove('motion_notify', mouse_event_fn);\n\n    rubberband.mouseenter('figure_enter', mouse_event_fn);\n    rubberband.mouseleave('figure_leave', mouse_event_fn);\n\n    canvas_div.on(\"wheel\", function (event) {\n        event = event.originalEvent;\n        event['data'] = 'scroll'\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        mouse_event_fn(event);\n    });\n\n    canvas_div.append(canvas);\n    canvas_div.append(rubberband);\n\n    this.rubberband = rubberband;\n    this.rubberband_canvas = rubberband[0];\n    this.rubberband_context = rubberband[0].getContext(\"2d\");\n    this.rubberband_context.strokeStyle = \"#000000\";\n\n    this._resize_canvas = function(width, height) {\n        // Keep the size of the canvas, canvas container, and rubber band\n        // canvas in synch.\n        canvas_div.css('width', width)\n        canvas_div.css('height', height)\n\n        canvas.attr('width', width * mpl.ratio);\n        canvas.attr('height', height * mpl.ratio);\n        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n\n        rubberband.attr('width', width);\n        rubberband.attr('height', height);\n    }\n\n    // Set the figure to an initial 600x600px, this will subsequently be updated\n    // upon first draw.\n    this._resize_canvas(600, 600);\n\n    // Disable right mouse context menu.\n    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n        return false;\n    });\n\n    function set_focus () {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n}\n\nmpl.figure.prototype._init_toolbar = function() {\n    var fig = this;\n\n    var nav_element = $('<div/>');\n    nav_element.attr('style', 'width: 100%');\n    this.root.append(nav_element);\n\n    // Define a callback function for later on.\n    function toolbar_event(event) {\n        return fig.toolbar_button_onclick(event['data']);\n    }\n    function toolbar_mouse_event(event) {\n        return fig.toolbar_button_onmouseover(event['data']);\n    }\n\n    for(var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            // put a spacer in here.\n            continue;\n        }\n        var button = $('<button/>');\n        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n                        'ui-button-icon-only');\n        button.attr('role', 'button');\n        button.attr('aria-disabled', 'false');\n        button.click(method_name, toolbar_event);\n        button.mouseover(tooltip, toolbar_mouse_event);\n\n        var icon_img = $('<span/>');\n        icon_img.addClass('ui-button-icon-primary ui-icon');\n        icon_img.addClass(image);\n        icon_img.addClass('ui-corner-all');\n\n        var tooltip_span = $('<span/>');\n        tooltip_span.addClass('ui-button-text');\n        tooltip_span.html(tooltip);\n\n        button.append(icon_img);\n        button.append(tooltip_span);\n\n        nav_element.append(button);\n    }\n\n    var fmt_picker_span = $('<span/>');\n\n    var fmt_picker = $('<select/>');\n    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n    fmt_picker_span.append(fmt_picker);\n    nav_element.append(fmt_picker_span);\n    this.format_dropdown = fmt_picker[0];\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = $(\n            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n        fmt_picker.append(option);\n    }\n\n    // Add hover states to the ui-buttons\n    $( \".ui-button\" ).hover(\n        function() { $(this).addClass(\"ui-state-hover\");},\n        function() { $(this).removeClass(\"ui-state-hover\");}\n    );\n\n    var status_bar = $('<span class=\"mpl-message\"/>');\n    nav_element.append(status_bar);\n    this.message = status_bar[0];\n}\n\nmpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n}\n\nmpl.figure.prototype.send_message = function(type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n}\n\nmpl.figure.prototype.send_draw_message = function() {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n    }\n}\n\n\nmpl.figure.prototype.handle_save = function(fig, msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n}\n\n\nmpl.figure.prototype.handle_resize = function(fig, msg) {\n    var size = msg['size'];\n    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1]);\n        fig.send_message(\"refresh\", {});\n    };\n}\n\nmpl.figure.prototype.handle_rubberband = function(fig, msg) {\n    var x0 = msg['x0'] / mpl.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n    var x1 = msg['x1'] / mpl.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0, 0, fig.canvas.width, fig.canvas.height);\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n}\n\nmpl.figure.prototype.handle_figure_label = function(fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n}\n\nmpl.figure.prototype.handle_cursor = function(fig, msg) {\n    var cursor = msg['cursor'];\n    switch(cursor)\n    {\n    case 0:\n        cursor = 'pointer';\n        break;\n    case 1:\n        cursor = 'default';\n        break;\n    case 2:\n        cursor = 'crosshair';\n        break;\n    case 3:\n        cursor = 'move';\n        break;\n    }\n    fig.rubberband_canvas.style.cursor = cursor;\n}\n\nmpl.figure.prototype.handle_message = function(fig, msg) {\n    fig.message.textContent = msg['message'];\n}\n\nmpl.figure.prototype.handle_draw = function(fig, msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n}\n\nmpl.figure.prototype.handle_image_mode = function(fig, msg) {\n    fig.image_mode = msg['mode'];\n}\n\nmpl.figure.prototype.updated_canvas_event = function() {\n    // Called whenever the canvas gets updated.\n    this.send_message(\"ack\", {});\n}\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function(fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            /* FIXME: We get \"Resource interpreted as Image but\n             * transferred with MIME type text/plain:\" errors on\n             * Chrome.  But how to set the MIME type?  It doesn't seem\n             * to be part of the websocket stream */\n            evt.data.type = \"image/png\";\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src);\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                evt.data);\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig[\"handle_\" + msg_type];\n        } catch (e) {\n            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n            }\n        }\n    };\n}\n\n// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\nmpl.findpos = function(e) {\n    //this section is from http://www.quirksmode.org/js/events_properties.html\n    var targ;\n    if (!e)\n        e = window.event;\n    if (e.target)\n        targ = e.target;\n    else if (e.srcElement)\n        targ = e.srcElement;\n    if (targ.nodeType == 3) // defeat Safari bug\n        targ = targ.parentNode;\n\n    // jQuery normalizes the pageX and pageY\n    // pageX,Y are the mouse positions relative to the document\n    // offset() returns the position of the element relative to the document\n    var x = e.pageX - $(targ).offset().left;\n    var y = e.pageY - $(targ).offset().top;\n\n    return {\"x\": x, \"y\": y};\n};\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * http://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys (original) {\n  return Object.keys(original).reduce(function (obj, key) {\n    if (typeof original[key] !== 'object')\n        obj[key] = original[key]\n    return obj;\n  }, {});\n}\n\nmpl.figure.prototype.mouse_event = function(event, name) {\n    var canvas_pos = mpl.findpos(event)\n\n    if (name === 'button_press')\n    {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    var x = canvas_pos.x * mpl.ratio;\n    var y = canvas_pos.y * mpl.ratio;\n\n    this.send_message(name, {x: x, y: y, button: event.button,\n                             step: event.step,\n                             guiEvent: simpleKeys(event)});\n\n    /* This prevents the web browser from automatically changing to\n     * the text insertion cursor when the button is pressed.  We want\n     * to control all of the cursor setting manually through the\n     * 'cursor' event from matplotlib */\n    event.preventDefault();\n    return false;\n}\n\nmpl.figure.prototype._key_event_extra = function(event, name) {\n    // Handle any extra behaviour associated with a key event\n}\n\nmpl.figure.prototype.key_event = function(event, name) {\n\n    // Prevent repeat events\n    if (name == 'key_press')\n    {\n        if (event.which === this._key)\n            return;\n        else\n            this._key = event.which;\n    }\n    if (name == 'key_release')\n        this._key = null;\n\n    var value = '';\n    if (event.ctrlKey && event.which != 17)\n        value += \"ctrl+\";\n    if (event.altKey && event.which != 18)\n        value += \"alt+\";\n    if (event.shiftKey && event.which != 16)\n        value += \"shift+\";\n\n    value += 'k';\n    value += event.which.toString();\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, {key: value,\n                             guiEvent: simpleKeys(event)});\n    return false;\n}\n\nmpl.figure.prototype.toolbar_button_onclick = function(name) {\n    if (name == 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message(\"toolbar_button\", {name: name});\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n    this.message.textContent = tooltip;\n};\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n\nmpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.close = function() {\n        comm.close()\n    };\n    ws.send = function(m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function(msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(msg['content']['data'])\n    });\n    return ws;\n}\n\nmpl.mpl_figure_comm = function(comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = $(\"#\" + id);\n    var ws_proxy = comm_websocket_adapter(comm)\n\n    function ondownload(figure, format) {\n        window.open(figure.imageObj.src);\n    }\n\n    var fig = new mpl.figure(id, ws_proxy,\n                           ondownload,\n                           element.get(0));\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element.get(0);\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error(\"Failed to find cell for figure\", id, fig);\n        return;\n    }\n\n    var output_index = fig.cell_info[2]\n    var cell = fig.cell_info[0];\n\n};\n\nmpl.figure.prototype.handle_close = function(fig, msg) {\n    var width = fig.canvas.width/mpl.ratio\n    fig.root.unbind('remove')\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable()\n    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n    fig.close_ws(fig, msg);\n}\n\nmpl.figure.prototype.close_ws = function(fig, msg){\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n}\n\nmpl.figure.prototype.push_to_output = function(remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width/mpl.ratio\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n}\n\nmpl.figure.prototype.updated_canvas_event = function() {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message(\"ack\", {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () { fig.push_to_output() }, 1000);\n}\n\nmpl.figure.prototype._init_toolbar = function() {\n    var fig = this;\n\n    var nav_element = $('<div/>');\n    nav_element.attr('style', 'width: 100%');\n    this.root.append(nav_element);\n\n    // Define a callback function for later on.\n    function toolbar_event(event) {\n        return fig.toolbar_button_onclick(event['data']);\n    }\n    function toolbar_mouse_event(event) {\n        return fig.toolbar_button_onmouseover(event['data']);\n    }\n\n    for(var toolbar_ind in mpl.toolbar_items){\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) { continue; };\n\n        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n        button.click(method_name, toolbar_event);\n        button.mouseover(tooltip, toolbar_mouse_event);\n        nav_element.append(button);\n    }\n\n    // Add the status bar.\n    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n    nav_element.append(status_bar);\n    this.message = status_bar[0];\n\n    // Add the close button to the window.\n    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n    button.click(function (evt) { fig.handle_close(fig, {}); } );\n    button.mouseover('Stop Interaction', toolbar_mouse_event);\n    buttongrp.append(button);\n    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n    titlebar.prepend(buttongrp);\n}\n\nmpl.figure.prototype._root_extra_style = function(el){\n    var fig = this\n    el.on(\"remove\", function(){\n\tfig.close_ws(fig, {});\n    });\n}\n\nmpl.figure.prototype._canvas_extra_style = function(el){\n    // this is important to make the div 'focusable\n    el.attr('tabindex', 0)\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    }\n    else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n\n}\n\nmpl.figure.prototype._key_event_extra = function(event, name) {\n    var manager = IPython.notebook.keyboard_manager;\n    if (!manager)\n        manager = IPython.keyboard_manager;\n\n    // Check for shift+enter\n    if (event.shiftKey && event.which == 13) {\n        this.canvas_div.blur();\n        event.shiftKey = false;\n        // Send a \"J\" for go to next cell\n        event.which = 74;\n        event.keyCode = 74;\n        manager.command_mode();\n        manager.handle_keydown(event);\n    }\n}\n\nmpl.figure.prototype.handle_save = function(fig, msg) {\n    fig.ondownload(fig, null);\n}\n\n\nmpl.find_output_cell = function(html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i=0; i<ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code'){\n            for (var j=0; j<cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] == html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n}\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel != null) {\n    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='8466562b-7675-4867-bc61-9ef86ff842e1'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12472720118239522\n"
     ]
    }
   ],
   "source": [
    "uce, err_in_bin, avg_sigma_in_bin, freq_in_bin = uceloss(err_calib**2, uncert_calib**2)\n",
    "plot_uncert(err_in_bin.cpu(), avg_sigma_in_bin.cpu())\n",
    "print(uce.item()*100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "/* Put everything inside the global mpl namespace */\nwindow.mpl = {};\n\n\nmpl.get_websocket_type = function() {\n    if (typeof(WebSocket) !== 'undefined') {\n        return WebSocket;\n    } else if (typeof(MozWebSocket) !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert('Your browser does not have WebSocket support. ' +\n              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n              'Firefox 4 and 5 are also supported but you ' +\n              'have to enable WebSockets in about:config.');\n    };\n}\n\nmpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = (this.ws.binaryType != undefined);\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById(\"mpl-warnings\");\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent = (\n                \"This browser does not support binary websocket messages. \" +\n                    \"Performance may be slow.\");\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = $('<div/>');\n    this._root_extra_style(this.root)\n    this.root.attr('style', 'display: inline-block');\n\n    $(parent_element).append(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen =  function () {\n            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n            fig.send_message(\"send_image_mode\", {});\n            if (mpl.ratio != 1) {\n                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n            }\n            fig.send_message(\"refresh\", {});\n        }\n\n    this.imageObj.onload = function() {\n            if (fig.image_mode == 'full') {\n                // Full images could contain transparency (where diff images\n                // almost always do), so we need to clear the canvas so that\n                // there is no ghosting.\n                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n            }\n            fig.context.drawImage(fig.imageObj, 0, 0);\n        };\n\n    this.imageObj.onunload = function() {\n        fig.ws.close();\n    }\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n}\n\nmpl.figure.prototype._init_header = function() {\n    var titlebar = $(\n        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n        'ui-helper-clearfix\"/>');\n    var titletext = $(\n        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n        'text-align: center; padding: 3px;\"/>');\n    titlebar.append(titletext)\n    this.root.append(titlebar);\n    this.header = titletext[0];\n}\n\n\n\nmpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n\n}\n\n\nmpl.figure.prototype._root_extra_style = function(canvas_div) {\n\n}\n\nmpl.figure.prototype._init_canvas = function() {\n    var fig = this;\n\n    var canvas_div = $('<div/>');\n\n    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n\n    function canvas_keyboard_event(event) {\n        return fig.key_event(event, event['data']);\n    }\n\n    canvas_div.keydown('key_press', canvas_keyboard_event);\n    canvas_div.keyup('key_release', canvas_keyboard_event);\n    this.canvas_div = canvas_div\n    this._canvas_extra_style(canvas_div)\n    this.root.append(canvas_div);\n\n    var canvas = $('<canvas/>');\n    canvas.addClass('mpl-canvas');\n    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n\n    this.canvas = canvas[0];\n    this.context = canvas[0].getContext(\"2d\");\n\n    var backingStore = this.context.backingStorePixelRatio ||\n\tthis.context.webkitBackingStorePixelRatio ||\n\tthis.context.mozBackingStorePixelRatio ||\n\tthis.context.msBackingStorePixelRatio ||\n\tthis.context.oBackingStorePixelRatio ||\n\tthis.context.backingStorePixelRatio || 1;\n\n    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband = $('<canvas/>');\n    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n\n    var pass_mouse_events = true;\n\n    canvas_div.resizable({\n        start: function(event, ui) {\n            pass_mouse_events = false;\n        },\n        resize: function(event, ui) {\n            fig.request_resize(ui.size.width, ui.size.height);\n        },\n        stop: function(event, ui) {\n            pass_mouse_events = true;\n            fig.request_resize(ui.size.width, ui.size.height);\n        },\n    });\n\n    function mouse_event_fn(event) {\n        if (pass_mouse_events)\n            return fig.mouse_event(event, event['data']);\n    }\n\n    rubberband.mousedown('button_press', mouse_event_fn);\n    rubberband.mouseup('button_release', mouse_event_fn);\n    // Throttle sequential mouse events to 1 every 20ms.\n    rubberband.mousemove('motion_notify', mouse_event_fn);\n\n    rubberband.mouseenter('figure_enter', mouse_event_fn);\n    rubberband.mouseleave('figure_leave', mouse_event_fn);\n\n    canvas_div.on(\"wheel\", function (event) {\n        event = event.originalEvent;\n        event['data'] = 'scroll'\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        mouse_event_fn(event);\n    });\n\n    canvas_div.append(canvas);\n    canvas_div.append(rubberband);\n\n    this.rubberband = rubberband;\n    this.rubberband_canvas = rubberband[0];\n    this.rubberband_context = rubberband[0].getContext(\"2d\");\n    this.rubberband_context.strokeStyle = \"#000000\";\n\n    this._resize_canvas = function(width, height) {\n        // Keep the size of the canvas, canvas container, and rubber band\n        // canvas in synch.\n        canvas_div.css('width', width)\n        canvas_div.css('height', height)\n\n        canvas.attr('width', width * mpl.ratio);\n        canvas.attr('height', height * mpl.ratio);\n        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n\n        rubberband.attr('width', width);\n        rubberband.attr('height', height);\n    }\n\n    // Set the figure to an initial 600x600px, this will subsequently be updated\n    // upon first draw.\n    this._resize_canvas(600, 600);\n\n    // Disable right mouse context menu.\n    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n        return false;\n    });\n\n    function set_focus () {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n}\n\nmpl.figure.prototype._init_toolbar = function() {\n    var fig = this;\n\n    var nav_element = $('<div/>');\n    nav_element.attr('style', 'width: 100%');\n    this.root.append(nav_element);\n\n    // Define a callback function for later on.\n    function toolbar_event(event) {\n        return fig.toolbar_button_onclick(event['data']);\n    }\n    function toolbar_mouse_event(event) {\n        return fig.toolbar_button_onmouseover(event['data']);\n    }\n\n    for(var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            // put a spacer in here.\n            continue;\n        }\n        var button = $('<button/>');\n        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n                        'ui-button-icon-only');\n        button.attr('role', 'button');\n        button.attr('aria-disabled', 'false');\n        button.click(method_name, toolbar_event);\n        button.mouseover(tooltip, toolbar_mouse_event);\n\n        var icon_img = $('<span/>');\n        icon_img.addClass('ui-button-icon-primary ui-icon');\n        icon_img.addClass(image);\n        icon_img.addClass('ui-corner-all');\n\n        var tooltip_span = $('<span/>');\n        tooltip_span.addClass('ui-button-text');\n        tooltip_span.html(tooltip);\n\n        button.append(icon_img);\n        button.append(tooltip_span);\n\n        nav_element.append(button);\n    }\n\n    var fmt_picker_span = $('<span/>');\n\n    var fmt_picker = $('<select/>');\n    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n    fmt_picker_span.append(fmt_picker);\n    nav_element.append(fmt_picker_span);\n    this.format_dropdown = fmt_picker[0];\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = $(\n            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n        fmt_picker.append(option);\n    }\n\n    // Add hover states to the ui-buttons\n    $( \".ui-button\" ).hover(\n        function() { $(this).addClass(\"ui-state-hover\");},\n        function() { $(this).removeClass(\"ui-state-hover\");}\n    );\n\n    var status_bar = $('<span class=\"mpl-message\"/>');\n    nav_element.append(status_bar);\n    this.message = status_bar[0];\n}\n\nmpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n}\n\nmpl.figure.prototype.send_message = function(type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n}\n\nmpl.figure.prototype.send_draw_message = function() {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n    }\n}\n\n\nmpl.figure.prototype.handle_save = function(fig, msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n}\n\n\nmpl.figure.prototype.handle_resize = function(fig, msg) {\n    var size = msg['size'];\n    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1]);\n        fig.send_message(\"refresh\", {});\n    };\n}\n\nmpl.figure.prototype.handle_rubberband = function(fig, msg) {\n    var x0 = msg['x0'] / mpl.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n    var x1 = msg['x1'] / mpl.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0, 0, fig.canvas.width, fig.canvas.height);\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n}\n\nmpl.figure.prototype.handle_figure_label = function(fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n}\n\nmpl.figure.prototype.handle_cursor = function(fig, msg) {\n    var cursor = msg['cursor'];\n    switch(cursor)\n    {\n    case 0:\n        cursor = 'pointer';\n        break;\n    case 1:\n        cursor = 'default';\n        break;\n    case 2:\n        cursor = 'crosshair';\n        break;\n    case 3:\n        cursor = 'move';\n        break;\n    }\n    fig.rubberband_canvas.style.cursor = cursor;\n}\n\nmpl.figure.prototype.handle_message = function(fig, msg) {\n    fig.message.textContent = msg['message'];\n}\n\nmpl.figure.prototype.handle_draw = function(fig, msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n}\n\nmpl.figure.prototype.handle_image_mode = function(fig, msg) {\n    fig.image_mode = msg['mode'];\n}\n\nmpl.figure.prototype.updated_canvas_event = function() {\n    // Called whenever the canvas gets updated.\n    this.send_message(\"ack\", {});\n}\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function(fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            /* FIXME: We get \"Resource interpreted as Image but\n             * transferred with MIME type text/plain:\" errors on\n             * Chrome.  But how to set the MIME type?  It doesn't seem\n             * to be part of the websocket stream */\n            evt.data.type = \"image/png\";\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src);\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                evt.data);\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig[\"handle_\" + msg_type];\n        } catch (e) {\n            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n            }\n        }\n    };\n}\n\n// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\nmpl.findpos = function(e) {\n    //this section is from http://www.quirksmode.org/js/events_properties.html\n    var targ;\n    if (!e)\n        e = window.event;\n    if (e.target)\n        targ = e.target;\n    else if (e.srcElement)\n        targ = e.srcElement;\n    if (targ.nodeType == 3) // defeat Safari bug\n        targ = targ.parentNode;\n\n    // jQuery normalizes the pageX and pageY\n    // pageX,Y are the mouse positions relative to the document\n    // offset() returns the position of the element relative to the document\n    var x = e.pageX - $(targ).offset().left;\n    var y = e.pageY - $(targ).offset().top;\n\n    return {\"x\": x, \"y\": y};\n};\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * http://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys (original) {\n  return Object.keys(original).reduce(function (obj, key) {\n    if (typeof original[key] !== 'object')\n        obj[key] = original[key]\n    return obj;\n  }, {});\n}\n\nmpl.figure.prototype.mouse_event = function(event, name) {\n    var canvas_pos = mpl.findpos(event)\n\n    if (name === 'button_press')\n    {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    var x = canvas_pos.x * mpl.ratio;\n    var y = canvas_pos.y * mpl.ratio;\n\n    this.send_message(name, {x: x, y: y, button: event.button,\n                             step: event.step,\n                             guiEvent: simpleKeys(event)});\n\n    /* This prevents the web browser from automatically changing to\n     * the text insertion cursor when the button is pressed.  We want\n     * to control all of the cursor setting manually through the\n     * 'cursor' event from matplotlib */\n    event.preventDefault();\n    return false;\n}\n\nmpl.figure.prototype._key_event_extra = function(event, name) {\n    // Handle any extra behaviour associated with a key event\n}\n\nmpl.figure.prototype.key_event = function(event, name) {\n\n    // Prevent repeat events\n    if (name == 'key_press')\n    {\n        if (event.which === this._key)\n            return;\n        else\n            this._key = event.which;\n    }\n    if (name == 'key_release')\n        this._key = null;\n\n    var value = '';\n    if (event.ctrlKey && event.which != 17)\n        value += \"ctrl+\";\n    if (event.altKey && event.which != 18)\n        value += \"alt+\";\n    if (event.shiftKey && event.which != 16)\n        value += \"shift+\";\n\n    value += 'k';\n    value += event.which.toString();\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, {key: value,\n                             guiEvent: simpleKeys(event)});\n    return false;\n}\n\nmpl.figure.prototype.toolbar_button_onclick = function(name) {\n    if (name == 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message(\"toolbar_button\", {name: name});\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n    this.message.textContent = tooltip;\n};\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n\nmpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.close = function() {\n        comm.close()\n    };\n    ws.send = function(m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function(msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(msg['content']['data'])\n    });\n    return ws;\n}\n\nmpl.mpl_figure_comm = function(comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = $(\"#\" + id);\n    var ws_proxy = comm_websocket_adapter(comm)\n\n    function ondownload(figure, format) {\n        window.open(figure.imageObj.src);\n    }\n\n    var fig = new mpl.figure(id, ws_proxy,\n                           ondownload,\n                           element.get(0));\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element.get(0);\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error(\"Failed to find cell for figure\", id, fig);\n        return;\n    }\n\n    var output_index = fig.cell_info[2]\n    var cell = fig.cell_info[0];\n\n};\n\nmpl.figure.prototype.handle_close = function(fig, msg) {\n    var width = fig.canvas.width/mpl.ratio\n    fig.root.unbind('remove')\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable()\n    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n    fig.close_ws(fig, msg);\n}\n\nmpl.figure.prototype.close_ws = function(fig, msg){\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n}\n\nmpl.figure.prototype.push_to_output = function(remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width/mpl.ratio\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n}\n\nmpl.figure.prototype.updated_canvas_event = function() {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message(\"ack\", {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () { fig.push_to_output() }, 1000);\n}\n\nmpl.figure.prototype._init_toolbar = function() {\n    var fig = this;\n\n    var nav_element = $('<div/>');\n    nav_element.attr('style', 'width: 100%');\n    this.root.append(nav_element);\n\n    // Define a callback function for later on.\n    function toolbar_event(event) {\n        return fig.toolbar_button_onclick(event['data']);\n    }\n    function toolbar_mouse_event(event) {\n        return fig.toolbar_button_onmouseover(event['data']);\n    }\n\n    for(var toolbar_ind in mpl.toolbar_items){\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) { continue; };\n\n        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n        button.click(method_name, toolbar_event);\n        button.mouseover(tooltip, toolbar_mouse_event);\n        nav_element.append(button);\n    }\n\n    // Add the status bar.\n    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n    nav_element.append(status_bar);\n    this.message = status_bar[0];\n\n    // Add the close button to the window.\n    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n    button.click(function (evt) { fig.handle_close(fig, {}); } );\n    button.mouseover('Stop Interaction', toolbar_mouse_event);\n    buttongrp.append(button);\n    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n    titlebar.prepend(buttongrp);\n}\n\nmpl.figure.prototype._root_extra_style = function(el){\n    var fig = this\n    el.on(\"remove\", function(){\n\tfig.close_ws(fig, {});\n    });\n}\n\nmpl.figure.prototype._canvas_extra_style = function(el){\n    // this is important to make the div 'focusable\n    el.attr('tabindex', 0)\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    }\n    else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n\n}\n\nmpl.figure.prototype._key_event_extra = function(event, name) {\n    var manager = IPython.notebook.keyboard_manager;\n    if (!manager)\n        manager = IPython.keyboard_manager;\n\n    // Check for shift+enter\n    if (event.shiftKey && event.which == 13) {\n        this.canvas_div.blur();\n        event.shiftKey = false;\n        // Send a \"J\" for go to next cell\n        event.which = 74;\n        event.keyCode = 74;\n        manager.command_mode();\n        manager.handle_keydown(event);\n    }\n}\n\nmpl.figure.prototype.handle_save = function(fig, msg) {\n    fig.ondownload(fig, null);\n}\n\n\nmpl.find_output_cell = function(html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i=0; i<ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code'){\n            for (var j=0; j<cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] == html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n}\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel != null) {\n    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='242f242a-a3c5-45b7-b025-ec3e2d05ffad'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013302323350217193\n"
     ]
    }
   ],
   "source": [
    "uce, err_in_bin, avg_sigma_in_bin, freq_in_bin = uceloss(err_calib**2, (S*uncert_calib)**2)\n",
    "plot_uncert(err_in_bin.cpu(), avg_sigma_in_bin.cpu())\n",
    "print(uce.item()*100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "/* Put everything inside the global mpl namespace */\nwindow.mpl = {};\n\n\nmpl.get_websocket_type = function() {\n    if (typeof(WebSocket) !== 'undefined') {\n        return WebSocket;\n    } else if (typeof(MozWebSocket) !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert('Your browser does not have WebSocket support. ' +\n              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n              'Firefox 4 and 5 are also supported but you ' +\n              'have to enable WebSockets in about:config.');\n    };\n}\n\nmpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = (this.ws.binaryType != undefined);\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById(\"mpl-warnings\");\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent = (\n                \"This browser does not support binary websocket messages. \" +\n                    \"Performance may be slow.\");\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = $('<div/>');\n    this._root_extra_style(this.root)\n    this.root.attr('style', 'display: inline-block');\n\n    $(parent_element).append(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen =  function () {\n            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n            fig.send_message(\"send_image_mode\", {});\n            if (mpl.ratio != 1) {\n                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n            }\n            fig.send_message(\"refresh\", {});\n        }\n\n    this.imageObj.onload = function() {\n            if (fig.image_mode == 'full') {\n                // Full images could contain transparency (where diff images\n                // almost always do), so we need to clear the canvas so that\n                // there is no ghosting.\n                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n            }\n            fig.context.drawImage(fig.imageObj, 0, 0);\n        };\n\n    this.imageObj.onunload = function() {\n        fig.ws.close();\n    }\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n}\n\nmpl.figure.prototype._init_header = function() {\n    var titlebar = $(\n        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n        'ui-helper-clearfix\"/>');\n    var titletext = $(\n        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n        'text-align: center; padding: 3px;\"/>');\n    titlebar.append(titletext)\n    this.root.append(titlebar);\n    this.header = titletext[0];\n}\n\n\n\nmpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n\n}\n\n\nmpl.figure.prototype._root_extra_style = function(canvas_div) {\n\n}\n\nmpl.figure.prototype._init_canvas = function() {\n    var fig = this;\n\n    var canvas_div = $('<div/>');\n\n    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n\n    function canvas_keyboard_event(event) {\n        return fig.key_event(event, event['data']);\n    }\n\n    canvas_div.keydown('key_press', canvas_keyboard_event);\n    canvas_div.keyup('key_release', canvas_keyboard_event);\n    this.canvas_div = canvas_div\n    this._canvas_extra_style(canvas_div)\n    this.root.append(canvas_div);\n\n    var canvas = $('<canvas/>');\n    canvas.addClass('mpl-canvas');\n    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n\n    this.canvas = canvas[0];\n    this.context = canvas[0].getContext(\"2d\");\n\n    var backingStore = this.context.backingStorePixelRatio ||\n\tthis.context.webkitBackingStorePixelRatio ||\n\tthis.context.mozBackingStorePixelRatio ||\n\tthis.context.msBackingStorePixelRatio ||\n\tthis.context.oBackingStorePixelRatio ||\n\tthis.context.backingStorePixelRatio || 1;\n\n    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband = $('<canvas/>');\n    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n\n    var pass_mouse_events = true;\n\n    canvas_div.resizable({\n        start: function(event, ui) {\n            pass_mouse_events = false;\n        },\n        resize: function(event, ui) {\n            fig.request_resize(ui.size.width, ui.size.height);\n        },\n        stop: function(event, ui) {\n            pass_mouse_events = true;\n            fig.request_resize(ui.size.width, ui.size.height);\n        },\n    });\n\n    function mouse_event_fn(event) {\n        if (pass_mouse_events)\n            return fig.mouse_event(event, event['data']);\n    }\n\n    rubberband.mousedown('button_press', mouse_event_fn);\n    rubberband.mouseup('button_release', mouse_event_fn);\n    // Throttle sequential mouse events to 1 every 20ms.\n    rubberband.mousemove('motion_notify', mouse_event_fn);\n\n    rubberband.mouseenter('figure_enter', mouse_event_fn);\n    rubberband.mouseleave('figure_leave', mouse_event_fn);\n\n    canvas_div.on(\"wheel\", function (event) {\n        event = event.originalEvent;\n        event['data'] = 'scroll'\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        mouse_event_fn(event);\n    });\n\n    canvas_div.append(canvas);\n    canvas_div.append(rubberband);\n\n    this.rubberband = rubberband;\n    this.rubberband_canvas = rubberband[0];\n    this.rubberband_context = rubberband[0].getContext(\"2d\");\n    this.rubberband_context.strokeStyle = \"#000000\";\n\n    this._resize_canvas = function(width, height) {\n        // Keep the size of the canvas, canvas container, and rubber band\n        // canvas in synch.\n        canvas_div.css('width', width)\n        canvas_div.css('height', height)\n\n        canvas.attr('width', width * mpl.ratio);\n        canvas.attr('height', height * mpl.ratio);\n        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n\n        rubberband.attr('width', width);\n        rubberband.attr('height', height);\n    }\n\n    // Set the figure to an initial 600x600px, this will subsequently be updated\n    // upon first draw.\n    this._resize_canvas(600, 600);\n\n    // Disable right mouse context menu.\n    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n        return false;\n    });\n\n    function set_focus () {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n}\n\nmpl.figure.prototype._init_toolbar = function() {\n    var fig = this;\n\n    var nav_element = $('<div/>');\n    nav_element.attr('style', 'width: 100%');\n    this.root.append(nav_element);\n\n    // Define a callback function for later on.\n    function toolbar_event(event) {\n        return fig.toolbar_button_onclick(event['data']);\n    }\n    function toolbar_mouse_event(event) {\n        return fig.toolbar_button_onmouseover(event['data']);\n    }\n\n    for(var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            // put a spacer in here.\n            continue;\n        }\n        var button = $('<button/>');\n        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n                        'ui-button-icon-only');\n        button.attr('role', 'button');\n        button.attr('aria-disabled', 'false');\n        button.click(method_name, toolbar_event);\n        button.mouseover(tooltip, toolbar_mouse_event);\n\n        var icon_img = $('<span/>');\n        icon_img.addClass('ui-button-icon-primary ui-icon');\n        icon_img.addClass(image);\n        icon_img.addClass('ui-corner-all');\n\n        var tooltip_span = $('<span/>');\n        tooltip_span.addClass('ui-button-text');\n        tooltip_span.html(tooltip);\n\n        button.append(icon_img);\n        button.append(tooltip_span);\n\n        nav_element.append(button);\n    }\n\n    var fmt_picker_span = $('<span/>');\n\n    var fmt_picker = $('<select/>');\n    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n    fmt_picker_span.append(fmt_picker);\n    nav_element.append(fmt_picker_span);\n    this.format_dropdown = fmt_picker[0];\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = $(\n            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n        fmt_picker.append(option);\n    }\n\n    // Add hover states to the ui-buttons\n    $( \".ui-button\" ).hover(\n        function() { $(this).addClass(\"ui-state-hover\");},\n        function() { $(this).removeClass(\"ui-state-hover\");}\n    );\n\n    var status_bar = $('<span class=\"mpl-message\"/>');\n    nav_element.append(status_bar);\n    this.message = status_bar[0];\n}\n\nmpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n}\n\nmpl.figure.prototype.send_message = function(type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n}\n\nmpl.figure.prototype.send_draw_message = function() {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n    }\n}\n\n\nmpl.figure.prototype.handle_save = function(fig, msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n}\n\n\nmpl.figure.prototype.handle_resize = function(fig, msg) {\n    var size = msg['size'];\n    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1]);\n        fig.send_message(\"refresh\", {});\n    };\n}\n\nmpl.figure.prototype.handle_rubberband = function(fig, msg) {\n    var x0 = msg['x0'] / mpl.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n    var x1 = msg['x1'] / mpl.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0, 0, fig.canvas.width, fig.canvas.height);\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n}\n\nmpl.figure.prototype.handle_figure_label = function(fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n}\n\nmpl.figure.prototype.handle_cursor = function(fig, msg) {\n    var cursor = msg['cursor'];\n    switch(cursor)\n    {\n    case 0:\n        cursor = 'pointer';\n        break;\n    case 1:\n        cursor = 'default';\n        break;\n    case 2:\n        cursor = 'crosshair';\n        break;\n    case 3:\n        cursor = 'move';\n        break;\n    }\n    fig.rubberband_canvas.style.cursor = cursor;\n}\n\nmpl.figure.prototype.handle_message = function(fig, msg) {\n    fig.message.textContent = msg['message'];\n}\n\nmpl.figure.prototype.handle_draw = function(fig, msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n}\n\nmpl.figure.prototype.handle_image_mode = function(fig, msg) {\n    fig.image_mode = msg['mode'];\n}\n\nmpl.figure.prototype.updated_canvas_event = function() {\n    // Called whenever the canvas gets updated.\n    this.send_message(\"ack\", {});\n}\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function(fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            /* FIXME: We get \"Resource interpreted as Image but\n             * transferred with MIME type text/plain:\" errors on\n             * Chrome.  But how to set the MIME type?  It doesn't seem\n             * to be part of the websocket stream */\n            evt.data.type = \"image/png\";\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src);\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                evt.data);\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig[\"handle_\" + msg_type];\n        } catch (e) {\n            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n            }\n        }\n    };\n}\n\n// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\nmpl.findpos = function(e) {\n    //this section is from http://www.quirksmode.org/js/events_properties.html\n    var targ;\n    if (!e)\n        e = window.event;\n    if (e.target)\n        targ = e.target;\n    else if (e.srcElement)\n        targ = e.srcElement;\n    if (targ.nodeType == 3) // defeat Safari bug\n        targ = targ.parentNode;\n\n    // jQuery normalizes the pageX and pageY\n    // pageX,Y are the mouse positions relative to the document\n    // offset() returns the position of the element relative to the document\n    var x = e.pageX - $(targ).offset().left;\n    var y = e.pageY - $(targ).offset().top;\n\n    return {\"x\": x, \"y\": y};\n};\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * http://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys (original) {\n  return Object.keys(original).reduce(function (obj, key) {\n    if (typeof original[key] !== 'object')\n        obj[key] = original[key]\n    return obj;\n  }, {});\n}\n\nmpl.figure.prototype.mouse_event = function(event, name) {\n    var canvas_pos = mpl.findpos(event)\n\n    if (name === 'button_press')\n    {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    var x = canvas_pos.x * mpl.ratio;\n    var y = canvas_pos.y * mpl.ratio;\n\n    this.send_message(name, {x: x, y: y, button: event.button,\n                             step: event.step,\n                             guiEvent: simpleKeys(event)});\n\n    /* This prevents the web browser from automatically changing to\n     * the text insertion cursor when the button is pressed.  We want\n     * to control all of the cursor setting manually through the\n     * 'cursor' event from matplotlib */\n    event.preventDefault();\n    return false;\n}\n\nmpl.figure.prototype._key_event_extra = function(event, name) {\n    // Handle any extra behaviour associated with a key event\n}\n\nmpl.figure.prototype.key_event = function(event, name) {\n\n    // Prevent repeat events\n    if (name == 'key_press')\n    {\n        if (event.which === this._key)\n            return;\n        else\n            this._key = event.which;\n    }\n    if (name == 'key_release')\n        this._key = null;\n\n    var value = '';\n    if (event.ctrlKey && event.which != 17)\n        value += \"ctrl+\";\n    if (event.altKey && event.which != 18)\n        value += \"alt+\";\n    if (event.shiftKey && event.which != 16)\n        value += \"shift+\";\n\n    value += 'k';\n    value += event.which.toString();\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, {key: value,\n                             guiEvent: simpleKeys(event)});\n    return false;\n}\n\nmpl.figure.prototype.toolbar_button_onclick = function(name) {\n    if (name == 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message(\"toolbar_button\", {name: name});\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n    this.message.textContent = tooltip;\n};\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n\nmpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.close = function() {\n        comm.close()\n    };\n    ws.send = function(m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function(msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(msg['content']['data'])\n    });\n    return ws;\n}\n\nmpl.mpl_figure_comm = function(comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = $(\"#\" + id);\n    var ws_proxy = comm_websocket_adapter(comm)\n\n    function ondownload(figure, format) {\n        window.open(figure.imageObj.src);\n    }\n\n    var fig = new mpl.figure(id, ws_proxy,\n                           ondownload,\n                           element.get(0));\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element.get(0);\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error(\"Failed to find cell for figure\", id, fig);\n        return;\n    }\n\n    var output_index = fig.cell_info[2]\n    var cell = fig.cell_info[0];\n\n};\n\nmpl.figure.prototype.handle_close = function(fig, msg) {\n    var width = fig.canvas.width/mpl.ratio\n    fig.root.unbind('remove')\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable()\n    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n    fig.close_ws(fig, msg);\n}\n\nmpl.figure.prototype.close_ws = function(fig, msg){\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n}\n\nmpl.figure.prototype.push_to_output = function(remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width/mpl.ratio\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n}\n\nmpl.figure.prototype.updated_canvas_event = function() {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message(\"ack\", {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () { fig.push_to_output() }, 1000);\n}\n\nmpl.figure.prototype._init_toolbar = function() {\n    var fig = this;\n\n    var nav_element = $('<div/>');\n    nav_element.attr('style', 'width: 100%');\n    this.root.append(nav_element);\n\n    // Define a callback function for later on.\n    function toolbar_event(event) {\n        return fig.toolbar_button_onclick(event['data']);\n    }\n    function toolbar_mouse_event(event) {\n        return fig.toolbar_button_onmouseover(event['data']);\n    }\n\n    for(var toolbar_ind in mpl.toolbar_items){\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) { continue; };\n\n        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n        button.click(method_name, toolbar_event);\n        button.mouseover(tooltip, toolbar_mouse_event);\n        nav_element.append(button);\n    }\n\n    // Add the status bar.\n    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n    nav_element.append(status_bar);\n    this.message = status_bar[0];\n\n    // Add the close button to the window.\n    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n    button.click(function (evt) { fig.handle_close(fig, {}); } );\n    button.mouseover('Stop Interaction', toolbar_mouse_event);\n    buttongrp.append(button);\n    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n    titlebar.prepend(buttongrp);\n}\n\nmpl.figure.prototype._root_extra_style = function(el){\n    var fig = this\n    el.on(\"remove\", function(){\n\tfig.close_ws(fig, {});\n    });\n}\n\nmpl.figure.prototype._canvas_extra_style = function(el){\n    // this is important to make the div 'focusable\n    el.attr('tabindex', 0)\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    }\n    else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n\n}\n\nmpl.figure.prototype._key_event_extra = function(event, name) {\n    var manager = IPython.notebook.keyboard_manager;\n    if (!manager)\n        manager = IPython.keyboard_manager;\n\n    // Check for shift+enter\n    if (event.shiftKey && event.which == 13) {\n        this.canvas_div.blur();\n        event.shiftKey = false;\n        // Send a \"J\" for go to next cell\n        event.which = 74;\n        event.keyCode = 74;\n        manager.command_mode();\n        manager.handle_keydown(event);\n    }\n}\n\nmpl.figure.prototype.handle_save = function(fig, msg) {\n    fig.ondownload(fig, null);\n}\n\n\nmpl.find_output_cell = function(html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i=0; i<ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code'){\n            for (var j=0; j<cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] == html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n}\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel != null) {\n    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='c1535d9f-7059-4f17-bc99-51f730f69747'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013302323350217193\n"
     ]
    },
    {
     "data": {
      "application/javascript": "/* Put everything inside the global mpl namespace */\nwindow.mpl = {};\n\n\nmpl.get_websocket_type = function() {\n    if (typeof(WebSocket) !== 'undefined') {\n        return WebSocket;\n    } else if (typeof(MozWebSocket) !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert('Your browser does not have WebSocket support. ' +\n              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n              'Firefox 4 and 5 are also supported but you ' +\n              'have to enable WebSockets in about:config.');\n    };\n}\n\nmpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = (this.ws.binaryType != undefined);\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById(\"mpl-warnings\");\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent = (\n                \"This browser does not support binary websocket messages. \" +\n                    \"Performance may be slow.\");\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = $('<div/>');\n    this._root_extra_style(this.root)\n    this.root.attr('style', 'display: inline-block');\n\n    $(parent_element).append(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen =  function () {\n            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n            fig.send_message(\"send_image_mode\", {});\n            if (mpl.ratio != 1) {\n                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n            }\n            fig.send_message(\"refresh\", {});\n        }\n\n    this.imageObj.onload = function() {\n            if (fig.image_mode == 'full') {\n                // Full images could contain transparency (where diff images\n                // almost always do), so we need to clear the canvas so that\n                // there is no ghosting.\n                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n            }\n            fig.context.drawImage(fig.imageObj, 0, 0);\n        };\n\n    this.imageObj.onunload = function() {\n        fig.ws.close();\n    }\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n}\n\nmpl.figure.prototype._init_header = function() {\n    var titlebar = $(\n        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n        'ui-helper-clearfix\"/>');\n    var titletext = $(\n        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n        'text-align: center; padding: 3px;\"/>');\n    titlebar.append(titletext)\n    this.root.append(titlebar);\n    this.header = titletext[0];\n}\n\n\n\nmpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n\n}\n\n\nmpl.figure.prototype._root_extra_style = function(canvas_div) {\n\n}\n\nmpl.figure.prototype._init_canvas = function() {\n    var fig = this;\n\n    var canvas_div = $('<div/>');\n\n    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n\n    function canvas_keyboard_event(event) {\n        return fig.key_event(event, event['data']);\n    }\n\n    canvas_div.keydown('key_press', canvas_keyboard_event);\n    canvas_div.keyup('key_release', canvas_keyboard_event);\n    this.canvas_div = canvas_div\n    this._canvas_extra_style(canvas_div)\n    this.root.append(canvas_div);\n\n    var canvas = $('<canvas/>');\n    canvas.addClass('mpl-canvas');\n    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n\n    this.canvas = canvas[0];\n    this.context = canvas[0].getContext(\"2d\");\n\n    var backingStore = this.context.backingStorePixelRatio ||\n\tthis.context.webkitBackingStorePixelRatio ||\n\tthis.context.mozBackingStorePixelRatio ||\n\tthis.context.msBackingStorePixelRatio ||\n\tthis.context.oBackingStorePixelRatio ||\n\tthis.context.backingStorePixelRatio || 1;\n\n    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband = $('<canvas/>');\n    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n\n    var pass_mouse_events = true;\n\n    canvas_div.resizable({\n        start: function(event, ui) {\n            pass_mouse_events = false;\n        },\n        resize: function(event, ui) {\n            fig.request_resize(ui.size.width, ui.size.height);\n        },\n        stop: function(event, ui) {\n            pass_mouse_events = true;\n            fig.request_resize(ui.size.width, ui.size.height);\n        },\n    });\n\n    function mouse_event_fn(event) {\n        if (pass_mouse_events)\n            return fig.mouse_event(event, event['data']);\n    }\n\n    rubberband.mousedown('button_press', mouse_event_fn);\n    rubberband.mouseup('button_release', mouse_event_fn);\n    // Throttle sequential mouse events to 1 every 20ms.\n    rubberband.mousemove('motion_notify', mouse_event_fn);\n\n    rubberband.mouseenter('figure_enter', mouse_event_fn);\n    rubberband.mouseleave('figure_leave', mouse_event_fn);\n\n    canvas_div.on(\"wheel\", function (event) {\n        event = event.originalEvent;\n        event['data'] = 'scroll'\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        mouse_event_fn(event);\n    });\n\n    canvas_div.append(canvas);\n    canvas_div.append(rubberband);\n\n    this.rubberband = rubberband;\n    this.rubberband_canvas = rubberband[0];\n    this.rubberband_context = rubberband[0].getContext(\"2d\");\n    this.rubberband_context.strokeStyle = \"#000000\";\n\n    this._resize_canvas = function(width, height) {\n        // Keep the size of the canvas, canvas container, and rubber band\n        // canvas in synch.\n        canvas_div.css('width', width)\n        canvas_div.css('height', height)\n\n        canvas.attr('width', width * mpl.ratio);\n        canvas.attr('height', height * mpl.ratio);\n        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n\n        rubberband.attr('width', width);\n        rubberband.attr('height', height);\n    }\n\n    // Set the figure to an initial 600x600px, this will subsequently be updated\n    // upon first draw.\n    this._resize_canvas(600, 600);\n\n    // Disable right mouse context menu.\n    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n        return false;\n    });\n\n    function set_focus () {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n}\n\nmpl.figure.prototype._init_toolbar = function() {\n    var fig = this;\n\n    var nav_element = $('<div/>');\n    nav_element.attr('style', 'width: 100%');\n    this.root.append(nav_element);\n\n    // Define a callback function for later on.\n    function toolbar_event(event) {\n        return fig.toolbar_button_onclick(event['data']);\n    }\n    function toolbar_mouse_event(event) {\n        return fig.toolbar_button_onmouseover(event['data']);\n    }\n\n    for(var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            // put a spacer in here.\n            continue;\n        }\n        var button = $('<button/>');\n        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n                        'ui-button-icon-only');\n        button.attr('role', 'button');\n        button.attr('aria-disabled', 'false');\n        button.click(method_name, toolbar_event);\n        button.mouseover(tooltip, toolbar_mouse_event);\n\n        var icon_img = $('<span/>');\n        icon_img.addClass('ui-button-icon-primary ui-icon');\n        icon_img.addClass(image);\n        icon_img.addClass('ui-corner-all');\n\n        var tooltip_span = $('<span/>');\n        tooltip_span.addClass('ui-button-text');\n        tooltip_span.html(tooltip);\n\n        button.append(icon_img);\n        button.append(tooltip_span);\n\n        nav_element.append(button);\n    }\n\n    var fmt_picker_span = $('<span/>');\n\n    var fmt_picker = $('<select/>');\n    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n    fmt_picker_span.append(fmt_picker);\n    nav_element.append(fmt_picker_span);\n    this.format_dropdown = fmt_picker[0];\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = $(\n            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n        fmt_picker.append(option);\n    }\n\n    // Add hover states to the ui-buttons\n    $( \".ui-button\" ).hover(\n        function() { $(this).addClass(\"ui-state-hover\");},\n        function() { $(this).removeClass(\"ui-state-hover\");}\n    );\n\n    var status_bar = $('<span class=\"mpl-message\"/>');\n    nav_element.append(status_bar);\n    this.message = status_bar[0];\n}\n\nmpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n}\n\nmpl.figure.prototype.send_message = function(type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n}\n\nmpl.figure.prototype.send_draw_message = function() {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n    }\n}\n\n\nmpl.figure.prototype.handle_save = function(fig, msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n}\n\n\nmpl.figure.prototype.handle_resize = function(fig, msg) {\n    var size = msg['size'];\n    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1]);\n        fig.send_message(\"refresh\", {});\n    };\n}\n\nmpl.figure.prototype.handle_rubberband = function(fig, msg) {\n    var x0 = msg['x0'] / mpl.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n    var x1 = msg['x1'] / mpl.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0, 0, fig.canvas.width, fig.canvas.height);\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n}\n\nmpl.figure.prototype.handle_figure_label = function(fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n}\n\nmpl.figure.prototype.handle_cursor = function(fig, msg) {\n    var cursor = msg['cursor'];\n    switch(cursor)\n    {\n    case 0:\n        cursor = 'pointer';\n        break;\n    case 1:\n        cursor = 'default';\n        break;\n    case 2:\n        cursor = 'crosshair';\n        break;\n    case 3:\n        cursor = 'move';\n        break;\n    }\n    fig.rubberband_canvas.style.cursor = cursor;\n}\n\nmpl.figure.prototype.handle_message = function(fig, msg) {\n    fig.message.textContent = msg['message'];\n}\n\nmpl.figure.prototype.handle_draw = function(fig, msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n}\n\nmpl.figure.prototype.handle_image_mode = function(fig, msg) {\n    fig.image_mode = msg['mode'];\n}\n\nmpl.figure.prototype.updated_canvas_event = function() {\n    // Called whenever the canvas gets updated.\n    this.send_message(\"ack\", {});\n}\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function(fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            /* FIXME: We get \"Resource interpreted as Image but\n             * transferred with MIME type text/plain:\" errors on\n             * Chrome.  But how to set the MIME type?  It doesn't seem\n             * to be part of the websocket stream */\n            evt.data.type = \"image/png\";\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src);\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                evt.data);\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig[\"handle_\" + msg_type];\n        } catch (e) {\n            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n            }\n        }\n    };\n}\n\n// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\nmpl.findpos = function(e) {\n    //this section is from http://www.quirksmode.org/js/events_properties.html\n    var targ;\n    if (!e)\n        e = window.event;\n    if (e.target)\n        targ = e.target;\n    else if (e.srcElement)\n        targ = e.srcElement;\n    if (targ.nodeType == 3) // defeat Safari bug\n        targ = targ.parentNode;\n\n    // jQuery normalizes the pageX and pageY\n    // pageX,Y are the mouse positions relative to the document\n    // offset() returns the position of the element relative to the document\n    var x = e.pageX - $(targ).offset().left;\n    var y = e.pageY - $(targ).offset().top;\n\n    return {\"x\": x, \"y\": y};\n};\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * http://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys (original) {\n  return Object.keys(original).reduce(function (obj, key) {\n    if (typeof original[key] !== 'object')\n        obj[key] = original[key]\n    return obj;\n  }, {});\n}\n\nmpl.figure.prototype.mouse_event = function(event, name) {\n    var canvas_pos = mpl.findpos(event)\n\n    if (name === 'button_press')\n    {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    var x = canvas_pos.x * mpl.ratio;\n    var y = canvas_pos.y * mpl.ratio;\n\n    this.send_message(name, {x: x, y: y, button: event.button,\n                             step: event.step,\n                             guiEvent: simpleKeys(event)});\n\n    /* This prevents the web browser from automatically changing to\n     * the text insertion cursor when the button is pressed.  We want\n     * to control all of the cursor setting manually through the\n     * 'cursor' event from matplotlib */\n    event.preventDefault();\n    return false;\n}\n\nmpl.figure.prototype._key_event_extra = function(event, name) {\n    // Handle any extra behaviour associated with a key event\n}\n\nmpl.figure.prototype.key_event = function(event, name) {\n\n    // Prevent repeat events\n    if (name == 'key_press')\n    {\n        if (event.which === this._key)\n            return;\n        else\n            this._key = event.which;\n    }\n    if (name == 'key_release')\n        this._key = null;\n\n    var value = '';\n    if (event.ctrlKey && event.which != 17)\n        value += \"ctrl+\";\n    if (event.altKey && event.which != 18)\n        value += \"alt+\";\n    if (event.shiftKey && event.which != 16)\n        value += \"shift+\";\n\n    value += 'k';\n    value += event.which.toString();\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, {key: value,\n                             guiEvent: simpleKeys(event)});\n    return false;\n}\n\nmpl.figure.prototype.toolbar_button_onclick = function(name) {\n    if (name == 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message(\"toolbar_button\", {name: name});\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n    this.message.textContent = tooltip;\n};\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n\nmpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.close = function() {\n        comm.close()\n    };\n    ws.send = function(m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function(msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(msg['content']['data'])\n    });\n    return ws;\n}\n\nmpl.mpl_figure_comm = function(comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = $(\"#\" + id);\n    var ws_proxy = comm_websocket_adapter(comm)\n\n    function ondownload(figure, format) {\n        window.open(figure.imageObj.src);\n    }\n\n    var fig = new mpl.figure(id, ws_proxy,\n                           ondownload,\n                           element.get(0));\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element.get(0);\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error(\"Failed to find cell for figure\", id, fig);\n        return;\n    }\n\n    var output_index = fig.cell_info[2]\n    var cell = fig.cell_info[0];\n\n};\n\nmpl.figure.prototype.handle_close = function(fig, msg) {\n    var width = fig.canvas.width/mpl.ratio\n    fig.root.unbind('remove')\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable()\n    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n    fig.close_ws(fig, msg);\n}\n\nmpl.figure.prototype.close_ws = function(fig, msg){\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n}\n\nmpl.figure.prototype.push_to_output = function(remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width/mpl.ratio\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n}\n\nmpl.figure.prototype.updated_canvas_event = function() {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message(\"ack\", {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () { fig.push_to_output() }, 1000);\n}\n\nmpl.figure.prototype._init_toolbar = function() {\n    var fig = this;\n\n    var nav_element = $('<div/>');\n    nav_element.attr('style', 'width: 100%');\n    this.root.append(nav_element);\n\n    // Define a callback function for later on.\n    function toolbar_event(event) {\n        return fig.toolbar_button_onclick(event['data']);\n    }\n    function toolbar_mouse_event(event) {\n        return fig.toolbar_button_onmouseover(event['data']);\n    }\n\n    for(var toolbar_ind in mpl.toolbar_items){\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) { continue; };\n\n        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n        button.click(method_name, toolbar_event);\n        button.mouseover(tooltip, toolbar_mouse_event);\n        nav_element.append(button);\n    }\n\n    // Add the status bar.\n    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n    nav_element.append(status_bar);\n    this.message = status_bar[0];\n\n    // Add the close button to the window.\n    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n    button.click(function (evt) { fig.handle_close(fig, {}); } );\n    button.mouseover('Stop Interaction', toolbar_mouse_event);\n    buttongrp.append(button);\n    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n    titlebar.prepend(buttongrp);\n}\n\nmpl.figure.prototype._root_extra_style = function(el){\n    var fig = this\n    el.on(\"remove\", function(){\n\tfig.close_ws(fig, {});\n    });\n}\n\nmpl.figure.prototype._canvas_extra_style = function(el){\n    // this is important to make the div 'focusable\n    el.attr('tabindex', 0)\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    }\n    else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n\n}\n\nmpl.figure.prototype._key_event_extra = function(event, name) {\n    var manager = IPython.notebook.keyboard_manager;\n    if (!manager)\n        manager = IPython.keyboard_manager;\n\n    // Check for shift+enter\n    if (event.shiftKey && event.which == 13) {\n        this.canvas_div.blur();\n        event.shiftKey = false;\n        // Send a \"J\" for go to next cell\n        event.which = 74;\n        event.keyCode = 74;\n        manager.command_mode();\n        manager.handle_keydown(event);\n    }\n}\n\nmpl.figure.prototype.handle_save = function(fig, msg) {\n    fig.ondownload(fig, null);\n}\n\n\nmpl.find_output_cell = function(html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i=0; i<ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code'){\n            for (var j=0; j<cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] == html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n}\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel != null) {\n    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='15a11b7a-12f3-435e-8b15-985b96e5a3c5'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_bins = 15\n",
    "uce, err_in_bin, avg_uncert_in_bin, freq_in_bin = uceloss(err_calib**2, scaler(uncert_calib)**2, n_bins=n_bins)\n",
    "plot_uncert(err_in_bin.cpu(), avg_uncert_in_bin.cpu())\n",
    "plt.show()\n",
    "print(uce.item()*100)\n",
    "fig, ax = plot_frequency(scaler(uncert_calib).cpu(), freq_in_bin.cpu(), n_bins=n_bins)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "/* Put everything inside the global mpl namespace */\nwindow.mpl = {};\n\n\nmpl.get_websocket_type = function() {\n    if (typeof(WebSocket) !== 'undefined') {\n        return WebSocket;\n    } else if (typeof(MozWebSocket) !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert('Your browser does not have WebSocket support. ' +\n              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n              'Firefox 4 and 5 are also supported but you ' +\n              'have to enable WebSockets in about:config.');\n    };\n}\n\nmpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = (this.ws.binaryType != undefined);\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById(\"mpl-warnings\");\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent = (\n                \"This browser does not support binary websocket messages. \" +\n                    \"Performance may be slow.\");\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = $('<div/>');\n    this._root_extra_style(this.root)\n    this.root.attr('style', 'display: inline-block');\n\n    $(parent_element).append(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen =  function () {\n            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n            fig.send_message(\"send_image_mode\", {});\n            if (mpl.ratio != 1) {\n                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n            }\n            fig.send_message(\"refresh\", {});\n        }\n\n    this.imageObj.onload = function() {\n            if (fig.image_mode == 'full') {\n                // Full images could contain transparency (where diff images\n                // almost always do), so we need to clear the canvas so that\n                // there is no ghosting.\n                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n            }\n            fig.context.drawImage(fig.imageObj, 0, 0);\n        };\n\n    this.imageObj.onunload = function() {\n        fig.ws.close();\n    }\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n}\n\nmpl.figure.prototype._init_header = function() {\n    var titlebar = $(\n        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n        'ui-helper-clearfix\"/>');\n    var titletext = $(\n        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n        'text-align: center; padding: 3px;\"/>');\n    titlebar.append(titletext)\n    this.root.append(titlebar);\n    this.header = titletext[0];\n}\n\n\n\nmpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n\n}\n\n\nmpl.figure.prototype._root_extra_style = function(canvas_div) {\n\n}\n\nmpl.figure.prototype._init_canvas = function() {\n    var fig = this;\n\n    var canvas_div = $('<div/>');\n\n    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n\n    function canvas_keyboard_event(event) {\n        return fig.key_event(event, event['data']);\n    }\n\n    canvas_div.keydown('key_press', canvas_keyboard_event);\n    canvas_div.keyup('key_release', canvas_keyboard_event);\n    this.canvas_div = canvas_div\n    this._canvas_extra_style(canvas_div)\n    this.root.append(canvas_div);\n\n    var canvas = $('<canvas/>');\n    canvas.addClass('mpl-canvas');\n    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n\n    this.canvas = canvas[0];\n    this.context = canvas[0].getContext(\"2d\");\n\n    var backingStore = this.context.backingStorePixelRatio ||\n\tthis.context.webkitBackingStorePixelRatio ||\n\tthis.context.mozBackingStorePixelRatio ||\n\tthis.context.msBackingStorePixelRatio ||\n\tthis.context.oBackingStorePixelRatio ||\n\tthis.context.backingStorePixelRatio || 1;\n\n    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband = $('<canvas/>');\n    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n\n    var pass_mouse_events = true;\n\n    canvas_div.resizable({\n        start: function(event, ui) {\n            pass_mouse_events = false;\n        },\n        resize: function(event, ui) {\n            fig.request_resize(ui.size.width, ui.size.height);\n        },\n        stop: function(event, ui) {\n            pass_mouse_events = true;\n            fig.request_resize(ui.size.width, ui.size.height);\n        },\n    });\n\n    function mouse_event_fn(event) {\n        if (pass_mouse_events)\n            return fig.mouse_event(event, event['data']);\n    }\n\n    rubberband.mousedown('button_press', mouse_event_fn);\n    rubberband.mouseup('button_release', mouse_event_fn);\n    // Throttle sequential mouse events to 1 every 20ms.\n    rubberband.mousemove('motion_notify', mouse_event_fn);\n\n    rubberband.mouseenter('figure_enter', mouse_event_fn);\n    rubberband.mouseleave('figure_leave', mouse_event_fn);\n\n    canvas_div.on(\"wheel\", function (event) {\n        event = event.originalEvent;\n        event['data'] = 'scroll'\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        mouse_event_fn(event);\n    });\n\n    canvas_div.append(canvas);\n    canvas_div.append(rubberband);\n\n    this.rubberband = rubberband;\n    this.rubberband_canvas = rubberband[0];\n    this.rubberband_context = rubberband[0].getContext(\"2d\");\n    this.rubberband_context.strokeStyle = \"#000000\";\n\n    this._resize_canvas = function(width, height) {\n        // Keep the size of the canvas, canvas container, and rubber band\n        // canvas in synch.\n        canvas_div.css('width', width)\n        canvas_div.css('height', height)\n\n        canvas.attr('width', width * mpl.ratio);\n        canvas.attr('height', height * mpl.ratio);\n        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n\n        rubberband.attr('width', width);\n        rubberband.attr('height', height);\n    }\n\n    // Set the figure to an initial 600x600px, this will subsequently be updated\n    // upon first draw.\n    this._resize_canvas(600, 600);\n\n    // Disable right mouse context menu.\n    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n        return false;\n    });\n\n    function set_focus () {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n}\n\nmpl.figure.prototype._init_toolbar = function() {\n    var fig = this;\n\n    var nav_element = $('<div/>');\n    nav_element.attr('style', 'width: 100%');\n    this.root.append(nav_element);\n\n    // Define a callback function for later on.\n    function toolbar_event(event) {\n        return fig.toolbar_button_onclick(event['data']);\n    }\n    function toolbar_mouse_event(event) {\n        return fig.toolbar_button_onmouseover(event['data']);\n    }\n\n    for(var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            // put a spacer in here.\n            continue;\n        }\n        var button = $('<button/>');\n        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n                        'ui-button-icon-only');\n        button.attr('role', 'button');\n        button.attr('aria-disabled', 'false');\n        button.click(method_name, toolbar_event);\n        button.mouseover(tooltip, toolbar_mouse_event);\n\n        var icon_img = $('<span/>');\n        icon_img.addClass('ui-button-icon-primary ui-icon');\n        icon_img.addClass(image);\n        icon_img.addClass('ui-corner-all');\n\n        var tooltip_span = $('<span/>');\n        tooltip_span.addClass('ui-button-text');\n        tooltip_span.html(tooltip);\n\n        button.append(icon_img);\n        button.append(tooltip_span);\n\n        nav_element.append(button);\n    }\n\n    var fmt_picker_span = $('<span/>');\n\n    var fmt_picker = $('<select/>');\n    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n    fmt_picker_span.append(fmt_picker);\n    nav_element.append(fmt_picker_span);\n    this.format_dropdown = fmt_picker[0];\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = $(\n            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n        fmt_picker.append(option);\n    }\n\n    // Add hover states to the ui-buttons\n    $( \".ui-button\" ).hover(\n        function() { $(this).addClass(\"ui-state-hover\");},\n        function() { $(this).removeClass(\"ui-state-hover\");}\n    );\n\n    var status_bar = $('<span class=\"mpl-message\"/>');\n    nav_element.append(status_bar);\n    this.message = status_bar[0];\n}\n\nmpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n}\n\nmpl.figure.prototype.send_message = function(type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n}\n\nmpl.figure.prototype.send_draw_message = function() {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n    }\n}\n\n\nmpl.figure.prototype.handle_save = function(fig, msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n}\n\n\nmpl.figure.prototype.handle_resize = function(fig, msg) {\n    var size = msg['size'];\n    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1]);\n        fig.send_message(\"refresh\", {});\n    };\n}\n\nmpl.figure.prototype.handle_rubberband = function(fig, msg) {\n    var x0 = msg['x0'] / mpl.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n    var x1 = msg['x1'] / mpl.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0, 0, fig.canvas.width, fig.canvas.height);\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n}\n\nmpl.figure.prototype.handle_figure_label = function(fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n}\n\nmpl.figure.prototype.handle_cursor = function(fig, msg) {\n    var cursor = msg['cursor'];\n    switch(cursor)\n    {\n    case 0:\n        cursor = 'pointer';\n        break;\n    case 1:\n        cursor = 'default';\n        break;\n    case 2:\n        cursor = 'crosshair';\n        break;\n    case 3:\n        cursor = 'move';\n        break;\n    }\n    fig.rubberband_canvas.style.cursor = cursor;\n}\n\nmpl.figure.prototype.handle_message = function(fig, msg) {\n    fig.message.textContent = msg['message'];\n}\n\nmpl.figure.prototype.handle_draw = function(fig, msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n}\n\nmpl.figure.prototype.handle_image_mode = function(fig, msg) {\n    fig.image_mode = msg['mode'];\n}\n\nmpl.figure.prototype.updated_canvas_event = function() {\n    // Called whenever the canvas gets updated.\n    this.send_message(\"ack\", {});\n}\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function(fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            /* FIXME: We get \"Resource interpreted as Image but\n             * transferred with MIME type text/plain:\" errors on\n             * Chrome.  But how to set the MIME type?  It doesn't seem\n             * to be part of the websocket stream */\n            evt.data.type = \"image/png\";\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src);\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                evt.data);\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig[\"handle_\" + msg_type];\n        } catch (e) {\n            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n            }\n        }\n    };\n}\n\n// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\nmpl.findpos = function(e) {\n    //this section is from http://www.quirksmode.org/js/events_properties.html\n    var targ;\n    if (!e)\n        e = window.event;\n    if (e.target)\n        targ = e.target;\n    else if (e.srcElement)\n        targ = e.srcElement;\n    if (targ.nodeType == 3) // defeat Safari bug\n        targ = targ.parentNode;\n\n    // jQuery normalizes the pageX and pageY\n    // pageX,Y are the mouse positions relative to the document\n    // offset() returns the position of the element relative to the document\n    var x = e.pageX - $(targ).offset().left;\n    var y = e.pageY - $(targ).offset().top;\n\n    return {\"x\": x, \"y\": y};\n};\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * http://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys (original) {\n  return Object.keys(original).reduce(function (obj, key) {\n    if (typeof original[key] !== 'object')\n        obj[key] = original[key]\n    return obj;\n  }, {});\n}\n\nmpl.figure.prototype.mouse_event = function(event, name) {\n    var canvas_pos = mpl.findpos(event)\n\n    if (name === 'button_press')\n    {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    var x = canvas_pos.x * mpl.ratio;\n    var y = canvas_pos.y * mpl.ratio;\n\n    this.send_message(name, {x: x, y: y, button: event.button,\n                             step: event.step,\n                             guiEvent: simpleKeys(event)});\n\n    /* This prevents the web browser from automatically changing to\n     * the text insertion cursor when the button is pressed.  We want\n     * to control all of the cursor setting manually through the\n     * 'cursor' event from matplotlib */\n    event.preventDefault();\n    return false;\n}\n\nmpl.figure.prototype._key_event_extra = function(event, name) {\n    // Handle any extra behaviour associated with a key event\n}\n\nmpl.figure.prototype.key_event = function(event, name) {\n\n    // Prevent repeat events\n    if (name == 'key_press')\n    {\n        if (event.which === this._key)\n            return;\n        else\n            this._key = event.which;\n    }\n    if (name == 'key_release')\n        this._key = null;\n\n    var value = '';\n    if (event.ctrlKey && event.which != 17)\n        value += \"ctrl+\";\n    if (event.altKey && event.which != 18)\n        value += \"alt+\";\n    if (event.shiftKey && event.which != 16)\n        value += \"shift+\";\n\n    value += 'k';\n    value += event.which.toString();\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, {key: value,\n                             guiEvent: simpleKeys(event)});\n    return false;\n}\n\nmpl.figure.prototype.toolbar_button_onclick = function(name) {\n    if (name == 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message(\"toolbar_button\", {name: name});\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n    this.message.textContent = tooltip;\n};\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n\nmpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.close = function() {\n        comm.close()\n    };\n    ws.send = function(m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function(msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(msg['content']['data'])\n    });\n    return ws;\n}\n\nmpl.mpl_figure_comm = function(comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = $(\"#\" + id);\n    var ws_proxy = comm_websocket_adapter(comm)\n\n    function ondownload(figure, format) {\n        window.open(figure.imageObj.src);\n    }\n\n    var fig = new mpl.figure(id, ws_proxy,\n                           ondownload,\n                           element.get(0));\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element.get(0);\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error(\"Failed to find cell for figure\", id, fig);\n        return;\n    }\n\n    var output_index = fig.cell_info[2]\n    var cell = fig.cell_info[0];\n\n};\n\nmpl.figure.prototype.handle_close = function(fig, msg) {\n    var width = fig.canvas.width/mpl.ratio\n    fig.root.unbind('remove')\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable()\n    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n    fig.close_ws(fig, msg);\n}\n\nmpl.figure.prototype.close_ws = function(fig, msg){\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n}\n\nmpl.figure.prototype.push_to_output = function(remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width/mpl.ratio\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n}\n\nmpl.figure.prototype.updated_canvas_event = function() {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message(\"ack\", {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () { fig.push_to_output() }, 1000);\n}\n\nmpl.figure.prototype._init_toolbar = function() {\n    var fig = this;\n\n    var nav_element = $('<div/>');\n    nav_element.attr('style', 'width: 100%');\n    this.root.append(nav_element);\n\n    // Define a callback function for later on.\n    function toolbar_event(event) {\n        return fig.toolbar_button_onclick(event['data']);\n    }\n    function toolbar_mouse_event(event) {\n        return fig.toolbar_button_onmouseover(event['data']);\n    }\n\n    for(var toolbar_ind in mpl.toolbar_items){\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) { continue; };\n\n        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n        button.click(method_name, toolbar_event);\n        button.mouseover(tooltip, toolbar_mouse_event);\n        nav_element.append(button);\n    }\n\n    // Add the status bar.\n    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n    nav_element.append(status_bar);\n    this.message = status_bar[0];\n\n    // Add the close button to the window.\n    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n    button.click(function (evt) { fig.handle_close(fig, {}); } );\n    button.mouseover('Stop Interaction', toolbar_mouse_event);\n    buttongrp.append(button);\n    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n    titlebar.prepend(buttongrp);\n}\n\nmpl.figure.prototype._root_extra_style = function(el){\n    var fig = this\n    el.on(\"remove\", function(){\n\tfig.close_ws(fig, {});\n    });\n}\n\nmpl.figure.prototype._canvas_extra_style = function(el){\n    // this is important to make the div 'focusable\n    el.attr('tabindex', 0)\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    }\n    else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n\n}\n\nmpl.figure.prototype._key_event_extra = function(event, name) {\n    var manager = IPython.notebook.keyboard_manager;\n    if (!manager)\n        manager = IPython.keyboard_manager;\n\n    // Check for shift+enter\n    if (event.shiftKey && event.which == 13) {\n        this.canvas_div.blur();\n        event.shiftKey = false;\n        // Send a \"J\" for go to next cell\n        event.which = 74;\n        event.keyCode = 74;\n        manager.command_mode();\n        manager.handle_keydown(event);\n    }\n}\n\nmpl.figure.prototype.handle_save = function(fig, msg) {\n    fig.ondownload(fig, null);\n}\n\n\nmpl.find_output_cell = function(html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i=0; i<ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code'){\n            for (var j=0; j<cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] == html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n}\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel != null) {\n    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='8cea0b0d-7a72-427b-bc1c-b41f77a667a0'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008440115198027343\n"
     ]
    }
   ],
   "source": [
    "uce, err_in_bin, avg_uncert_in_bin, freq_in_bin = uceloss(err_calib**2, aux(uncert_calib)**2, n_bins=n_bins)\n",
    "plot_uncert(err_in_bin.cpu(), avg_uncert_in_bin.cpu())\n",
    "plt.show()\n",
    "print(uce.item()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [01:42<00:00,  1.89s/it]\n",
      "100%|██████████| 54/54 [01:35<00:00,  1.77s/it]\n",
      "100%|██████████| 54/54 [01:35<00:00,  1.76s/it]\n",
      "100%|██████████| 54/54 [01:35<00:00,  1.76s/it]\n",
      "100%|██████████| 54/54 [01:35<00:00,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "y_p_test_list = []\n",
    "mu_test_list = []\n",
    "var_test_list = []\n",
    "logvars_test_list = []\n",
    "logvar_test_list = []\n",
    "target_test_list = []\n",
    "\n",
    "for i in range(5):\n",
    "    y_p_test = []\n",
    "    mus_test = []\n",
    "    vars_test = []\n",
    "    logvars_test = []\n",
    "    targets_test = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(test_loader)):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            y_p, logvar, var_bayesian = model(data, dropout=True, mc_dropout=True, test=True)\n",
    "\n",
    "            y_p_test.append(y_p.detach())\n",
    "            vars_test.append(var_bayesian.detach())\n",
    "            logvars_test.append(logvar.detach())\n",
    "            targets_test.append(target.detach())\n",
    "\n",
    "        y_p_test = torch.cat(y_p_test, dim=1).clamp(0, 1).permute(1,0,2)\n",
    "        mu_test = y_p_test.mean(dim=1)\n",
    "        var_test = torch.cat(vars_test, dim=0)\n",
    "        logvars_test = torch.cat(logvars_test, dim=1).permute(1,0,2)\n",
    "        logvar_test = logvars_test.mean(dim=1)\n",
    "        target_test = torch.cat(targets_test, dim=0)\n",
    "\n",
    "        y_p_test_list.append(y_p_test)\n",
    "        mu_test_list.append(mu_test)\n",
    "        var_test_list.append(var_test)\n",
    "        logvars_test_list.append(logvars_test)\n",
    "        logvar_test_list.append(logvar_test)\n",
    "        target_test_list.append(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_test = [(target_test-mu_test).pow(2).mean(dim=1, keepdim=True).sqrt() for target_test, mu_test in zip(target_test_list, mu_test_list)]\n",
    "errvar_test = [(y_p_test-target_test.unsqueeze(1).repeat(1,25,1)).pow(2).mean(dim=(1,2)).unsqueeze(-1) for target_test, y_p_test in zip(target_test_list, y_p_test_list)]\n",
    "\n",
    "uncert_aleatoric_test = [logvar_test.exp().mean(dim=1, keepdim=True) for logvar_test in logvar_test_list]\n",
    "uncert_epistemic_test = [var_test.mean(dim=1, keepdim=True) for var_test in var_test_list]\n",
    "\n",
    "if uncertainty == 'aleatoric':\n",
    "    uncert_test = [uncert_aleatoric_t.sqrt().clamp(0, 1) for uncert_aleatoric_t in uncert_aleatoric_test]\n",
    "    uncert_test_laves = [(u_a_t + u_e_t).sqrt().clamp(0, 1) for u_a_t, u_e_t in zip(uncert_aleatoric_test, uncert_epistemic_test)]\n",
    "elif uncertainty == 'epistemic':\n",
    "    uncert_test = [uncert_epistemic_t.sqrt().clamp(0, 1) for uncert_epistemic_t in uncert_epistemic_test]\n",
    "else:\n",
    "    uncert_test = [(u_a_t + u_e_t).sqrt().clamp(0, 1) for u_a_t, u_e_t in zip(uncert_aleatoric_test, uncert_epistemic_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calc_optimal_q(target_calib, mu_calib, uncert_calib, alpha=0.1, gc=False, single=True):\n",
    "\n",
    "    if single:\n",
    "        s_t = torch.abs(target_calib-mu_calib)[:, 0].unsqueeze(-1) / uncert_calib\n",
    "    else:\n",
    "        s_t = torch.abs(target_calib-mu_calib) / uncert_calib\n",
    "    if gc:\n",
    "        # q = 1.64485 * torch.sqrt((s_t**2).mean()).item()\n",
    "        q = 1.64485 * s_t.median().item()\n",
    "    else:\n",
    "        s_t_sorted, _ = torch.sort(s_t, dim=0)\n",
    "        # q_index = math.ceil((len(s_t_sorted) + 1) * (1 - alpha))\n",
    "        q_index = math.ceil((len(s_t_sorted)) * (1 - alpha))\n",
    "        q = s_t_sorted[q_index].item()\n",
    "        # q = torch.quantile(s_t, (1 - alpha))\n",
    "    \n",
    "    return q\n",
    "\n",
    "q = calc_optimal_q(target_calib, mu_calib, uncert_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save_path = 'C:/lior/studies/master/projects/calibration/regression calibration/well-calibrated-regression-uncertainty/var_and_mse_calib/'\n",
    "save_path = 'C:/lior/studies/master/projects/calibration/regression calibration/regression_calibration/reports/var_and_mse_calib/'\n",
    "with open(save_path + f'{base_model}_gaussian_oct_new_conformal.pickle', 'wb') as handle:\n",
    "    pickle.dump({'mu': [mu_calib, mu_test_list],\n",
    "                 'target': [target_calib, target_test_list],\n",
    "                 'err': [err_calib, err_test], \n",
    "                 'uncert': [uncert_calib, uncert_test, uncert_calib_laves, uncert_test_laves],\n",
    "                 's': S,\n",
    "                 'q': q}\n",
    "                , handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "save_path = 'C:/lior/studies/master/projects/calibration/regression calibration/regression_calibration/reports/var_and_mse_calib/'\n",
    "# with open(save_path + f'{base_model}_gaussian_boneage_best_freeze_lr_3e-05_nll.pickle', 'rb') as handle:\n",
    "# with open(save_path + f'{base_model}_gaussian_boneage_493_conformal.pickle', 'rb') as handle:\n",
    "with open(save_path + f'{base_model}_gaussian_oct_new_conformal.pickle', 'rb') as handle:\n",
    "    calib_dict = pickle.load(handle)\n",
    "    err_calib = calib_dict['err'][0]\n",
    "    err_test = calib_dict['err'][1]\n",
    "    uncert_calib = calib_dict['uncert'][0]\n",
    "    uncert_test = calib_dict['uncert'][1]\n",
    "    uncert_calib_laves = calib_dict['uncert'][2]\n",
    "    uncert_test_laves = calib_dict['uncert'][3]\n",
    "    mu_calib = calib_dict['mu'][0]\n",
    "    mu_test_list = calib_dict['mu'][1]\n",
    "    target_calib = calib_dict['target'][0]\n",
    "    target_test_list = calib_dict['target'][1]\n",
    "    q = calib_dict['q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0253, device='cuda:0')\n",
      "tensor(0.7707, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "calib = ((target_calib - mu_calib) / uncert_calib)\n",
    "print(torch.mean(calib))\n",
    "print(torch.std(calib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.918609579746589e-10\n",
      "1.4174268374513583e-60\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "calib = [calib_s.item() for calib_s in list(calib.mean(-1).squeeze())]\n",
    "\n",
    "res = stats.normaltest(calib)\n",
    "res2 = stats.kstest(calib, cdf=stats.norm.cdf)\n",
    "\n",
    "print(res.pvalue)\n",
    "print(res2.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "save_path = 'C:/lior/studies/master/projects/calibration/regression calibration/well-calibrated-regression-uncertainty/var_and_mse_calib/'\n",
    "with open(save_path + f'{base_model}_gaussian_oct_best_freeze_lr_0.0003_nll.pickle', 'rb') as handle:\n",
    "    calib_dict = pickle.load(handle)\n",
    "    err_calib = calib_dict['err'][0]\n",
    "    err_test = calib_dict['err'][1]\n",
    "    uncert_calib = calib_dict['uncert'][0]\n",
    "    uncert_test = calib_dict['uncert'][1]\n",
    "    uncert_calib_laves = calib_dict['uncert'][2]\n",
    "    uncert_test_laves = calib_dict['uncert'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0014, device='cuda:1')\n",
      "tensor(0.0016, device='cuda:1')\n",
      "tensor(0.0002, device='cuda:1')\n",
      "\n",
      "tensor(0.0014, device='cuda:1')\n",
      "tensor(0.0016, device='cuda:1')\n",
      "tensor(0.0002, device='cuda:1')\n",
      "\n",
      "tensor(0.0014, device='cuda:1')\n",
      "tensor(0.0016, device='cuda:1')\n",
      "tensor(0.0002, device='cuda:1')\n",
      "\n",
      "tensor(0.0014, device='cuda:1')\n",
      "tensor(0.0016, device='cuda:1')\n",
      "tensor(0.0002, device='cuda:1')\n",
      "\n",
      "tensor(0.0014, device='cuda:1')\n",
      "tensor(0.0016, device='cuda:1')\n",
      "tensor(0.0002, device='cuda:1')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(err_test)):\n",
    "    print((err_test[i]**2).mean())\n",
    "    print(errvar_test[i].mean())\n",
    "    print((uncert_test[i]**2).mean())\n",
    "    print()\n",
    "\n",
    "#err_test = [errvar.sqrt() for errvar in errvar_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.7315411567687988\n",
      "-5.575181484222412\n",
      "-5.575181484222412\n",
      "-5.577203273773193\n",
      "\n",
      "-1.7305828332901\n",
      "-5.576295852661133\n",
      "-5.576295852661133\n",
      "-5.578205108642578\n",
      "\n",
      "-1.719127893447876\n",
      "-5.573840618133545\n",
      "-5.573840618133545\n",
      "-5.575546741485596\n",
      "\n",
      "-1.7019404172897339\n",
      "-5.571837425231934\n",
      "-5.571837425231934\n",
      "-5.573824405670166\n",
      "\n",
      "-1.7118245363235474\n",
      "-5.571545124053955\n",
      "-5.571545124053955\n",
      "-5.573381423950195\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AuxModel(\n",
       "  (linear1): Linear(in_features=1, out_features=16, bias=True)\n",
       "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux.train()\n",
    "for i in range(len(mu_test_list)):\n",
    "    print(nll_criterion_gaussian(mu_test_list[i], uncert_test[i].pow(2).log(), target_test_list[i]).item())\n",
    "    print(nll_criterion_gaussian(mu_test_list[i], (S*uncert_test[i]).pow(2).log(), target_test_list[i]).item())\n",
    "    print(nll_criterion_gaussian(mu_test_list[i], scaler(uncert_test[i]).pow(2).log(), target_test_list[i]).item())\n",
    "    print(nll_criterion_gaussian(mu_test_list[i], aux(uncert_test[i]), target_test_list[i]).item())\n",
    "    print()\n",
    "aux.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0021998360753059387\n",
      "0.0010134568437933922\n",
      "0.0010134568437933922\n",
      "0.001003417419269681\n",
      "\n",
      "0.002199190203100443\n",
      "0.0010135209886357188\n",
      "0.0010135209886357188\n",
      "0.001004102872684598\n",
      "\n",
      "0.0021977326832711697\n",
      "0.0009997253073379397\n",
      "0.0009997253073379397\n",
      "0.0009912129025906324\n",
      "\n",
      "0.0022080745548009872\n",
      "0.001008693128824234\n",
      "0.001008693128824234\n",
      "0.0009996322914958\n",
      "\n",
      "0.0022122515365481377\n",
      "0.0010095217730849981\n",
      "0.0010095217730849981\n",
      "0.0010007396340370178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(mu_test_list)):\n",
    "    print(torch.nn.functional.mse_loss(uncert_test[i]**2, err_test[i]**2, reduction='sum').item())\n",
    "    print(torch.nn.functional.mse_loss((S*uncert_test[i])**2, err_test[i]**2, reduction='sum').item())\n",
    "    print(torch.nn.functional.mse_loss(scaler(uncert_test[i])**2, err_test[i]**2, reduction='sum').item())\n",
    "    print(torch.nn.functional.mse_loss(aux(uncert_test[i])**2, err_test[i]**2, reduction='sum').item())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histedges_equalN(x, n_bins=15):\n",
    "    npt = len(x)\n",
    "    return np.interp(np.linspace(0, npt, n_bins + 1),\n",
    "                    np.arange(npt),\n",
    "                    np.sort(x))\n",
    "\n",
    "def set_scaler(err_calib, uncert_calib, cross_validate='uce',\n",
    "                     init_temp=2.5, log=True, num_bins=15, outlier=0.0):\n",
    "    \"\"\"\n",
    "    Tune single scaler for the model (using the validation set) with cross-validation on NLL\n",
    "    \"\"\"\n",
    "    # Calculate ECE before temperature scaling\n",
    "    nll_criterion = nn.CrossEntropyLoss().cuda()\n",
    "    before_scaling_uce = uceloss(err_calib**2, uncert_calib**2, single=True)\n",
    "    if log:\n",
    "        print('Before scaling - UCE: %.3f' % (before_scaling_uce * 100))\n",
    "        \n",
    "    # calculate optimal S\n",
    "    S = (err_calib**2 / uncert_calib**2).mean().sqrt()\n",
    "            \n",
    "    n_bins = num_bins\n",
    "    eps = 1e-5\n",
    "    nll_val = 10 ** 7\n",
    "    buce_val = 10 ** 7\n",
    "        \n",
    "    # Calculate UCE after single scaling\n",
    "    after_single_scaling_uce = uceloss(err_calib**2, (S * uncert_calib)**2, single=True)\n",
    "    if log:\n",
    "        print('Optimal scaler: %.3f' % S)\n",
    "        print('After single scaling- UCE: %.3f' % (after_single_scaling_uce * 100))\n",
    "    \n",
    "    init_scaler = 1.0\n",
    "    \n",
    "    bins_T = init_scaler*torch.ones(n_bins).cuda()\n",
    "    uce_list = []\n",
    "    uce_list.append(after_single_scaling_uce)\n",
    "                    \n",
    "    ece_ada_list = []\n",
    "    count_high_acc = 0\n",
    "    is_acc = False\n",
    "    n, bin_boundaries = np.histogram(uncert_calib.squeeze(-1).cpu().detach(), histedges_equalN(uncert_calib.squeeze(-1).cpu().detach(), n_bins=n_bins))\n",
    "    print(bin_boundaries)\n",
    "\n",
    "\n",
    "    if cross_validate == 'uce':\n",
    "        T_opt_buce = init_temp*torch.ones(uncert_calib.shape[0]).cuda()\n",
    "        T_buce = init_temp*torch.ones(uncert_calib.shape[0]).cuda()\n",
    "        buce_temperature = T_buce\n",
    "    else:\n",
    "        T_opt_nll = init_temp*torch.ones(uncert_calib.shape[0]).cuda()\n",
    "        T_nll = init_temp*torch.ones(uncert_calib.shape[0]).cuda()\n",
    "        nll_temperature = T_nll\n",
    "    \n",
    "    bin = 0\n",
    "    \n",
    "    # bin_boundaries = torch.linspace(uncert_calib.min().item(), uncert_calib.max().item(), n_bins + 1, device=device)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = uncert_calib.gt(bin_lower.item()) * uncert_calib.le(bin_upper.item())\n",
    "        prop_in_bin = in_bin.float().mean()  # |Bm| / n\n",
    "        if prop_in_bin.item() > outlier:        \n",
    "            if cross_validate == 'uce':\n",
    "                errors_in_bin = (err_calib[in_bin]**2).float().mean()  # err()\n",
    "                avg_uncert_in_bin = (uncert_calib[in_bin]**2).mean()  # uncert()\n",
    "                S_bin = (errors_in_bin / avg_uncert_in_bin).sqrt()\n",
    "                bins_T[bin] = S_bin\n",
    "                avg_uncert_in_bin = ((S_bin * uncert_calib[in_bin])**2).mean()  # uncert() after calib\n",
    "                buce_val = torch.abs(avg_uncert_in_bin - errors_in_bin)\n",
    "            else:\n",
    "                S_bin = (err_calib[in_bin]**2 / uncert_calib[in_bin]**2).mean().sqrt()\n",
    "                bins_T[bin] = S_bin\n",
    "                errors_in_bin = (err_calib[in_bin]**2).float().mean()  # err()\n",
    "                avg_uncert_in_bin = ((S_bin * uncert_calib[in_bin])**2).mean()  # uncert()\n",
    "                buce_val = torch.abs(avg_uncert_in_bin - errors_in_bin)\n",
    "                                    \n",
    "            samples = uncert_calib[in_bin].shape[0]\n",
    "            print('uce in bin ', bin+1, ' :', (prop_in_bin * buce_val).item(), ', number of samples: ', samples)\n",
    "\n",
    "        bin += 1\n",
    "\n",
    "    print(bins_T)\n",
    "    uncert_calib_after = uncert_calib.clone()\n",
    "    for inx, (bin_lower, bin_upper) in enumerate(zip(bin_lowers, bin_uppers)):\n",
    "        in_bin = uncert_calib.gt(bin_lower.item()) * uncert_calib.le(bin_upper.item())\n",
    "        uncert_calib_after[in_bin] = bins_T[inx] * uncert_calib[in_bin]\n",
    "    current_uce = uceloss(err_calib**2, uncert_calib_after**2, single=True)\n",
    "    print(f'After bins scaling by {cross_validate} - UCE:', current_uce.item() * 100)\n",
    "\n",
    "    return bins_T, S, bin_boundaries, current_uce.item()\n",
    "\n",
    "def scale_bins(err_test, uncert_test, bins_T, bin_boundaries, num_bins=15):\n",
    "    uncert_test_after = uncert_test.clone()\n",
    "    \n",
    "    # bin_boundaries = torch.linspace(uncert_test.min().item(), uncert_test.max().item(), n_bins + 1, device=device)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    \n",
    "    bin = 0\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = uncert_test.gt(bin_lower.item()) * uncert_test.le(bin_upper.item())\n",
    "        if any(in_bin):\n",
    "            uncert_test_after[in_bin] = bins_T[bin] * uncert_test[in_bin]\n",
    "        bin += 1\n",
    "    uce = uceloss(err_test**2, uncert_test_after**2, single=True)\n",
    "    \n",
    "    return uce, uncert_test_after\n",
    "\n",
    "def enceloss(errors, uncert, n_bins=15, outlier=0.0, range=None, single=None):\n",
    "    device = errors.device\n",
    "    if range == None:\n",
    "        bin_boundaries = torch.linspace(uncert.min().item(), uncert.max().item(), n_bins + 1, device=device)\n",
    "    else:\n",
    "        bin_boundaries = torch.linspace(range[0], range[1], n_bins + 1, device=device)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    errors_in_bin_list = []\n",
    "    avg_uncert_in_bin_list = []\n",
    "    ence_per_bin = []\n",
    "\n",
    "    ence = torch.zeros(1, device=device)\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        # Calculated |RMV - RMSE| / RMV in each bin\n",
    "        in_bin = uncert.gt(bin_lower.item()) * uncert.le(bin_upper.item())\n",
    "        prop_in_bin = in_bin.float().mean() \n",
    "        if prop_in_bin.item() > outlier:\n",
    "            errors_in_bin = errors[in_bin].float().mean().sqrt()  # RMV()\n",
    "            avg_uncert_in_bin = uncert[in_bin].mean().sqrt()  # RMSE()\n",
    "            ence_in_bin = torch.abs(avg_uncert_in_bin - errors_in_bin) / errors_in_bin\n",
    "            ence_per_bin.append(ence_in_bin)\n",
    "            ence += ence_in_bin\n",
    "\n",
    "            errors_in_bin_list.append(errors_in_bin)\n",
    "            avg_uncert_in_bin_list.append(avg_uncert_in_bin)\n",
    "\n",
    "    err_in_bin = torch.tensor(errors_in_bin_list, device=device)\n",
    "    avg_uncert_in_bin = torch.tensor(avg_uncert_in_bin_list, device=device)\n",
    "\n",
    "    if single:\n",
    "        return ence.mean()\n",
    "    else:\n",
    "        return ence.mean(), err_in_bin, avg_uncert_in_bin, ence_per_bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03974266 0.04148997 0.0431485  0.04510581 0.05490025]\n",
      "uce in bin  1  : 2.3283062977608182e-11 , number of samples:  170\n",
      "uce in bin  2  : 2.3283062977608182e-11 , number of samples:  170\n",
      "uce in bin  3  : 0.0 , number of samples:  170\n",
      "uce in bin  4  : 2.3283062977608182e-11 , number of samples:  170\n",
      "uce in bin  5  : 0.0 , number of samples:  169\n",
      "tensor([0.9057, 0.8973, 0.8350, 0.8441, 0.8532], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.0073337585490662605\n",
      "5 bins with tensor([7.0100e-05], device='cuda:0') UCE\n",
      "5 bins with 2.9301822185516357 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.0393443  0.04102954 0.04220093 0.04364066 0.04584211\n",
      " 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  141\n",
      "uce in bin  2  : 0.0 , number of samples:  142\n",
      "uce in bin  3  : 1.9448205199057433e-11 , number of samples:  142\n",
      "uce in bin  4  : 1.931124704590559e-11 , number of samples:  141\n",
      "uce in bin  5  : 3.889641039811487e-11 , number of samples:  142\n",
      "uce in bin  6  : 3.862249409181118e-11 , number of samples:  141\n",
      "tensor([0.9153, 0.9041, 0.8477, 0.8476, 0.8638, 0.8295], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.004964306936017238\n",
      "6 bins with tensor([7.3429e-05], device='cuda:0') UCE\n",
      "6 bins with 3.1743106842041016 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03901603 0.04061612 0.04164109 0.04291208 0.04410909\n",
      " 0.04611907 0.05490025]\n",
      "uce in bin  1  : 1.657206316618698e-11 , number of samples:  121\n",
      "uce in bin  2  : 3.314412633237396e-11 , number of samples:  121\n",
      "uce in bin  3  : 0.0 , number of samples:  122\n",
      "uce in bin  4  : 0.0 , number of samples:  121\n",
      "uce in bin  5  : 0.0 , number of samples:  122\n",
      "uce in bin  6  : 1.657206316618698e-11 , number of samples:  121\n",
      "uce in bin  7  : 3.314412633237396e-11 , number of samples:  121\n",
      "tensor([0.9077, 0.9140, 0.8630, 0.8396, 0.8586, 0.8755, 0.8168],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.004389879904920235\n",
      "7 bins with tensor([6.5578e-05], device='cuda:0') UCE\n",
      "7 bins with 2.9675819873809814 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03877927 0.04027902 0.04132751 0.04220093 0.04336798\n",
      " 0.04446644 0.04642986 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  106\n",
      "uce in bin  2  : 1.4517675256398022e-11 , number of samples:  106\n",
      "uce in bin  3  : 0.0 , number of samples:  106\n",
      "uce in bin  4  : 1.4654633409549866e-11 , number of samples:  107\n",
      "uce in bin  5  : 1.4517675256398022e-11 , number of samples:  106\n",
      "uce in bin  6  : 0.0 , number of samples:  106\n",
      "uce in bin  7  : 1.4517675256398022e-11 , number of samples:  106\n",
      "uce in bin  8  : 1.4517675256398022e-11 , number of samples:  106\n",
      "tensor([0.9195, 0.9258, 0.8544, 0.8571, 0.8415, 0.8584, 0.8905, 0.7986],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.009560416219756007\n",
      "8 bins with tensor([5.7823e-05], device='cuda:0') UCE\n",
      "8 bins with 3.109689235687256 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03853986 0.04001301 0.04102954 0.04178748 0.04280239\n",
      " 0.04364066 0.04477942 0.04667186 0.05490025]\n",
      "uce in bin  1  : 1.2874164408149813e-11 , number of samples:  94\n",
      "uce in bin  2  : 0.0 , number of samples:  94\n",
      "uce in bin  3  : 1.3011123428663396e-11 , number of samples:  95\n",
      "uce in bin  4  : 0.0 , number of samples:  94\n",
      "uce in bin  5  : 1.3011123428663396e-11 , number of samples:  95\n",
      "uce in bin  6  : 0.0 , number of samples:  94\n",
      "uce in bin  7  : 0.0 , number of samples:  95\n",
      "uce in bin  8  : 0.0 , number of samples:  94\n",
      "uce in bin  9  : 2.5748328816299626e-11 , number of samples:  94\n",
      "tensor([0.9195, 0.9274, 0.8836, 0.8559, 0.8366, 0.8505, 0.8503, 0.8897, 0.8007],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.009096165740629658\n",
      "9 bins with tensor([7.6277e-05], device='cuda:0') UCE\n",
      "9 bins with 3.154799222946167 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03843282 0.03974266 0.04070082 0.04148997 0.04220093\n",
      " 0.0431485  0.04398953 0.04510581 0.04691925 0.05490025]\n",
      "uce in bin  1  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  2  : 0.0 , number of samples:  85\n",
      "uce in bin  3  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  4  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  5  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  6  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  7  : 2.3283062977608182e-11 , number of samples:  85\n",
      "uce in bin  8  : 0.0 , number of samples:  85\n",
      "uce in bin  9  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  10  : 1.1504572468290508e-11 , number of samples:  84\n",
      "tensor([0.9339, 0.8803, 0.9149, 0.8801, 0.8366, 0.8335, 0.8773, 0.8111, 0.9079,\n",
      "        0.8009], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005077945388620719\n",
      "10 bins with tensor([6.3425e-05], device='cuda:0') UCE\n",
      "10 bins with 2.92940092086792 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03827366 0.0395275  0.04045991 0.0412123  0.04187584\n",
      " 0.04266999 0.04343626 0.04433504 0.04554641 0.04714209 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  77\n",
      "uce in bin  2  : 1.054585845733369e-11 , number of samples:  77\n",
      "uce in bin  3  : 0.0 , number of samples:  77\n",
      "uce in bin  4  : 1.0819776498360856e-11 , number of samples:  79\n",
      "uce in bin  5  : 1.0408898569458369e-11 , number of samples:  76\n",
      "uce in bin  6  : 1.054585845733369e-11 , number of samples:  77\n",
      "uce in bin  7  : 1.054585845733369e-11 , number of samples:  77\n",
      "uce in bin  8  : 1.0682817477847273e-11 , number of samples:  78\n",
      "uce in bin  9  : 0.0 , number of samples:  77\n",
      "uce in bin  10  : 2.109171691466738e-11 , number of samples:  77\n",
      "uce in bin  11  : 0.0 , number of samples:  77\n",
      "tensor([0.9365, 0.8733, 0.9352, 0.8739, 0.8635, 0.8390, 0.8264, 0.8621, 0.8313,\n",
      "        0.9134, 0.7909], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.007587010622955859\n",
      "11 bins with tensor([9.5405e-05], device='cuda:0') UCE\n",
      "11 bins with 2.9200949668884277 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03811063 0.0393443  0.04027902 0.04102954 0.04157097\n",
      " 0.04220093 0.04299221 0.04364066 0.04446644 0.04584211 0.04726971\n",
      " 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  70\n",
      "uce in bin  2  : 0.0 , number of samples:  71\n",
      "uce in bin  3  : 1.9448205199057433e-11 , number of samples:  71\n",
      "uce in bin  4  : 9.724102599528717e-12 , number of samples:  71\n",
      "uce in bin  5  : 1.9448205199057433e-11 , number of samples:  71\n",
      "uce in bin  6  : 0.0 , number of samples:  71\n",
      "uce in bin  7  : 1.9174287158030268e-11 , number of samples:  70\n",
      "uce in bin  8  : 0.0 , number of samples:  71\n",
      "uce in bin  9  : 0.0 , number of samples:  71\n",
      "uce in bin  10  : 1.9448205199057433e-11 , number of samples:  71\n",
      "uce in bin  11  : 9.724102599528717e-12 , number of samples:  71\n",
      "uce in bin  12  : 9.587143579015134e-12 , number of samples:  70\n",
      "tensor([0.9453, 0.8885, 0.9360, 0.8724, 0.8566, 0.8390, 0.8165, 0.8762, 0.8551,\n",
      "        0.8720, 0.8738, 0.7874], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.0074315088568255305\n",
      "12 bins with tensor([5.0438e-05], device='cuda:0') UCE\n",
      "12 bins with 2.789762258529663 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03788432 0.03915853 0.04011369 0.04076396 0.04139863\n",
      " 0.04190108 0.04262602 0.04329034 0.04386971 0.0446565  0.04599188\n",
      " 0.04745675 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  65\n",
      "uce in bin  2  : 8.902347609085481e-12 , number of samples:  65\n",
      "uce in bin  3  : 0.0 , number of samples:  66\n",
      "uce in bin  4  : 8.902347609085481e-12 , number of samples:  65\n",
      "uce in bin  5  : 0.0 , number of samples:  65\n",
      "uce in bin  6  : 0.0 , number of samples:  66\n",
      "uce in bin  7  : 1.7804695218170963e-11 , number of samples:  65\n",
      "uce in bin  8  : 0.0 , number of samples:  66\n",
      "uce in bin  9  : 0.0 , number of samples:  65\n",
      "uce in bin  10  : 1.7804695218170963e-11 , number of samples:  65\n",
      "uce in bin  11  : 0.0 , number of samples:  66\n",
      "uce in bin  12  : 8.902347609085481e-12 , number of samples:  65\n",
      "uce in bin  13  : 8.902347609085481e-12 , number of samples:  65\n",
      "tensor([0.9434, 0.8920, 0.9465, 0.8599, 0.8560, 0.8574, 0.8504, 0.8371, 0.8554,\n",
      "        0.8603, 0.8628, 0.8841, 0.7820], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.007287979678949341\n",
      "13 bins with tensor([8.2056e-05], device='cuda:0') UCE\n",
      "13 bins with 3.136815071105957 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03771835 0.03901603 0.03988922 0.04061612 0.04117621\n",
      " 0.04164109 0.04220093 0.04291208 0.04347522 0.04410909 0.04487395\n",
      " 0.04611907 0.04760478 0.05490025]\n",
      "uce in bin  1  : 8.217551639155829e-12 , number of samples:  60\n",
      "uce in bin  2  : 0.0 , number of samples:  61\n",
      "uce in bin  3  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  4  : 8.217551639155829e-12 , number of samples:  60\n",
      "uce in bin  5  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  6  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  7  : 0.0 , number of samples:  61\n",
      "uce in bin  8  : 1.6435103278311658e-11 , number of samples:  60\n",
      "uce in bin  9  : 0.0 , number of samples:  61\n",
      "uce in bin  10  : 0.0 , number of samples:  61\n",
      "uce in bin  11  : 8.217551639155829e-12 , number of samples:  60\n",
      "uce in bin  12  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  13  : 1.6709021319338824e-11 , number of samples:  61\n",
      "uce in bin  14  : 1.6435103278311658e-11 , number of samples:  60\n",
      "tensor([0.9473, 0.8722, 0.9349, 0.8932, 0.8834, 0.8426, 0.8522, 0.8271, 0.8544,\n",
      "        0.8628, 0.8497, 0.8991, 0.8574, 0.7780], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005041862459620461\n",
      "14 bins with tensor([6.2087e-05], device='cuda:0') UCE\n",
      "14 bins with 2.8513453006744385 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03758804 0.03883939 0.03974266 0.04038315 0.04102954\n",
      " 0.04148997 0.04190926 0.04260738 0.0431485  0.04364066 0.04436997\n",
      " 0.04510581 0.0462356  0.04782094 0.05490025]\n",
      "uce in bin  1  : 1.533942937947952e-11 , number of samples:  56\n",
      "uce in bin  2  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  3  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  4  : 0.0 , number of samples:  56\n",
      "uce in bin  5  : 0.0 , number of samples:  57\n",
      "uce in bin  6  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  7  : 0.0 , number of samples:  56\n",
      "uce in bin  8  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  9  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  10  : 7.66971468973976e-12 , number of samples:  56\n",
      "uce in bin  11  : 0.0 , number of samples:  57\n",
      "uce in bin  12  : 0.0 , number of samples:  57\n",
      "uce in bin  13  : 1.533942937947952e-11 , number of samples:  56\n",
      "uce in bin  14  : 0.0 , number of samples:  57\n",
      "uce in bin  15  : 1.533942937947952e-11 , number of samples:  56\n",
      "tensor([0.9525, 0.8999, 0.8713, 0.9614, 0.8665, 0.8645, 0.8401, 0.8180, 0.8466,\n",
      "        0.8678, 0.8601, 0.8054, 0.9511, 0.8329, 0.7801], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005359812712413259\n",
      "15 bins with tensor([8.2696e-05], device='cuda:0') UCE\n",
      "15 bins with 3.2235119342803955 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03739283 0.03877927 0.03959142 0.04027902 0.04081613\n",
      " 0.04132751 0.04174127 0.04220093 0.0428364  0.04336798 0.04382173\n",
      " 0.04446644 0.04530898 0.04642986 0.04793808 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  53\n",
      "uce in bin  2  : 0.0 , number of samples:  53\n",
      "uce in bin  3  : 0.0 , number of samples:  53\n",
      "uce in bin  4  : 7.258837628199011e-12 , number of samples:  53\n",
      "uce in bin  5  : 0.0 , number of samples:  53\n",
      "uce in bin  6  : 0.0 , number of samples:  53\n",
      "uce in bin  7  : 0.0 , number of samples:  53\n",
      "uce in bin  8  : 0.0 , number of samples:  54\n",
      "uce in bin  9  : 0.0 , number of samples:  53\n",
      "uce in bin  10  : 1.4517675256398022e-11 , number of samples:  53\n",
      "uce in bin  11  : 7.258837628199011e-12 , number of samples:  53\n",
      "uce in bin  12  : 1.4517675256398022e-11 , number of samples:  53\n",
      "uce in bin  13  : 7.258837628199011e-12 , number of samples:  53\n",
      "uce in bin  14  : 0.0 , number of samples:  53\n",
      "uce in bin  15  : 1.4517675256398022e-11 , number of samples:  53\n",
      "uce in bin  16  : 7.258837628199011e-12 , number of samples:  53\n",
      "tensor([0.9667, 0.8759, 0.8596, 0.9853, 0.8535, 0.8552, 0.8919, 0.8222, 0.8298,\n",
      "        0.8527, 0.8562, 0.8605, 0.8042, 0.9657, 0.8229, 0.7761],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.00444475699623581\n",
      "16 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "16 bins with 3.1879825592041016 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03735686 0.0387038  0.03949024 0.04013795 0.0406526\n",
      " 0.04114018 0.0415368  0.04192781 0.04257943 0.0430803  0.04349529\n",
      " 0.04402716 0.04462811 0.04568613 0.04651846 0.0480996  0.05490025]\n",
      "uce in bin  1  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  2  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  3  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  4  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  5  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  6  : 0.0 , number of samples:  50\n",
      "uce in bin  7  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  8  : 0.0 , number of samples:  50\n",
      "uce in bin  9  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  10  : 0.0 , number of samples:  50\n",
      "uce in bin  11  : 0.0 , number of samples:  50\n",
      "uce in bin  12  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  13  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  14  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  15  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  16  : 0.0 , number of samples:  50\n",
      "uce in bin  17  : 1.3422001357565883e-11 , number of samples:  49\n",
      "tensor([0.9643, 0.8832, 0.8894, 0.9815, 0.8441, 0.8659, 0.8721, 0.8274, 0.8322,\n",
      "        0.8150, 0.8914, 0.8933, 0.8382, 0.8077, 0.9294, 0.8533, 0.7611],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.004361058381618932\n",
      "17 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "17 bins with 2.9229416847229004 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.0372903  0.03853986 0.0393443  0.04001301 0.04052238\n",
      " 0.04102954 0.04141849 0.04178748 0.04220093 0.04280239 0.0432357\n",
      " 0.04364066 0.04426047 0.04477942 0.04584211 0.04667186 0.04816676\n",
      " 0.05490025]\n",
      "uce in bin  1  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  2  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  3  : 0.0 , number of samples:  47\n",
      "uce in bin  4  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  5  : 6.574041658269358e-12 , number of samples:  48\n",
      "uce in bin  6  : 0.0 , number of samples:  47\n",
      "uce in bin  7  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  8  : 0.0 , number of samples:  47\n",
      "uce in bin  9  : 0.0 , number of samples:  48\n",
      "uce in bin  10  : 0.0 , number of samples:  47\n",
      "uce in bin  11  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  12  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  13  : 0.0 , number of samples:  47\n",
      "uce in bin  14  : 1.3148083316538717e-11 , number of samples:  48\n",
      "uce in bin  15  : 0.0 , number of samples:  47\n",
      "uce in bin  16  : 0.0 , number of samples:  47\n",
      "uce in bin  17  : 0.0 , number of samples:  47\n",
      "uce in bin  18  : 0.0 , number of samples:  47\n",
      "tensor([0.9431, 0.8983, 0.9078, 0.9459, 0.8836, 0.8836, 0.8336, 0.8773, 0.8318,\n",
      "        0.8414, 0.8459, 0.8551, 0.8286, 0.8704, 0.8892, 0.8902, 0.8493, 0.7543],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.007391966937575489\n",
      "18 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "18 bins with 2.93591046333313 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03717165 0.03847128 0.03919853 0.03984631 0.04035464\n",
      " 0.04086252 0.04128456 0.04160371 0.04195645 0.04255719 0.04295224\n",
      " 0.04340825 0.0438094  0.04439156 0.04492533 0.04594383 0.04680784\n",
      " 0.04827194 0.05490025]\n",
      "uce in bin  1  : 1.2052409417706578e-11 , number of samples:  44\n",
      "uce in bin  2  : 0.0 , number of samples:  45\n",
      "uce in bin  3  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  4  : 0.0 , number of samples:  44\n",
      "uce in bin  5  : 0.0 , number of samples:  45\n",
      "uce in bin  6  : 0.0 , number of samples:  45\n",
      "uce in bin  7  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  8  : 0.0 , number of samples:  44\n",
      "uce in bin  9  : 0.0 , number of samples:  45\n",
      "uce in bin  10  : 0.0 , number of samples:  45\n",
      "uce in bin  11  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  12  : 0.0 , number of samples:  44\n",
      "uce in bin  13  : 0.0 , number of samples:  45\n",
      "uce in bin  14  : 0.0 , number of samples:  45\n",
      "uce in bin  15  : 1.8489491188100615e-11 , number of samples:  45\n",
      "uce in bin  16  : 0.0 , number of samples:  44\n",
      "uce in bin  17  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  18  : 0.0 , number of samples:  45\n",
      "uce in bin  19  : 6.026204708853289e-12 , number of samples:  44\n",
      "tensor([0.9554, 0.9155, 0.8747, 0.9309, 0.9390, 0.8379, 0.8714, 0.8701, 0.8188,\n",
      "        0.8498, 0.8137, 0.8715, 0.8619, 0.8647, 0.8212, 0.9048, 0.8963, 0.8503,\n",
      "        0.7465], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005586453335126862\n",
      "19 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "19 bins with 2.8989076614379883 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03714634 0.03843282 0.03910286 0.03974266 0.04027902\n",
      " 0.04070082 0.04112842 0.04148997 0.04182794 0.04220093 0.04271838\n",
      " 0.0431485  0.04351169 0.04398953 0.04446644 0.04510581 0.04603227\n",
      " 0.04691925 0.0484722  0.05490025]\n",
      "uce in bin  1  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  2  : 5.889245254658837e-12 , number of samples:  43\n",
      "uce in bin  3  : 0.0 , number of samples:  42\n",
      "uce in bin  4  : 5.889245254658837e-12 , number of samples:  43\n",
      "uce in bin  5  : 0.0 , number of samples:  42\n",
      "uce in bin  6  : 0.0 , number of samples:  43\n",
      "uce in bin  7  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  8  : 0.0 , number of samples:  43\n",
      "uce in bin  9  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  10  : 5.889245254658837e-12 , number of samples:  43\n",
      "uce in bin  11  : 0.0 , number of samples:  42\n",
      "uce in bin  12  : 0.0 , number of samples:  43\n",
      "uce in bin  13  : 1.1504572468290508e-11 , number of samples:  42\n",
      "uce in bin  14  : 0.0 , number of samples:  43\n",
      "uce in bin  15  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  16  : 0.0 , number of samples:  43\n",
      "uce in bin  17  : 0.0 , number of samples:  42\n",
      "uce in bin  18  : 0.0 , number of samples:  43\n",
      "uce in bin  19  : 0.0 , number of samples:  42\n",
      "uce in bin  20  : 5.752286234145254e-12 , number of samples:  42\n",
      "tensor([0.9679, 0.9037, 0.8447, 0.9125, 0.9824, 0.8453, 0.8897, 0.8708, 0.8364,\n",
      "        0.8367, 0.8602, 0.8072, 0.8592, 0.8944, 0.8269, 0.7957, 0.9635, 0.8521,\n",
      "        0.8490, 0.7548], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.00640117796137929\n",
      "20 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "20 bins with 3.111142158508301 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.0371107  0.03836454 0.03901603 0.03963196 0.04017686\n",
      " 0.04061612 0.04102954 0.04136473 0.04164109 0.04196217 0.04252083\n",
      " 0.04291208 0.04333641 0.04364066 0.04410909 0.04459873 0.04527837\n",
      " 0.04611907 0.0470507  0.04859396 0.05490025]\n",
      "uce in bin  1  : 1.0956735518874439e-11 , number of samples:  40\n",
      "uce in bin  2  : 0.0 , number of samples:  40\n",
      "uce in bin  3  : 1.1230654427263342e-11 , number of samples:  41\n",
      "uce in bin  4  : 0.0 , number of samples:  40\n",
      "uce in bin  5  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  6  : 0.0 , number of samples:  40\n",
      "uce in bin  7  : 0.0 , number of samples:  41\n",
      "uce in bin  8  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  9  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  10  : 0.0 , number of samples:  40\n",
      "uce in bin  11  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  12  : 0.0 , number of samples:  40\n",
      "uce in bin  13  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  14  : 0.0 , number of samples:  40\n",
      "uce in bin  15  : 0.0 , number of samples:  41\n",
      "uce in bin  16  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  17  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  18  : 0.0 , number of samples:  40\n",
      "uce in bin  19  : 0.0 , number of samples:  41\n",
      "uce in bin  20  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  21  : 5.478367759437219e-12 , number of samples:  40\n",
      "tensor([0.9715, 0.8940, 0.8656, 0.8911, 1.0129, 0.8270, 0.8999, 0.8218, 0.8653,\n",
      "        0.8300, 0.8431, 0.8453, 0.8582, 0.8656, 0.8523, 0.8734, 0.7511, 0.9846,\n",
      "        0.8521, 0.8543, 0.7473], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.003710352029884234\n",
      "21 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "21 bins with 3.1074585914611816 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03699935 0.03827366 0.03888163 0.0395275  0.04008555\n",
      " 0.04045991 0.04087854 0.0412123  0.0415174  0.04187584 0.04220093\n",
      " 0.04266999 0.04309418 0.04343626 0.0437853  0.04433504 0.04470373\n",
      " 0.04554641 0.04622195 0.04714209 0.04875836 0.05490025]\n",
      "uce in bin  1  : 5.2044492847291846e-12 , number of samples:  38\n",
      "uce in bin  2  : 0.0 , number of samples:  39\n",
      "uce in bin  3  : 0.0 , number of samples:  38\n",
      "uce in bin  4  : 0.0 , number of samples:  39\n",
      "uce in bin  5  : 0.0 , number of samples:  39\n",
      "uce in bin  6  : 5.2044492847291846e-12 , number of samples:  38\n",
      "uce in bin  7  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  8  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  9  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  10  : 0.0 , number of samples:  39\n",
      "uce in bin  11  : 1.0682817477847273e-11 , number of samples:  39\n",
      "uce in bin  12  : 0.0 , number of samples:  38\n",
      "uce in bin  13  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  14  : 1.0408898569458369e-11 , number of samples:  38\n",
      "uce in bin  15  : 1.0682817477847273e-11 , number of samples:  39\n",
      "uce in bin  16  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  17  : 1.0408898569458369e-11 , number of samples:  38\n",
      "uce in bin  18  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  19  : 0.0 , number of samples:  39\n",
      "uce in bin  20  : 0.0 , number of samples:  38\n",
      "uce in bin  21  : 0.0 , number of samples:  39\n",
      "uce in bin  22  : 5.2044492847291846e-12 , number of samples:  38\n",
      "tensor([0.9787, 0.8988, 0.8824, 0.8647, 1.0102, 0.8534, 0.8803, 0.8677, 0.8711,\n",
      "        0.8563, 0.8156, 0.8618, 0.7478, 0.8986, 0.8704, 0.8540, 0.8680, 0.7948,\n",
      "        0.9661, 0.8577, 0.8392, 0.7434], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005499077815329656\n",
      "22 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "22 bins with 2.9402458667755127 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03693046 0.03816176 0.03879927 0.03946559 0.03993529\n",
      " 0.04033316 0.04072777 0.041114   0.04143014 0.04170835 0.04200198\n",
      " 0.04249719 0.04286387 0.04323085 0.04352613 0.04391286 0.04440021\n",
      " 0.04483973 0.04573644 0.04628374 0.04724101 0.04888271 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  36\n",
      "uce in bin  2  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  3  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  4  : 0.0 , number of samples:  37\n",
      "uce in bin  5  : 0.0 , number of samples:  37\n",
      "uce in bin  6  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  7  : 0.0 , number of samples:  37\n",
      "uce in bin  8  : 0.0 , number of samples:  37\n",
      "uce in bin  9  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  10  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  11  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  12  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  13  : 0.0 , number of samples:  37\n",
      "uce in bin  14  : 0.0 , number of samples:  37\n",
      "uce in bin  15  : 0.0 , number of samples:  37\n",
      "uce in bin  16  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  17  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  18  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  19  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  20  : 0.0 , number of samples:  37\n",
      "uce in bin  21  : 0.0 , number of samples:  37\n",
      "uce in bin  22  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  23  : 0.0 , number of samples:  36\n",
      "tensor([0.9703, 0.9100, 0.9035, 0.8787, 0.9526, 0.9213, 0.8422, 0.8868, 0.8250,\n",
      "        0.8798, 0.8079, 0.8546, 0.8444, 0.8448, 0.8595, 0.8946, 0.8223, 0.8433,\n",
      "        0.8394, 0.9497, 0.8582, 0.8268, 0.7486], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.0033119442377937958\n",
      "23 bins with tensor([9.3213e-05], device='cuda:0') UCE\n",
      "23 bins with 3.171170234680176 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03688534 0.03811063 0.03877927 0.0393443  0.03981887\n",
      " 0.04027902 0.04064623 0.04102954 0.04132751 0.04157097 0.04189624\n",
      " 0.04220093 0.04264931 0.04299221 0.04336798 0.04364066 0.04405021\n",
      " 0.04446644 0.04495535 0.04584211 0.04642986 0.04726971 0.04896568\n",
      " 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  35\n",
      "uce in bin  2  : 0.0 , number of samples:  35\n",
      "uce in bin  3  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  4  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  5  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  6  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  7  : 0.0 , number of samples:  35\n",
      "uce in bin  8  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  9  : 0.0 , number of samples:  35\n",
      "uce in bin  10  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  11  : 9.587143579015134e-12 , number of samples:  35\n",
      "uce in bin  12  : 0.0 , number of samples:  36\n",
      "uce in bin  13  : 0.0 , number of samples:  35\n",
      "uce in bin  14  : 0.0 , number of samples:  35\n",
      "uce in bin  15  : 0.0 , number of samples:  36\n",
      "uce in bin  16  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  17  : 0.0 , number of samples:  36\n",
      "uce in bin  18  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  19  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  20  : 0.0 , number of samples:  36\n",
      "uce in bin  21  : 0.0 , number of samples:  35\n",
      "uce in bin  22  : 9.861062487404038e-12 , number of samples:  36\n",
      "uce in bin  23  : 0.0 , number of samples:  35\n",
      "uce in bin  24  : 4.793571789507567e-12 , number of samples:  35\n",
      "tensor([0.9752, 0.9184, 0.8728, 0.9039, 0.9315, 0.9404, 0.8535, 0.8900, 0.8175,\n",
      "        0.8924, 0.8481, 0.8301, 0.8695, 0.7607, 0.8869, 0.8652, 0.8884, 0.8201,\n",
      "        0.8183, 0.9197, 0.9254, 0.8222, 0.8236, 0.7530], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.006843351729912683\n",
      "24 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "24 bins with 2.9840140342712402 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03974266 0.04148997 0.0431485  0.04510581 0.05490025]\n",
      "uce in bin  1  : 2.3283062977608182e-11 , number of samples:  170\n",
      "uce in bin  2  : 2.3283062977608182e-11 , number of samples:  170\n",
      "uce in bin  3  : 0.0 , number of samples:  170\n",
      "uce in bin  4  : 2.3283062977608182e-11 , number of samples:  170\n",
      "uce in bin  5  : 0.0 , number of samples:  169\n",
      "tensor([0.9057, 0.8973, 0.8350, 0.8441, 0.8532], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.0073337585490662605\n",
      "5 bins with tensor([8.2139e-05], device='cuda:0') UCE\n",
      "5 bins with 1.3563681840896606 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.0393443  0.04102954 0.04220093 0.04364066 0.04584211\n",
      " 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  141\n",
      "uce in bin  2  : 0.0 , number of samples:  142\n",
      "uce in bin  3  : 1.9448205199057433e-11 , number of samples:  142\n",
      "uce in bin  4  : 1.931124704590559e-11 , number of samples:  141\n",
      "uce in bin  5  : 3.889641039811487e-11 , number of samples:  142\n",
      "uce in bin  6  : 3.862249409181118e-11 , number of samples:  141\n",
      "tensor([0.9153, 0.9041, 0.8477, 0.8476, 0.8638, 0.8295], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.004964306936017238\n",
      "6 bins with tensor([8.8768e-05], device='cuda:0') UCE\n",
      "6 bins with 1.508626103401184 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03901603 0.04061612 0.04164109 0.04291208 0.04410909\n",
      " 0.04611907 0.05490025]\n",
      "uce in bin  1  : 1.657206316618698e-11 , number of samples:  121\n",
      "uce in bin  2  : 3.314412633237396e-11 , number of samples:  121\n",
      "uce in bin  3  : 0.0 , number of samples:  122\n",
      "uce in bin  4  : 0.0 , number of samples:  121\n",
      "uce in bin  5  : 0.0 , number of samples:  122\n",
      "uce in bin  6  : 1.657206316618698e-11 , number of samples:  121\n",
      "uce in bin  7  : 3.314412633237396e-11 , number of samples:  121\n",
      "tensor([0.9077, 0.9140, 0.8630, 0.8396, 0.8586, 0.8755, 0.8168],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.004389879904920235\n",
      "7 bins with tensor([9.1749e-05], device='cuda:0') UCE\n",
      "7 bins with 1.5719578266143799 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03877927 0.04027902 0.04132751 0.04220093 0.04336798\n",
      " 0.04446644 0.04642986 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  106\n",
      "uce in bin  2  : 1.4517675256398022e-11 , number of samples:  106\n",
      "uce in bin  3  : 0.0 , number of samples:  106\n",
      "uce in bin  4  : 1.4654633409549866e-11 , number of samples:  107\n",
      "uce in bin  5  : 1.4517675256398022e-11 , number of samples:  106\n",
      "uce in bin  6  : 0.0 , number of samples:  106\n",
      "uce in bin  7  : 1.4517675256398022e-11 , number of samples:  106\n",
      "uce in bin  8  : 1.4517675256398022e-11 , number of samples:  106\n",
      "tensor([0.9195, 0.9258, 0.8544, 0.8571, 0.8415, 0.8584, 0.8905, 0.7986],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.009560416219756007\n",
      "8 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "8 bins with 1.1589654684066772 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03853986 0.04001301 0.04102954 0.04178748 0.04280239\n",
      " 0.04364066 0.04477942 0.04667186 0.05490025]\n",
      "uce in bin  1  : 1.2874164408149813e-11 , number of samples:  94\n",
      "uce in bin  2  : 0.0 , number of samples:  94\n",
      "uce in bin  3  : 1.3011123428663396e-11 , number of samples:  95\n",
      "uce in bin  4  : 0.0 , number of samples:  94\n",
      "uce in bin  5  : 1.3011123428663396e-11 , number of samples:  95\n",
      "uce in bin  6  : 0.0 , number of samples:  94\n",
      "uce in bin  7  : 0.0 , number of samples:  95\n",
      "uce in bin  8  : 0.0 , number of samples:  94\n",
      "uce in bin  9  : 2.5748328816299626e-11 , number of samples:  94\n",
      "tensor([0.9195, 0.9274, 0.8836, 0.8559, 0.8366, 0.8505, 0.8503, 0.8897, 0.8007],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.009096165740629658\n",
      "9 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "9 bins with 1.3004889488220215 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03843282 0.03974266 0.04070082 0.04148997 0.04220093\n",
      " 0.0431485  0.04398953 0.04510581 0.04691925 0.05490025]\n",
      "uce in bin  1  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  2  : 0.0 , number of samples:  85\n",
      "uce in bin  3  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  4  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  5  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  6  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  7  : 2.3283062977608182e-11 , number of samples:  85\n",
      "uce in bin  8  : 0.0 , number of samples:  85\n",
      "uce in bin  9  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  10  : 1.1504572468290508e-11 , number of samples:  84\n",
      "tensor([0.9339, 0.8803, 0.9149, 0.8801, 0.8366, 0.8335, 0.8773, 0.8111, 0.9079,\n",
      "        0.8009], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005077945388620719\n",
      "10 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "10 bins with 1.5769752264022827 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03827366 0.0395275  0.04045991 0.0412123  0.04187584\n",
      " 0.04266999 0.04343626 0.04433504 0.04554641 0.04714209 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  77\n",
      "uce in bin  2  : 1.054585845733369e-11 , number of samples:  77\n",
      "uce in bin  3  : 0.0 , number of samples:  77\n",
      "uce in bin  4  : 1.0819776498360856e-11 , number of samples:  79\n",
      "uce in bin  5  : 1.0408898569458369e-11 , number of samples:  76\n",
      "uce in bin  6  : 1.054585845733369e-11 , number of samples:  77\n",
      "uce in bin  7  : 1.054585845733369e-11 , number of samples:  77\n",
      "uce in bin  8  : 1.0682817477847273e-11 , number of samples:  78\n",
      "uce in bin  9  : 0.0 , number of samples:  77\n",
      "uce in bin  10  : 2.109171691466738e-11 , number of samples:  77\n",
      "uce in bin  11  : 0.0 , number of samples:  77\n",
      "tensor([0.9365, 0.8733, 0.9352, 0.8739, 0.8635, 0.8390, 0.8264, 0.8621, 0.8313,\n",
      "        0.9134, 0.7909], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.007587010622955859\n",
      "11 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "11 bins with 1.8237894773483276 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03811063 0.0393443  0.04027902 0.04102954 0.04157097\n",
      " 0.04220093 0.04299221 0.04364066 0.04446644 0.04584211 0.04726971\n",
      " 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  70\n",
      "uce in bin  2  : 0.0 , number of samples:  71\n",
      "uce in bin  3  : 1.9448205199057433e-11 , number of samples:  71\n",
      "uce in bin  4  : 9.724102599528717e-12 , number of samples:  71\n",
      "uce in bin  5  : 1.9448205199057433e-11 , number of samples:  71\n",
      "uce in bin  6  : 0.0 , number of samples:  71\n",
      "uce in bin  7  : 1.9174287158030268e-11 , number of samples:  70\n",
      "uce in bin  8  : 0.0 , number of samples:  71\n",
      "uce in bin  9  : 0.0 , number of samples:  71\n",
      "uce in bin  10  : 1.9448205199057433e-11 , number of samples:  71\n",
      "uce in bin  11  : 9.724102599528717e-12 , number of samples:  71\n",
      "uce in bin  12  : 9.587143579015134e-12 , number of samples:  70\n",
      "tensor([0.9453, 0.8885, 0.9360, 0.8724, 0.8566, 0.8390, 0.8165, 0.8762, 0.8551,\n",
      "        0.8720, 0.8738, 0.7874], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.0074315088568255305\n",
      "12 bins with tensor([9.2622e-05], device='cuda:0') UCE\n",
      "12 bins with 1.161619782447815 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03788432 0.03915853 0.04011369 0.04076396 0.04139863\n",
      " 0.04190108 0.04262602 0.04329034 0.04386971 0.0446565  0.04599188\n",
      " 0.04745675 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  65\n",
      "uce in bin  2  : 8.902347609085481e-12 , number of samples:  65\n",
      "uce in bin  3  : 0.0 , number of samples:  66\n",
      "uce in bin  4  : 8.902347609085481e-12 , number of samples:  65\n",
      "uce in bin  5  : 0.0 , number of samples:  65\n",
      "uce in bin  6  : 0.0 , number of samples:  66\n",
      "uce in bin  7  : 1.7804695218170963e-11 , number of samples:  65\n",
      "uce in bin  8  : 0.0 , number of samples:  66\n",
      "uce in bin  9  : 0.0 , number of samples:  65\n",
      "uce in bin  10  : 1.7804695218170963e-11 , number of samples:  65\n",
      "uce in bin  11  : 0.0 , number of samples:  66\n",
      "uce in bin  12  : 8.902347609085481e-12 , number of samples:  65\n",
      "uce in bin  13  : 8.902347609085481e-12 , number of samples:  65\n",
      "tensor([0.9434, 0.8920, 0.9465, 0.8599, 0.8560, 0.8574, 0.8504, 0.8371, 0.8554,\n",
      "        0.8603, 0.8628, 0.8841, 0.7820], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.007287979678949341\n",
      "13 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "13 bins with 0.95313960313797 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03771835 0.03901603 0.03988922 0.04061612 0.04117621\n",
      " 0.04164109 0.04220093 0.04291208 0.04347522 0.04410909 0.04487395\n",
      " 0.04611907 0.04760478 0.05490025]\n",
      "uce in bin  1  : 8.217551639155829e-12 , number of samples:  60\n",
      "uce in bin  2  : 0.0 , number of samples:  61\n",
      "uce in bin  3  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  4  : 8.217551639155829e-12 , number of samples:  60\n",
      "uce in bin  5  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  6  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  7  : 0.0 , number of samples:  61\n",
      "uce in bin  8  : 1.6435103278311658e-11 , number of samples:  60\n",
      "uce in bin  9  : 0.0 , number of samples:  61\n",
      "uce in bin  10  : 0.0 , number of samples:  61\n",
      "uce in bin  11  : 8.217551639155829e-12 , number of samples:  60\n",
      "uce in bin  12  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  13  : 1.6709021319338824e-11 , number of samples:  61\n",
      "uce in bin  14  : 1.6435103278311658e-11 , number of samples:  60\n",
      "tensor([0.9473, 0.8722, 0.9349, 0.8932, 0.8834, 0.8426, 0.8522, 0.8271, 0.8544,\n",
      "        0.8628, 0.8497, 0.8991, 0.8574, 0.7780], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005041862459620461\n",
      "14 bins with tensor([9.2402e-05], device='cuda:0') UCE\n",
      "14 bins with 1.1200345754623413 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03758804 0.03883939 0.03974266 0.04038315 0.04102954\n",
      " 0.04148997 0.04190926 0.04260738 0.0431485  0.04364066 0.04436997\n",
      " 0.04510581 0.0462356  0.04782094 0.05490025]\n",
      "uce in bin  1  : 1.533942937947952e-11 , number of samples:  56\n",
      "uce in bin  2  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  3  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  4  : 0.0 , number of samples:  56\n",
      "uce in bin  5  : 0.0 , number of samples:  57\n",
      "uce in bin  6  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  7  : 0.0 , number of samples:  56\n",
      "uce in bin  8  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  9  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  10  : 7.66971468973976e-12 , number of samples:  56\n",
      "uce in bin  11  : 0.0 , number of samples:  57\n",
      "uce in bin  12  : 0.0 , number of samples:  57\n",
      "uce in bin  13  : 1.533942937947952e-11 , number of samples:  56\n",
      "uce in bin  14  : 0.0 , number of samples:  57\n",
      "uce in bin  15  : 1.533942937947952e-11 , number of samples:  56\n",
      "tensor([0.9525, 0.8999, 0.8713, 0.9614, 0.8665, 0.8645, 0.8401, 0.8180, 0.8466,\n",
      "        0.8678, 0.8601, 0.8054, 0.9511, 0.8329, 0.7801], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005359812712413259\n",
      "15 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "15 bins with 1.5686479806900024 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03739283 0.03877927 0.03959142 0.04027902 0.04081613\n",
      " 0.04132751 0.04174127 0.04220093 0.0428364  0.04336798 0.04382173\n",
      " 0.04446644 0.04530898 0.04642986 0.04793808 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  53\n",
      "uce in bin  2  : 0.0 , number of samples:  53\n",
      "uce in bin  3  : 0.0 , number of samples:  53\n",
      "uce in bin  4  : 7.258837628199011e-12 , number of samples:  53\n",
      "uce in bin  5  : 0.0 , number of samples:  53\n",
      "uce in bin  6  : 0.0 , number of samples:  53\n",
      "uce in bin  7  : 0.0 , number of samples:  53\n",
      "uce in bin  8  : 0.0 , number of samples:  54\n",
      "uce in bin  9  : 0.0 , number of samples:  53\n",
      "uce in bin  10  : 1.4517675256398022e-11 , number of samples:  53\n",
      "uce in bin  11  : 7.258837628199011e-12 , number of samples:  53\n",
      "uce in bin  12  : 1.4517675256398022e-11 , number of samples:  53\n",
      "uce in bin  13  : 7.258837628199011e-12 , number of samples:  53\n",
      "uce in bin  14  : 0.0 , number of samples:  53\n",
      "uce in bin  15  : 1.4517675256398022e-11 , number of samples:  53\n",
      "uce in bin  16  : 7.258837628199011e-12 , number of samples:  53\n",
      "tensor([0.9667, 0.8759, 0.8596, 0.9853, 0.8535, 0.8552, 0.8919, 0.8222, 0.8298,\n",
      "        0.8527, 0.8562, 0.8605, 0.8042, 0.9657, 0.8229, 0.7761],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.00444475699623581\n",
      "16 bins with tensor([9.8084e-05], device='cuda:0') UCE\n",
      "16 bins with 0.7742586135864258 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03735686 0.0387038  0.03949024 0.04013795 0.0406526\n",
      " 0.04114018 0.0415368  0.04192781 0.04257943 0.0430803  0.04349529\n",
      " 0.04402716 0.04462811 0.04568613 0.04651846 0.0480996  0.05490025]\n",
      "uce in bin  1  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  2  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  3  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  4  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  5  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  6  : 0.0 , number of samples:  50\n",
      "uce in bin  7  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  8  : 0.0 , number of samples:  50\n",
      "uce in bin  9  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  10  : 0.0 , number of samples:  50\n",
      "uce in bin  11  : 0.0 , number of samples:  50\n",
      "uce in bin  12  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  13  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  14  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  15  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  16  : 0.0 , number of samples:  50\n",
      "uce in bin  17  : 1.3422001357565883e-11 , number of samples:  49\n",
      "tensor([0.9643, 0.8832, 0.8894, 0.9815, 0.8441, 0.8659, 0.8721, 0.8274, 0.8322,\n",
      "        0.8150, 0.8914, 0.8933, 0.8382, 0.8077, 0.9294, 0.8533, 0.7611],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.004361058381618932\n",
      "17 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "17 bins with 0.6430698037147522 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.0372903  0.03853986 0.0393443  0.04001301 0.04052238\n",
      " 0.04102954 0.04141849 0.04178748 0.04220093 0.04280239 0.0432357\n",
      " 0.04364066 0.04426047 0.04477942 0.04584211 0.04667186 0.04816676\n",
      " 0.05490025]\n",
      "uce in bin  1  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  2  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  3  : 0.0 , number of samples:  47\n",
      "uce in bin  4  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  5  : 6.574041658269358e-12 , number of samples:  48\n",
      "uce in bin  6  : 0.0 , number of samples:  47\n",
      "uce in bin  7  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  8  : 0.0 , number of samples:  47\n",
      "uce in bin  9  : 0.0 , number of samples:  48\n",
      "uce in bin  10  : 0.0 , number of samples:  47\n",
      "uce in bin  11  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  12  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  13  : 0.0 , number of samples:  47\n",
      "uce in bin  14  : 1.3148083316538717e-11 , number of samples:  48\n",
      "uce in bin  15  : 0.0 , number of samples:  47\n",
      "uce in bin  16  : 0.0 , number of samples:  47\n",
      "uce in bin  17  : 0.0 , number of samples:  47\n",
      "uce in bin  18  : 0.0 , number of samples:  47\n",
      "tensor([0.9431, 0.8983, 0.9078, 0.9459, 0.8836, 0.8836, 0.8336, 0.8773, 0.8318,\n",
      "        0.8414, 0.8459, 0.8551, 0.8286, 0.8704, 0.8892, 0.8902, 0.8493, 0.7543],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.007391966937575489\n",
      "18 bins with tensor([8.6642e-05], device='cuda:0') UCE\n",
      "18 bins with 0.9609472751617432 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03717165 0.03847128 0.03919853 0.03984631 0.04035464\n",
      " 0.04086252 0.04128456 0.04160371 0.04195645 0.04255719 0.04295224\n",
      " 0.04340825 0.0438094  0.04439156 0.04492533 0.04594383 0.04680784\n",
      " 0.04827194 0.05490025]\n",
      "uce in bin  1  : 1.2052409417706578e-11 , number of samples:  44\n",
      "uce in bin  2  : 0.0 , number of samples:  45\n",
      "uce in bin  3  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  4  : 0.0 , number of samples:  44\n",
      "uce in bin  5  : 0.0 , number of samples:  45\n",
      "uce in bin  6  : 0.0 , number of samples:  45\n",
      "uce in bin  7  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  8  : 0.0 , number of samples:  44\n",
      "uce in bin  9  : 0.0 , number of samples:  45\n",
      "uce in bin  10  : 0.0 , number of samples:  45\n",
      "uce in bin  11  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  12  : 0.0 , number of samples:  44\n",
      "uce in bin  13  : 0.0 , number of samples:  45\n",
      "uce in bin  14  : 0.0 , number of samples:  45\n",
      "uce in bin  15  : 1.8489491188100615e-11 , number of samples:  45\n",
      "uce in bin  16  : 0.0 , number of samples:  44\n",
      "uce in bin  17  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  18  : 0.0 , number of samples:  45\n",
      "uce in bin  19  : 6.026204708853289e-12 , number of samples:  44\n",
      "tensor([0.9554, 0.9155, 0.8747, 0.9309, 0.9390, 0.8379, 0.8714, 0.8701, 0.8188,\n",
      "        0.8498, 0.8137, 0.8715, 0.8619, 0.8647, 0.8212, 0.9048, 0.8963, 0.8503,\n",
      "        0.7465], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005586453335126862\n",
      "19 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "19 bins with 1.350168228149414 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03714634 0.03843282 0.03910286 0.03974266 0.04027902\n",
      " 0.04070082 0.04112842 0.04148997 0.04182794 0.04220093 0.04271838\n",
      " 0.0431485  0.04351169 0.04398953 0.04446644 0.04510581 0.04603227\n",
      " 0.04691925 0.0484722  0.05490025]\n",
      "uce in bin  1  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  2  : 5.889245254658837e-12 , number of samples:  43\n",
      "uce in bin  3  : 0.0 , number of samples:  42\n",
      "uce in bin  4  : 5.889245254658837e-12 , number of samples:  43\n",
      "uce in bin  5  : 0.0 , number of samples:  42\n",
      "uce in bin  6  : 0.0 , number of samples:  43\n",
      "uce in bin  7  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  8  : 0.0 , number of samples:  43\n",
      "uce in bin  9  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  10  : 5.889245254658837e-12 , number of samples:  43\n",
      "uce in bin  11  : 0.0 , number of samples:  42\n",
      "uce in bin  12  : 0.0 , number of samples:  43\n",
      "uce in bin  13  : 1.1504572468290508e-11 , number of samples:  42\n",
      "uce in bin  14  : 0.0 , number of samples:  43\n",
      "uce in bin  15  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  16  : 0.0 , number of samples:  43\n",
      "uce in bin  17  : 0.0 , number of samples:  42\n",
      "uce in bin  18  : 0.0 , number of samples:  43\n",
      "uce in bin  19  : 0.0 , number of samples:  42\n",
      "uce in bin  20  : 5.752286234145254e-12 , number of samples:  42\n",
      "tensor([0.9679, 0.9037, 0.8447, 0.9125, 0.9824, 0.8453, 0.8897, 0.8708, 0.8364,\n",
      "        0.8367, 0.8602, 0.8072, 0.8592, 0.8944, 0.8269, 0.7957, 0.9635, 0.8521,\n",
      "        0.8490, 0.7548], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.00640117796137929\n",
      "20 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "20 bins with 1.378222107887268 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.0371107  0.03836454 0.03901603 0.03963196 0.04017686\n",
      " 0.04061612 0.04102954 0.04136473 0.04164109 0.04196217 0.04252083\n",
      " 0.04291208 0.04333641 0.04364066 0.04410909 0.04459873 0.04527837\n",
      " 0.04611907 0.0470507  0.04859396 0.05490025]\n",
      "uce in bin  1  : 1.0956735518874439e-11 , number of samples:  40\n",
      "uce in bin  2  : 0.0 , number of samples:  40\n",
      "uce in bin  3  : 1.1230654427263342e-11 , number of samples:  41\n",
      "uce in bin  4  : 0.0 , number of samples:  40\n",
      "uce in bin  5  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  6  : 0.0 , number of samples:  40\n",
      "uce in bin  7  : 0.0 , number of samples:  41\n",
      "uce in bin  8  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  9  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  10  : 0.0 , number of samples:  40\n",
      "uce in bin  11  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  12  : 0.0 , number of samples:  40\n",
      "uce in bin  13  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  14  : 0.0 , number of samples:  40\n",
      "uce in bin  15  : 0.0 , number of samples:  41\n",
      "uce in bin  16  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  17  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  18  : 0.0 , number of samples:  40\n",
      "uce in bin  19  : 0.0 , number of samples:  41\n",
      "uce in bin  20  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  21  : 5.478367759437219e-12 , number of samples:  40\n",
      "tensor([0.9715, 0.8940, 0.8656, 0.8911, 1.0129, 0.8270, 0.8999, 0.8218, 0.8653,\n",
      "        0.8300, 0.8431, 0.8453, 0.8582, 0.8656, 0.8523, 0.8734, 0.7511, 0.9846,\n",
      "        0.8521, 0.8543, 0.7473], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.003710352029884234\n",
      "21 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "21 bins with 1.2056297063827515 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03699935 0.03827366 0.03888163 0.0395275  0.04008555\n",
      " 0.04045991 0.04087854 0.0412123  0.0415174  0.04187584 0.04220093\n",
      " 0.04266999 0.04309418 0.04343626 0.0437853  0.04433504 0.04470373\n",
      " 0.04554641 0.04622195 0.04714209 0.04875836 0.05490025]\n",
      "uce in bin  1  : 5.2044492847291846e-12 , number of samples:  38\n",
      "uce in bin  2  : 0.0 , number of samples:  39\n",
      "uce in bin  3  : 0.0 , number of samples:  38\n",
      "uce in bin  4  : 0.0 , number of samples:  39\n",
      "uce in bin  5  : 0.0 , number of samples:  39\n",
      "uce in bin  6  : 5.2044492847291846e-12 , number of samples:  38\n",
      "uce in bin  7  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  8  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  9  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  10  : 0.0 , number of samples:  39\n",
      "uce in bin  11  : 1.0682817477847273e-11 , number of samples:  39\n",
      "uce in bin  12  : 0.0 , number of samples:  38\n",
      "uce in bin  13  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  14  : 1.0408898569458369e-11 , number of samples:  38\n",
      "uce in bin  15  : 1.0682817477847273e-11 , number of samples:  39\n",
      "uce in bin  16  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  17  : 1.0408898569458369e-11 , number of samples:  38\n",
      "uce in bin  18  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  19  : 0.0 , number of samples:  39\n",
      "uce in bin  20  : 0.0 , number of samples:  38\n",
      "uce in bin  21  : 0.0 , number of samples:  39\n",
      "uce in bin  22  : 5.2044492847291846e-12 , number of samples:  38\n",
      "tensor([0.9787, 0.8988, 0.8824, 0.8647, 1.0102, 0.8534, 0.8803, 0.8677, 0.8711,\n",
      "        0.8563, 0.8156, 0.8618, 0.7478, 0.8986, 0.8704, 0.8540, 0.8680, 0.7948,\n",
      "        0.9661, 0.8577, 0.8392, 0.7434], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005499077815329656\n",
      "22 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "22 bins with 0.7641932368278503 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03693046 0.03816176 0.03879927 0.03946559 0.03993529\n",
      " 0.04033316 0.04072777 0.041114   0.04143014 0.04170835 0.04200198\n",
      " 0.04249719 0.04286387 0.04323085 0.04352613 0.04391286 0.04440021\n",
      " 0.04483973 0.04573644 0.04628374 0.04724101 0.04888271 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  36\n",
      "uce in bin  2  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  3  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  4  : 0.0 , number of samples:  37\n",
      "uce in bin  5  : 0.0 , number of samples:  37\n",
      "uce in bin  6  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  7  : 0.0 , number of samples:  37\n",
      "uce in bin  8  : 0.0 , number of samples:  37\n",
      "uce in bin  9  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  10  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  11  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  12  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  13  : 0.0 , number of samples:  37\n",
      "uce in bin  14  : 0.0 , number of samples:  37\n",
      "uce in bin  15  : 0.0 , number of samples:  37\n",
      "uce in bin  16  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  17  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  18  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  19  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  20  : 0.0 , number of samples:  37\n",
      "uce in bin  21  : 0.0 , number of samples:  37\n",
      "uce in bin  22  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  23  : 0.0 , number of samples:  36\n",
      "tensor([0.9703, 0.9100, 0.9035, 0.8787, 0.9526, 0.9213, 0.8422, 0.8868, 0.8250,\n",
      "        0.8798, 0.8079, 0.8546, 0.8444, 0.8448, 0.8595, 0.8946, 0.8223, 0.8433,\n",
      "        0.8394, 0.9497, 0.8582, 0.8268, 0.7486], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.0033119442377937958\n",
      "23 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "23 bins with 1.112810492515564 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03688534 0.03811063 0.03877927 0.0393443  0.03981887\n",
      " 0.04027902 0.04064623 0.04102954 0.04132751 0.04157097 0.04189624\n",
      " 0.04220093 0.04264931 0.04299221 0.04336798 0.04364066 0.04405021\n",
      " 0.04446644 0.04495535 0.04584211 0.04642986 0.04726971 0.04896568\n",
      " 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  35\n",
      "uce in bin  2  : 0.0 , number of samples:  35\n",
      "uce in bin  3  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  4  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  5  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  6  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  7  : 0.0 , number of samples:  35\n",
      "uce in bin  8  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  9  : 0.0 , number of samples:  35\n",
      "uce in bin  10  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  11  : 9.587143579015134e-12 , number of samples:  35\n",
      "uce in bin  12  : 0.0 , number of samples:  36\n",
      "uce in bin  13  : 0.0 , number of samples:  35\n",
      "uce in bin  14  : 0.0 , number of samples:  35\n",
      "uce in bin  15  : 0.0 , number of samples:  36\n",
      "uce in bin  16  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  17  : 0.0 , number of samples:  36\n",
      "uce in bin  18  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  19  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  20  : 0.0 , number of samples:  36\n",
      "uce in bin  21  : 0.0 , number of samples:  35\n",
      "uce in bin  22  : 9.861062487404038e-12 , number of samples:  36\n",
      "uce in bin  23  : 0.0 , number of samples:  35\n",
      "uce in bin  24  : 4.793571789507567e-12 , number of samples:  35\n",
      "tensor([0.9752, 0.9184, 0.8728, 0.9039, 0.9315, 0.9404, 0.8535, 0.8900, 0.8175,\n",
      "        0.8924, 0.8481, 0.8301, 0.8695, 0.7607, 0.8869, 0.8652, 0.8884, 0.8201,\n",
      "        0.8183, 0.9197, 0.9254, 0.8222, 0.8236, 0.7530], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.006843351729912683\n",
      "24 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "24 bins with 1.341376543045044 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03974266 0.04148997 0.0431485  0.04510581 0.05490025]\n",
      "uce in bin  1  : 2.3283062977608182e-11 , number of samples:  170\n",
      "uce in bin  2  : 2.3283062977608182e-11 , number of samples:  170\n",
      "uce in bin  3  : 0.0 , number of samples:  170\n",
      "uce in bin  4  : 2.3283062977608182e-11 , number of samples:  170\n",
      "uce in bin  5  : 0.0 , number of samples:  169\n",
      "tensor([0.9057, 0.8973, 0.8350, 0.8441, 0.8532], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.0073337585490662605\n",
      "5 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "5 bins with 1.8438080549240112 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.0393443  0.04102954 0.04220093 0.04364066 0.04584211\n",
      " 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  141\n",
      "uce in bin  2  : 0.0 , number of samples:  142\n",
      "uce in bin  3  : 1.9448205199057433e-11 , number of samples:  142\n",
      "uce in bin  4  : 1.931124704590559e-11 , number of samples:  141\n",
      "uce in bin  5  : 3.889641039811487e-11 , number of samples:  142\n",
      "uce in bin  6  : 3.862249409181118e-11 , number of samples:  141\n",
      "tensor([0.9153, 0.9041, 0.8477, 0.8476, 0.8638, 0.8295], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.004964306936017238\n",
      "6 bins with tensor([9.7023e-05], device='cuda:0') UCE\n",
      "6 bins with 1.3348679542541504 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03901603 0.04061612 0.04164109 0.04291208 0.04410909\n",
      " 0.04611907 0.05490025]\n",
      "uce in bin  1  : 1.657206316618698e-11 , number of samples:  121\n",
      "uce in bin  2  : 3.314412633237396e-11 , number of samples:  121\n",
      "uce in bin  3  : 0.0 , number of samples:  122\n",
      "uce in bin  4  : 0.0 , number of samples:  121\n",
      "uce in bin  5  : 0.0 , number of samples:  122\n",
      "uce in bin  6  : 1.657206316618698e-11 , number of samples:  121\n",
      "uce in bin  7  : 3.314412633237396e-11 , number of samples:  121\n",
      "tensor([0.9077, 0.9140, 0.8630, 0.8396, 0.8586, 0.8755, 0.8168],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.004389879904920235\n",
      "7 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "7 bins with 1.4292385578155518 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03877927 0.04027902 0.04132751 0.04220093 0.04336798\n",
      " 0.04446644 0.04642986 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  106\n",
      "uce in bin  2  : 1.4517675256398022e-11 , number of samples:  106\n",
      "uce in bin  3  : 0.0 , number of samples:  106\n",
      "uce in bin  4  : 1.4654633409549866e-11 , number of samples:  107\n",
      "uce in bin  5  : 1.4517675256398022e-11 , number of samples:  106\n",
      "uce in bin  6  : 0.0 , number of samples:  106\n",
      "uce in bin  7  : 1.4517675256398022e-11 , number of samples:  106\n",
      "uce in bin  8  : 1.4517675256398022e-11 , number of samples:  106\n",
      "tensor([0.9195, 0.9258, 0.8544, 0.8571, 0.8415, 0.8584, 0.8905, 0.7986],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.009560416219756007\n",
      "8 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "8 bins with 1.5930066108703613 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03853986 0.04001301 0.04102954 0.04178748 0.04280239\n",
      " 0.04364066 0.04477942 0.04667186 0.05490025]\n",
      "uce in bin  1  : 1.2874164408149813e-11 , number of samples:  94\n",
      "uce in bin  2  : 0.0 , number of samples:  94\n",
      "uce in bin  3  : 1.3011123428663396e-11 , number of samples:  95\n",
      "uce in bin  4  : 0.0 , number of samples:  94\n",
      "uce in bin  5  : 1.3011123428663396e-11 , number of samples:  95\n",
      "uce in bin  6  : 0.0 , number of samples:  94\n",
      "uce in bin  7  : 0.0 , number of samples:  95\n",
      "uce in bin  8  : 0.0 , number of samples:  94\n",
      "uce in bin  9  : 2.5748328816299626e-11 , number of samples:  94\n",
      "tensor([0.9195, 0.9274, 0.8836, 0.8559, 0.8366, 0.8505, 0.8503, 0.8897, 0.8007],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.009096165740629658\n",
      "9 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "9 bins with 1.6650258302688599 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03843282 0.03974266 0.04070082 0.04148997 0.04220093\n",
      " 0.0431485  0.04398953 0.04510581 0.04691925 0.05490025]\n",
      "uce in bin  1  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  2  : 0.0 , number of samples:  85\n",
      "uce in bin  3  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  4  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  5  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  6  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  7  : 2.3283062977608182e-11 , number of samples:  85\n",
      "uce in bin  8  : 0.0 , number of samples:  85\n",
      "uce in bin  9  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  10  : 1.1504572468290508e-11 , number of samples:  84\n",
      "tensor([0.9339, 0.8803, 0.9149, 0.8801, 0.8366, 0.8335, 0.8773, 0.8111, 0.9079,\n",
      "        0.8009], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005077945388620719\n",
      "10 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "10 bins with 1.621716856956482 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03827366 0.0395275  0.04045991 0.0412123  0.04187584\n",
      " 0.04266999 0.04343626 0.04433504 0.04554641 0.04714209 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  77\n",
      "uce in bin  2  : 1.054585845733369e-11 , number of samples:  77\n",
      "uce in bin  3  : 0.0 , number of samples:  77\n",
      "uce in bin  4  : 1.0819776498360856e-11 , number of samples:  79\n",
      "uce in bin  5  : 1.0408898569458369e-11 , number of samples:  76\n",
      "uce in bin  6  : 1.054585845733369e-11 , number of samples:  77\n",
      "uce in bin  7  : 1.054585845733369e-11 , number of samples:  77\n",
      "uce in bin  8  : 1.0682817477847273e-11 , number of samples:  78\n",
      "uce in bin  9  : 0.0 , number of samples:  77\n",
      "uce in bin  10  : 2.109171691466738e-11 , number of samples:  77\n",
      "uce in bin  11  : 0.0 , number of samples:  77\n",
      "tensor([0.9365, 0.8733, 0.9352, 0.8739, 0.8635, 0.8390, 0.8264, 0.8621, 0.8313,\n",
      "        0.9134, 0.7909], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.007587010622955859\n",
      "11 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "11 bins with 1.761064052581787 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03811063 0.0393443  0.04027902 0.04102954 0.04157097\n",
      " 0.04220093 0.04299221 0.04364066 0.04446644 0.04584211 0.04726971\n",
      " 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  70\n",
      "uce in bin  2  : 0.0 , number of samples:  71\n",
      "uce in bin  3  : 1.9448205199057433e-11 , number of samples:  71\n",
      "uce in bin  4  : 9.724102599528717e-12 , number of samples:  71\n",
      "uce in bin  5  : 1.9448205199057433e-11 , number of samples:  71\n",
      "uce in bin  6  : 0.0 , number of samples:  71\n",
      "uce in bin  7  : 1.9174287158030268e-11 , number of samples:  70\n",
      "uce in bin  8  : 0.0 , number of samples:  71\n",
      "uce in bin  9  : 0.0 , number of samples:  71\n",
      "uce in bin  10  : 1.9448205199057433e-11 , number of samples:  71\n",
      "uce in bin  11  : 9.724102599528717e-12 , number of samples:  71\n",
      "uce in bin  12  : 9.587143579015134e-12 , number of samples:  70\n",
      "tensor([0.9453, 0.8885, 0.9360, 0.8724, 0.8566, 0.8390, 0.8165, 0.8762, 0.8551,\n",
      "        0.8720, 0.8738, 0.7874], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.0074315088568255305\n",
      "12 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "12 bins with 1.3756651878356934 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03788432 0.03915853 0.04011369 0.04076396 0.04139863\n",
      " 0.04190108 0.04262602 0.04329034 0.04386971 0.0446565  0.04599188\n",
      " 0.04745675 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  65\n",
      "uce in bin  2  : 8.902347609085481e-12 , number of samples:  65\n",
      "uce in bin  3  : 0.0 , number of samples:  66\n",
      "uce in bin  4  : 8.902347609085481e-12 , number of samples:  65\n",
      "uce in bin  5  : 0.0 , number of samples:  65\n",
      "uce in bin  6  : 0.0 , number of samples:  66\n",
      "uce in bin  7  : 1.7804695218170963e-11 , number of samples:  65\n",
      "uce in bin  8  : 0.0 , number of samples:  66\n",
      "uce in bin  9  : 0.0 , number of samples:  65\n",
      "uce in bin  10  : 1.7804695218170963e-11 , number of samples:  65\n",
      "uce in bin  11  : 0.0 , number of samples:  66\n",
      "uce in bin  12  : 8.902347609085481e-12 , number of samples:  65\n",
      "uce in bin  13  : 8.902347609085481e-12 , number of samples:  65\n",
      "tensor([0.9434, 0.8920, 0.9465, 0.8599, 0.8560, 0.8574, 0.8504, 0.8371, 0.8554,\n",
      "        0.8603, 0.8628, 0.8841, 0.7820], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.007287979678949341\n",
      "13 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "13 bins with 1.4931455850601196 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03771835 0.03901603 0.03988922 0.04061612 0.04117621\n",
      " 0.04164109 0.04220093 0.04291208 0.04347522 0.04410909 0.04487395\n",
      " 0.04611907 0.04760478 0.05490025]\n",
      "uce in bin  1  : 8.217551639155829e-12 , number of samples:  60\n",
      "uce in bin  2  : 0.0 , number of samples:  61\n",
      "uce in bin  3  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  4  : 8.217551639155829e-12 , number of samples:  60\n",
      "uce in bin  5  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  6  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  7  : 0.0 , number of samples:  61\n",
      "uce in bin  8  : 1.6435103278311658e-11 , number of samples:  60\n",
      "uce in bin  9  : 0.0 , number of samples:  61\n",
      "uce in bin  10  : 0.0 , number of samples:  61\n",
      "uce in bin  11  : 8.217551639155829e-12 , number of samples:  60\n",
      "uce in bin  12  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  13  : 1.6709021319338824e-11 , number of samples:  61\n",
      "uce in bin  14  : 1.6435103278311658e-11 , number of samples:  60\n",
      "tensor([0.9473, 0.8722, 0.9349, 0.8932, 0.8834, 0.8426, 0.8522, 0.8271, 0.8544,\n",
      "        0.8628, 0.8497, 0.8991, 0.8574, 0.7780], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005041862459620461\n",
      "14 bins with tensor([9.8840e-05], device='cuda:0') UCE\n",
      "14 bins with 1.1844719648361206 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03758804 0.03883939 0.03974266 0.04038315 0.04102954\n",
      " 0.04148997 0.04190926 0.04260738 0.0431485  0.04364066 0.04436997\n",
      " 0.04510581 0.0462356  0.04782094 0.05490025]\n",
      "uce in bin  1  : 1.533942937947952e-11 , number of samples:  56\n",
      "uce in bin  2  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  3  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  4  : 0.0 , number of samples:  56\n",
      "uce in bin  5  : 0.0 , number of samples:  57\n",
      "uce in bin  6  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  7  : 0.0 , number of samples:  56\n",
      "uce in bin  8  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  9  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  10  : 7.66971468973976e-12 , number of samples:  56\n",
      "uce in bin  11  : 0.0 , number of samples:  57\n",
      "uce in bin  12  : 0.0 , number of samples:  57\n",
      "uce in bin  13  : 1.533942937947952e-11 , number of samples:  56\n",
      "uce in bin  14  : 0.0 , number of samples:  57\n",
      "uce in bin  15  : 1.533942937947952e-11 , number of samples:  56\n",
      "tensor([0.9525, 0.8999, 0.8713, 0.9614, 0.8665, 0.8645, 0.8401, 0.8180, 0.8466,\n",
      "        0.8678, 0.8601, 0.8054, 0.9511, 0.8329, 0.7801], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005359812712413259\n",
      "15 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "15 bins with 1.3868887424468994 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03739283 0.03877927 0.03959142 0.04027902 0.04081613\n",
      " 0.04132751 0.04174127 0.04220093 0.0428364  0.04336798 0.04382173\n",
      " 0.04446644 0.04530898 0.04642986 0.04793808 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  53\n",
      "uce in bin  2  : 0.0 , number of samples:  53\n",
      "uce in bin  3  : 0.0 , number of samples:  53\n",
      "uce in bin  4  : 7.258837628199011e-12 , number of samples:  53\n",
      "uce in bin  5  : 0.0 , number of samples:  53\n",
      "uce in bin  6  : 0.0 , number of samples:  53\n",
      "uce in bin  7  : 0.0 , number of samples:  53\n",
      "uce in bin  8  : 0.0 , number of samples:  54\n",
      "uce in bin  9  : 0.0 , number of samples:  53\n",
      "uce in bin  10  : 1.4517675256398022e-11 , number of samples:  53\n",
      "uce in bin  11  : 7.258837628199011e-12 , number of samples:  53\n",
      "uce in bin  12  : 1.4517675256398022e-11 , number of samples:  53\n",
      "uce in bin  13  : 7.258837628199011e-12 , number of samples:  53\n",
      "uce in bin  14  : 0.0 , number of samples:  53\n",
      "uce in bin  15  : 1.4517675256398022e-11 , number of samples:  53\n",
      "uce in bin  16  : 7.258837628199011e-12 , number of samples:  53\n",
      "tensor([0.9667, 0.8759, 0.8596, 0.9853, 0.8535, 0.8552, 0.8919, 0.8222, 0.8298,\n",
      "        0.8527, 0.8562, 0.8605, 0.8042, 0.9657, 0.8229, 0.7761],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.00444475699623581\n",
      "16 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "16 bins with 1.179811716079712 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03735686 0.0387038  0.03949024 0.04013795 0.0406526\n",
      " 0.04114018 0.0415368  0.04192781 0.04257943 0.0430803  0.04349529\n",
      " 0.04402716 0.04462811 0.04568613 0.04651846 0.0480996  0.05490025]\n",
      "uce in bin  1  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  2  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  3  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  4  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  5  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  6  : 0.0 , number of samples:  50\n",
      "uce in bin  7  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  8  : 0.0 , number of samples:  50\n",
      "uce in bin  9  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  10  : 0.0 , number of samples:  50\n",
      "uce in bin  11  : 0.0 , number of samples:  50\n",
      "uce in bin  12  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  13  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  14  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  15  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  16  : 0.0 , number of samples:  50\n",
      "uce in bin  17  : 1.3422001357565883e-11 , number of samples:  49\n",
      "tensor([0.9643, 0.8832, 0.8894, 0.9815, 0.8441, 0.8659, 0.8721, 0.8274, 0.8322,\n",
      "        0.8150, 0.8914, 0.8933, 0.8382, 0.8077, 0.9294, 0.8533, 0.7611],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.004361058381618932\n",
      "17 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "17 bins with 1.5179048776626587 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.0372903  0.03853986 0.0393443  0.04001301 0.04052238\n",
      " 0.04102954 0.04141849 0.04178748 0.04220093 0.04280239 0.0432357\n",
      " 0.04364066 0.04426047 0.04477942 0.04584211 0.04667186 0.04816676\n",
      " 0.05490025]\n",
      "uce in bin  1  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  2  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  3  : 0.0 , number of samples:  47\n",
      "uce in bin  4  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  5  : 6.574041658269358e-12 , number of samples:  48\n",
      "uce in bin  6  : 0.0 , number of samples:  47\n",
      "uce in bin  7  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  8  : 0.0 , number of samples:  47\n",
      "uce in bin  9  : 0.0 , number of samples:  48\n",
      "uce in bin  10  : 0.0 , number of samples:  47\n",
      "uce in bin  11  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  12  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  13  : 0.0 , number of samples:  47\n",
      "uce in bin  14  : 1.3148083316538717e-11 , number of samples:  48\n",
      "uce in bin  15  : 0.0 , number of samples:  47\n",
      "uce in bin  16  : 0.0 , number of samples:  47\n",
      "uce in bin  17  : 0.0 , number of samples:  47\n",
      "uce in bin  18  : 0.0 , number of samples:  47\n",
      "tensor([0.9431, 0.8983, 0.9078, 0.9459, 0.8836, 0.8836, 0.8336, 0.8773, 0.8318,\n",
      "        0.8414, 0.8459, 0.8551, 0.8286, 0.8704, 0.8892, 0.8902, 0.8493, 0.7543],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.007391966937575489\n",
      "18 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "18 bins with 1.437077283859253 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03717165 0.03847128 0.03919853 0.03984631 0.04035464\n",
      " 0.04086252 0.04128456 0.04160371 0.04195645 0.04255719 0.04295224\n",
      " 0.04340825 0.0438094  0.04439156 0.04492533 0.04594383 0.04680784\n",
      " 0.04827194 0.05490025]\n",
      "uce in bin  1  : 1.2052409417706578e-11 , number of samples:  44\n",
      "uce in bin  2  : 0.0 , number of samples:  45\n",
      "uce in bin  3  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  4  : 0.0 , number of samples:  44\n",
      "uce in bin  5  : 0.0 , number of samples:  45\n",
      "uce in bin  6  : 0.0 , number of samples:  45\n",
      "uce in bin  7  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  8  : 0.0 , number of samples:  44\n",
      "uce in bin  9  : 0.0 , number of samples:  45\n",
      "uce in bin  10  : 0.0 , number of samples:  45\n",
      "uce in bin  11  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  12  : 0.0 , number of samples:  44\n",
      "uce in bin  13  : 0.0 , number of samples:  45\n",
      "uce in bin  14  : 0.0 , number of samples:  45\n",
      "uce in bin  15  : 1.8489491188100615e-11 , number of samples:  45\n",
      "uce in bin  16  : 0.0 , number of samples:  44\n",
      "uce in bin  17  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  18  : 0.0 , number of samples:  45\n",
      "uce in bin  19  : 6.026204708853289e-12 , number of samples:  44\n",
      "tensor([0.9554, 0.9155, 0.8747, 0.9309, 0.9390, 0.8379, 0.8714, 0.8701, 0.8188,\n",
      "        0.8498, 0.8137, 0.8715, 0.8619, 0.8647, 0.8212, 0.9048, 0.8963, 0.8503,\n",
      "        0.7465], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005586453335126862\n",
      "19 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "19 bins with 1.484187126159668 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03714634 0.03843282 0.03910286 0.03974266 0.04027902\n",
      " 0.04070082 0.04112842 0.04148997 0.04182794 0.04220093 0.04271838\n",
      " 0.0431485  0.04351169 0.04398953 0.04446644 0.04510581 0.04603227\n",
      " 0.04691925 0.0484722  0.05490025]\n",
      "uce in bin  1  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  2  : 5.889245254658837e-12 , number of samples:  43\n",
      "uce in bin  3  : 0.0 , number of samples:  42\n",
      "uce in bin  4  : 5.889245254658837e-12 , number of samples:  43\n",
      "uce in bin  5  : 0.0 , number of samples:  42\n",
      "uce in bin  6  : 0.0 , number of samples:  43\n",
      "uce in bin  7  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  8  : 0.0 , number of samples:  43\n",
      "uce in bin  9  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  10  : 5.889245254658837e-12 , number of samples:  43\n",
      "uce in bin  11  : 0.0 , number of samples:  42\n",
      "uce in bin  12  : 0.0 , number of samples:  43\n",
      "uce in bin  13  : 1.1504572468290508e-11 , number of samples:  42\n",
      "uce in bin  14  : 0.0 , number of samples:  43\n",
      "uce in bin  15  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  16  : 0.0 , number of samples:  43\n",
      "uce in bin  17  : 0.0 , number of samples:  42\n",
      "uce in bin  18  : 0.0 , number of samples:  43\n",
      "uce in bin  19  : 0.0 , number of samples:  42\n",
      "uce in bin  20  : 5.752286234145254e-12 , number of samples:  42\n",
      "tensor([0.9679, 0.9037, 0.8447, 0.9125, 0.9824, 0.8453, 0.8897, 0.8708, 0.8364,\n",
      "        0.8367, 0.8602, 0.8072, 0.8592, 0.8944, 0.8269, 0.7957, 0.9635, 0.8521,\n",
      "        0.8490, 0.7548], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.00640117796137929\n",
      "20 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "20 bins with 1.3692647218704224 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.0371107  0.03836454 0.03901603 0.03963196 0.04017686\n",
      " 0.04061612 0.04102954 0.04136473 0.04164109 0.04196217 0.04252083\n",
      " 0.04291208 0.04333641 0.04364066 0.04410909 0.04459873 0.04527837\n",
      " 0.04611907 0.0470507  0.04859396 0.05490025]\n",
      "uce in bin  1  : 1.0956735518874439e-11 , number of samples:  40\n",
      "uce in bin  2  : 0.0 , number of samples:  40\n",
      "uce in bin  3  : 1.1230654427263342e-11 , number of samples:  41\n",
      "uce in bin  4  : 0.0 , number of samples:  40\n",
      "uce in bin  5  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  6  : 0.0 , number of samples:  40\n",
      "uce in bin  7  : 0.0 , number of samples:  41\n",
      "uce in bin  8  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  9  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  10  : 0.0 , number of samples:  40\n",
      "uce in bin  11  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  12  : 0.0 , number of samples:  40\n",
      "uce in bin  13  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  14  : 0.0 , number of samples:  40\n",
      "uce in bin  15  : 0.0 , number of samples:  41\n",
      "uce in bin  16  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  17  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  18  : 0.0 , number of samples:  40\n",
      "uce in bin  19  : 0.0 , number of samples:  41\n",
      "uce in bin  20  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  21  : 5.478367759437219e-12 , number of samples:  40\n",
      "tensor([0.9715, 0.8940, 0.8656, 0.8911, 1.0129, 0.8270, 0.8999, 0.8218, 0.8653,\n",
      "        0.8300, 0.8431, 0.8453, 0.8582, 0.8656, 0.8523, 0.8734, 0.7511, 0.9846,\n",
      "        0.8521, 0.8543, 0.7473], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.003710352029884234\n",
      "21 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "21 bins with 1.048384428024292 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03699935 0.03827366 0.03888163 0.0395275  0.04008555\n",
      " 0.04045991 0.04087854 0.0412123  0.0415174  0.04187584 0.04220093\n",
      " 0.04266999 0.04309418 0.04343626 0.0437853  0.04433504 0.04470373\n",
      " 0.04554641 0.04622195 0.04714209 0.04875836 0.05490025]\n",
      "uce in bin  1  : 5.2044492847291846e-12 , number of samples:  38\n",
      "uce in bin  2  : 0.0 , number of samples:  39\n",
      "uce in bin  3  : 0.0 , number of samples:  38\n",
      "uce in bin  4  : 0.0 , number of samples:  39\n",
      "uce in bin  5  : 0.0 , number of samples:  39\n",
      "uce in bin  6  : 5.2044492847291846e-12 , number of samples:  38\n",
      "uce in bin  7  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  8  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  9  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  10  : 0.0 , number of samples:  39\n",
      "uce in bin  11  : 1.0682817477847273e-11 , number of samples:  39\n",
      "uce in bin  12  : 0.0 , number of samples:  38\n",
      "uce in bin  13  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  14  : 1.0408898569458369e-11 , number of samples:  38\n",
      "uce in bin  15  : 1.0682817477847273e-11 , number of samples:  39\n",
      "uce in bin  16  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  17  : 1.0408898569458369e-11 , number of samples:  38\n",
      "uce in bin  18  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  19  : 0.0 , number of samples:  39\n",
      "uce in bin  20  : 0.0 , number of samples:  38\n",
      "uce in bin  21  : 0.0 , number of samples:  39\n",
      "uce in bin  22  : 5.2044492847291846e-12 , number of samples:  38\n",
      "tensor([0.9787, 0.8988, 0.8824, 0.8647, 1.0102, 0.8534, 0.8803, 0.8677, 0.8711,\n",
      "        0.8563, 0.8156, 0.8618, 0.7478, 0.8986, 0.8704, 0.8540, 0.8680, 0.7948,\n",
      "        0.9661, 0.8577, 0.8392, 0.7434], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005499077815329656\n",
      "22 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "22 bins with 1.1930643320083618 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03693046 0.03816176 0.03879927 0.03946559 0.03993529\n",
      " 0.04033316 0.04072777 0.041114   0.04143014 0.04170835 0.04200198\n",
      " 0.04249719 0.04286387 0.04323085 0.04352613 0.04391286 0.04440021\n",
      " 0.04483973 0.04573644 0.04628374 0.04724101 0.04888271 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  36\n",
      "uce in bin  2  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  3  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  4  : 0.0 , number of samples:  37\n",
      "uce in bin  5  : 0.0 , number of samples:  37\n",
      "uce in bin  6  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  7  : 0.0 , number of samples:  37\n",
      "uce in bin  8  : 0.0 , number of samples:  37\n",
      "uce in bin  9  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  10  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  11  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  12  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  13  : 0.0 , number of samples:  37\n",
      "uce in bin  14  : 0.0 , number of samples:  37\n",
      "uce in bin  15  : 0.0 , number of samples:  37\n",
      "uce in bin  16  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  17  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  18  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  19  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  20  : 0.0 , number of samples:  37\n",
      "uce in bin  21  : 0.0 , number of samples:  37\n",
      "uce in bin  22  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  23  : 0.0 , number of samples:  36\n",
      "tensor([0.9703, 0.9100, 0.9035, 0.8787, 0.9526, 0.9213, 0.8422, 0.8868, 0.8250,\n",
      "        0.8798, 0.8079, 0.8546, 0.8444, 0.8448, 0.8595, 0.8946, 0.8223, 0.8433,\n",
      "        0.8394, 0.9497, 0.8582, 0.8268, 0.7486], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.0033119442377937958\n",
      "23 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "23 bins with 1.0597243309020996 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03688534 0.03811063 0.03877927 0.0393443  0.03981887\n",
      " 0.04027902 0.04064623 0.04102954 0.04132751 0.04157097 0.04189624\n",
      " 0.04220093 0.04264931 0.04299221 0.04336798 0.04364066 0.04405021\n",
      " 0.04446644 0.04495535 0.04584211 0.04642986 0.04726971 0.04896568\n",
      " 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  35\n",
      "uce in bin  2  : 0.0 , number of samples:  35\n",
      "uce in bin  3  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  4  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  5  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  6  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  7  : 0.0 , number of samples:  35\n",
      "uce in bin  8  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  9  : 0.0 , number of samples:  35\n",
      "uce in bin  10  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  11  : 9.587143579015134e-12 , number of samples:  35\n",
      "uce in bin  12  : 0.0 , number of samples:  36\n",
      "uce in bin  13  : 0.0 , number of samples:  35\n",
      "uce in bin  14  : 0.0 , number of samples:  35\n",
      "uce in bin  15  : 0.0 , number of samples:  36\n",
      "uce in bin  16  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  17  : 0.0 , number of samples:  36\n",
      "uce in bin  18  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  19  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  20  : 0.0 , number of samples:  36\n",
      "uce in bin  21  : 0.0 , number of samples:  35\n",
      "uce in bin  22  : 9.861062487404038e-12 , number of samples:  36\n",
      "uce in bin  23  : 0.0 , number of samples:  35\n",
      "uce in bin  24  : 4.793571789507567e-12 , number of samples:  35\n",
      "tensor([0.9752, 0.9184, 0.8728, 0.9039, 0.9315, 0.9404, 0.8535, 0.8900, 0.8175,\n",
      "        0.8924, 0.8481, 0.8301, 0.8695, 0.7607, 0.8869, 0.8652, 0.8884, 0.8201,\n",
      "        0.8183, 0.9197, 0.9254, 0.8222, 0.8236, 0.7530], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.006843351729912683\n",
      "24 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "24 bins with 1.2398453950881958 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03974266 0.04148997 0.0431485  0.04510581 0.05490025]\n",
      "uce in bin  1  : 2.3283062977608182e-11 , number of samples:  170\n",
      "uce in bin  2  : 2.3283062977608182e-11 , number of samples:  170\n",
      "uce in bin  3  : 0.0 , number of samples:  170\n",
      "uce in bin  4  : 2.3283062977608182e-11 , number of samples:  170\n",
      "uce in bin  5  : 0.0 , number of samples:  169\n",
      "tensor([0.9057, 0.8973, 0.8350, 0.8441, 0.8532], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.0073337585490662605\n",
      "5 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "5 bins with 2.2110838890075684 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.0393443  0.04102954 0.04220093 0.04364066 0.04584211\n",
      " 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  141\n",
      "uce in bin  2  : 0.0 , number of samples:  142\n",
      "uce in bin  3  : 1.9448205199057433e-11 , number of samples:  142\n",
      "uce in bin  4  : 1.931124704590559e-11 , number of samples:  141\n",
      "uce in bin  5  : 3.889641039811487e-11 , number of samples:  142\n",
      "uce in bin  6  : 3.862249409181118e-11 , number of samples:  141\n",
      "tensor([0.9153, 0.9041, 0.8477, 0.8476, 0.8638, 0.8295], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.004964306936017238\n",
      "6 bins with tensor([8.4723e-05], device='cuda:0') UCE\n",
      "6 bins with 2.4065160751342773 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03901603 0.04061612 0.04164109 0.04291208 0.04410909\n",
      " 0.04611907 0.05490025]\n",
      "uce in bin  1  : 1.657206316618698e-11 , number of samples:  121\n",
      "uce in bin  2  : 3.314412633237396e-11 , number of samples:  121\n",
      "uce in bin  3  : 0.0 , number of samples:  122\n",
      "uce in bin  4  : 0.0 , number of samples:  121\n",
      "uce in bin  5  : 0.0 , number of samples:  122\n",
      "uce in bin  6  : 1.657206316618698e-11 , number of samples:  121\n",
      "uce in bin  7  : 3.314412633237396e-11 , number of samples:  121\n",
      "tensor([0.9077, 0.9140, 0.8630, 0.8396, 0.8586, 0.8755, 0.8168],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.004389879904920235\n",
      "7 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "7 bins with 2.476263999938965 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03877927 0.04027902 0.04132751 0.04220093 0.04336798\n",
      " 0.04446644 0.04642986 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  106\n",
      "uce in bin  2  : 1.4517675256398022e-11 , number of samples:  106\n",
      "uce in bin  3  : 0.0 , number of samples:  106\n",
      "uce in bin  4  : 1.4654633409549866e-11 , number of samples:  107\n",
      "uce in bin  5  : 1.4517675256398022e-11 , number of samples:  106\n",
      "uce in bin  6  : 0.0 , number of samples:  106\n",
      "uce in bin  7  : 1.4517675256398022e-11 , number of samples:  106\n",
      "uce in bin  8  : 1.4517675256398022e-11 , number of samples:  106\n",
      "tensor([0.9195, 0.9258, 0.8544, 0.8571, 0.8415, 0.8584, 0.8905, 0.7986],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.009560416219756007\n",
      "8 bins with tensor([7.6948e-05], device='cuda:0') UCE\n",
      "8 bins with 1.9511638879776 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03853986 0.04001301 0.04102954 0.04178748 0.04280239\n",
      " 0.04364066 0.04477942 0.04667186 0.05490025]\n",
      "uce in bin  1  : 1.2874164408149813e-11 , number of samples:  94\n",
      "uce in bin  2  : 0.0 , number of samples:  94\n",
      "uce in bin  3  : 1.3011123428663396e-11 , number of samples:  95\n",
      "uce in bin  4  : 0.0 , number of samples:  94\n",
      "uce in bin  5  : 1.3011123428663396e-11 , number of samples:  95\n",
      "uce in bin  6  : 0.0 , number of samples:  94\n",
      "uce in bin  7  : 0.0 , number of samples:  95\n",
      "uce in bin  8  : 0.0 , number of samples:  94\n",
      "uce in bin  9  : 2.5748328816299626e-11 , number of samples:  94\n",
      "tensor([0.9195, 0.9274, 0.8836, 0.8559, 0.8366, 0.8505, 0.8503, 0.8897, 0.8007],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.009096165740629658\n",
      "9 bins with tensor([7.7839e-05], device='cuda:0') UCE\n",
      "9 bins with 1.939469337463379 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03843282 0.03974266 0.04070082 0.04148997 0.04220093\n",
      " 0.0431485  0.04398953 0.04510581 0.04691925 0.05490025]\n",
      "uce in bin  1  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  2  : 0.0 , number of samples:  85\n",
      "uce in bin  3  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  4  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  5  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  6  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  7  : 2.3283062977608182e-11 , number of samples:  85\n",
      "uce in bin  8  : 0.0 , number of samples:  85\n",
      "uce in bin  9  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  10  : 1.1504572468290508e-11 , number of samples:  84\n",
      "tensor([0.9339, 0.8803, 0.9149, 0.8801, 0.8366, 0.8335, 0.8773, 0.8111, 0.9079,\n",
      "        0.8009], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005077945388620719\n",
      "10 bins with tensor([8.2039e-05], device='cuda:0') UCE\n",
      "10 bins with 1.8853943347930908 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03827366 0.0395275  0.04045991 0.0412123  0.04187584\n",
      " 0.04266999 0.04343626 0.04433504 0.04554641 0.04714209 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  77\n",
      "uce in bin  2  : 1.054585845733369e-11 , number of samples:  77\n",
      "uce in bin  3  : 0.0 , number of samples:  77\n",
      "uce in bin  4  : 1.0819776498360856e-11 , number of samples:  79\n",
      "uce in bin  5  : 1.0408898569458369e-11 , number of samples:  76\n",
      "uce in bin  6  : 1.054585845733369e-11 , number of samples:  77\n",
      "uce in bin  7  : 1.054585845733369e-11 , number of samples:  77\n",
      "uce in bin  8  : 1.0682817477847273e-11 , number of samples:  78\n",
      "uce in bin  9  : 0.0 , number of samples:  77\n",
      "uce in bin  10  : 2.109171691466738e-11 , number of samples:  77\n",
      "uce in bin  11  : 0.0 , number of samples:  77\n",
      "tensor([0.9365, 0.8733, 0.9352, 0.8739, 0.8635, 0.8390, 0.8264, 0.8621, 0.8313,\n",
      "        0.9134, 0.7909], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.007587010622955859\n",
      "11 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "11 bins with 1.423243761062622 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03811063 0.0393443  0.04027902 0.04102954 0.04157097\n",
      " 0.04220093 0.04299221 0.04364066 0.04446644 0.04584211 0.04726971\n",
      " 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  70\n",
      "uce in bin  2  : 0.0 , number of samples:  71\n",
      "uce in bin  3  : 1.9448205199057433e-11 , number of samples:  71\n",
      "uce in bin  4  : 9.724102599528717e-12 , number of samples:  71\n",
      "uce in bin  5  : 1.9448205199057433e-11 , number of samples:  71\n",
      "uce in bin  6  : 0.0 , number of samples:  71\n",
      "uce in bin  7  : 1.9174287158030268e-11 , number of samples:  70\n",
      "uce in bin  8  : 0.0 , number of samples:  71\n",
      "uce in bin  9  : 0.0 , number of samples:  71\n",
      "uce in bin  10  : 1.9448205199057433e-11 , number of samples:  71\n",
      "uce in bin  11  : 9.724102599528717e-12 , number of samples:  71\n",
      "uce in bin  12  : 9.587143579015134e-12 , number of samples:  70\n",
      "tensor([0.9453, 0.8885, 0.9360, 0.8724, 0.8566, 0.8390, 0.8165, 0.8762, 0.8551,\n",
      "        0.8720, 0.8738, 0.7874], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.0074315088568255305\n",
      "12 bins with tensor([9.3942e-05], device='cuda:0') UCE\n",
      "12 bins with 1.6821627616882324 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03788432 0.03915853 0.04011369 0.04076396 0.04139863\n",
      " 0.04190108 0.04262602 0.04329034 0.04386971 0.0446565  0.04599188\n",
      " 0.04745675 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  65\n",
      "uce in bin  2  : 8.902347609085481e-12 , number of samples:  65\n",
      "uce in bin  3  : 0.0 , number of samples:  66\n",
      "uce in bin  4  : 8.902347609085481e-12 , number of samples:  65\n",
      "uce in bin  5  : 0.0 , number of samples:  65\n",
      "uce in bin  6  : 0.0 , number of samples:  66\n",
      "uce in bin  7  : 1.7804695218170963e-11 , number of samples:  65\n",
      "uce in bin  8  : 0.0 , number of samples:  66\n",
      "uce in bin  9  : 0.0 , number of samples:  65\n",
      "uce in bin  10  : 1.7804695218170963e-11 , number of samples:  65\n",
      "uce in bin  11  : 0.0 , number of samples:  66\n",
      "uce in bin  12  : 8.902347609085481e-12 , number of samples:  65\n",
      "uce in bin  13  : 8.902347609085481e-12 , number of samples:  65\n",
      "tensor([0.9434, 0.8920, 0.9465, 0.8599, 0.8560, 0.8574, 0.8504, 0.8371, 0.8554,\n",
      "        0.8603, 0.8628, 0.8841, 0.7820], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.007287979678949341\n",
      "13 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "13 bins with 1.468324899673462 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03771835 0.03901603 0.03988922 0.04061612 0.04117621\n",
      " 0.04164109 0.04220093 0.04291208 0.04347522 0.04410909 0.04487395\n",
      " 0.04611907 0.04760478 0.05490025]\n",
      "uce in bin  1  : 8.217551639155829e-12 , number of samples:  60\n",
      "uce in bin  2  : 0.0 , number of samples:  61\n",
      "uce in bin  3  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  4  : 8.217551639155829e-12 , number of samples:  60\n",
      "uce in bin  5  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  6  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  7  : 0.0 , number of samples:  61\n",
      "uce in bin  8  : 1.6435103278311658e-11 , number of samples:  60\n",
      "uce in bin  9  : 0.0 , number of samples:  61\n",
      "uce in bin  10  : 0.0 , number of samples:  61\n",
      "uce in bin  11  : 8.217551639155829e-12 , number of samples:  60\n",
      "uce in bin  12  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  13  : 1.6709021319338824e-11 , number of samples:  61\n",
      "uce in bin  14  : 1.6435103278311658e-11 , number of samples:  60\n",
      "tensor([0.9473, 0.8722, 0.9349, 0.8932, 0.8834, 0.8426, 0.8522, 0.8271, 0.8544,\n",
      "        0.8628, 0.8497, 0.8991, 0.8574, 0.7780], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005041862459620461\n",
      "14 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "14 bins with 1.592123031616211 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03758804 0.03883939 0.03974266 0.04038315 0.04102954\n",
      " 0.04148997 0.04190926 0.04260738 0.0431485  0.04364066 0.04436997\n",
      " 0.04510581 0.0462356  0.04782094 0.05490025]\n",
      "uce in bin  1  : 1.533942937947952e-11 , number of samples:  56\n",
      "uce in bin  2  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  3  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  4  : 0.0 , number of samples:  56\n",
      "uce in bin  5  : 0.0 , number of samples:  57\n",
      "uce in bin  6  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  7  : 0.0 , number of samples:  56\n",
      "uce in bin  8  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  9  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  10  : 7.66971468973976e-12 , number of samples:  56\n",
      "uce in bin  11  : 0.0 , number of samples:  57\n",
      "uce in bin  12  : 0.0 , number of samples:  57\n",
      "uce in bin  13  : 1.533942937947952e-11 , number of samples:  56\n",
      "uce in bin  14  : 0.0 , number of samples:  57\n",
      "uce in bin  15  : 1.533942937947952e-11 , number of samples:  56\n",
      "tensor([0.9525, 0.8999, 0.8713, 0.9614, 0.8665, 0.8645, 0.8401, 0.8180, 0.8466,\n",
      "        0.8678, 0.8601, 0.8054, 0.9511, 0.8329, 0.7801], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005359812712413259\n",
      "15 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "15 bins with 1.8015028238296509 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03739283 0.03877927 0.03959142 0.04027902 0.04081613\n",
      " 0.04132751 0.04174127 0.04220093 0.0428364  0.04336798 0.04382173\n",
      " 0.04446644 0.04530898 0.04642986 0.04793808 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  53\n",
      "uce in bin  2  : 0.0 , number of samples:  53\n",
      "uce in bin  3  : 0.0 , number of samples:  53\n",
      "uce in bin  4  : 7.258837628199011e-12 , number of samples:  53\n",
      "uce in bin  5  : 0.0 , number of samples:  53\n",
      "uce in bin  6  : 0.0 , number of samples:  53\n",
      "uce in bin  7  : 0.0 , number of samples:  53\n",
      "uce in bin  8  : 0.0 , number of samples:  54\n",
      "uce in bin  9  : 0.0 , number of samples:  53\n",
      "uce in bin  10  : 1.4517675256398022e-11 , number of samples:  53\n",
      "uce in bin  11  : 7.258837628199011e-12 , number of samples:  53\n",
      "uce in bin  12  : 1.4517675256398022e-11 , number of samples:  53\n",
      "uce in bin  13  : 7.258837628199011e-12 , number of samples:  53\n",
      "uce in bin  14  : 0.0 , number of samples:  53\n",
      "uce in bin  15  : 1.4517675256398022e-11 , number of samples:  53\n",
      "uce in bin  16  : 7.258837628199011e-12 , number of samples:  53\n",
      "tensor([0.9667, 0.8759, 0.8596, 0.9853, 0.8535, 0.8552, 0.8919, 0.8222, 0.8298,\n",
      "        0.8527, 0.8562, 0.8605, 0.8042, 0.9657, 0.8229, 0.7761],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.00444475699623581\n",
      "16 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "16 bins with 1.9176667928695679 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03735686 0.0387038  0.03949024 0.04013795 0.0406526\n",
      " 0.04114018 0.0415368  0.04192781 0.04257943 0.0430803  0.04349529\n",
      " 0.04402716 0.04462811 0.04568613 0.04651846 0.0480996  0.05490025]\n",
      "uce in bin  1  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  2  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  3  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  4  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  5  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  6  : 0.0 , number of samples:  50\n",
      "uce in bin  7  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  8  : 0.0 , number of samples:  50\n",
      "uce in bin  9  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  10  : 0.0 , number of samples:  50\n",
      "uce in bin  11  : 0.0 , number of samples:  50\n",
      "uce in bin  12  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  13  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  14  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  15  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  16  : 0.0 , number of samples:  50\n",
      "uce in bin  17  : 1.3422001357565883e-11 , number of samples:  49\n",
      "tensor([0.9643, 0.8832, 0.8894, 0.9815, 0.8441, 0.8659, 0.8721, 0.8274, 0.8322,\n",
      "        0.8150, 0.8914, 0.8933, 0.8382, 0.8077, 0.9294, 0.8533, 0.7611],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.004361058381618932\n",
      "17 bins with tensor([9.0404e-05], device='cuda:0') UCE\n",
      "17 bins with 1.460391640663147 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.0372903  0.03853986 0.0393443  0.04001301 0.04052238\n",
      " 0.04102954 0.04141849 0.04178748 0.04220093 0.04280239 0.0432357\n",
      " 0.04364066 0.04426047 0.04477942 0.04584211 0.04667186 0.04816676\n",
      " 0.05490025]\n",
      "uce in bin  1  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  2  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  3  : 0.0 , number of samples:  47\n",
      "uce in bin  4  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  5  : 6.574041658269358e-12 , number of samples:  48\n",
      "uce in bin  6  : 0.0 , number of samples:  47\n",
      "uce in bin  7  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  8  : 0.0 , number of samples:  47\n",
      "uce in bin  9  : 0.0 , number of samples:  48\n",
      "uce in bin  10  : 0.0 , number of samples:  47\n",
      "uce in bin  11  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  12  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  13  : 0.0 , number of samples:  47\n",
      "uce in bin  14  : 1.3148083316538717e-11 , number of samples:  48\n",
      "uce in bin  15  : 0.0 , number of samples:  47\n",
      "uce in bin  16  : 0.0 , number of samples:  47\n",
      "uce in bin  17  : 0.0 , number of samples:  47\n",
      "uce in bin  18  : 0.0 , number of samples:  47\n",
      "tensor([0.9431, 0.8983, 0.9078, 0.9459, 0.8836, 0.8836, 0.8336, 0.8773, 0.8318,\n",
      "        0.8414, 0.8459, 0.8551, 0.8286, 0.8704, 0.8892, 0.8902, 0.8493, 0.7543],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.007391966937575489\n",
      "18 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "18 bins with 1.2284334897994995 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03717165 0.03847128 0.03919853 0.03984631 0.04035464\n",
      " 0.04086252 0.04128456 0.04160371 0.04195645 0.04255719 0.04295224\n",
      " 0.04340825 0.0438094  0.04439156 0.04492533 0.04594383 0.04680784\n",
      " 0.04827194 0.05490025]\n",
      "uce in bin  1  : 1.2052409417706578e-11 , number of samples:  44\n",
      "uce in bin  2  : 0.0 , number of samples:  45\n",
      "uce in bin  3  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  4  : 0.0 , number of samples:  44\n",
      "uce in bin  5  : 0.0 , number of samples:  45\n",
      "uce in bin  6  : 0.0 , number of samples:  45\n",
      "uce in bin  7  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  8  : 0.0 , number of samples:  44\n",
      "uce in bin  9  : 0.0 , number of samples:  45\n",
      "uce in bin  10  : 0.0 , number of samples:  45\n",
      "uce in bin  11  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  12  : 0.0 , number of samples:  44\n",
      "uce in bin  13  : 0.0 , number of samples:  45\n",
      "uce in bin  14  : 0.0 , number of samples:  45\n",
      "uce in bin  15  : 1.8489491188100615e-11 , number of samples:  45\n",
      "uce in bin  16  : 0.0 , number of samples:  44\n",
      "uce in bin  17  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  18  : 0.0 , number of samples:  45\n",
      "uce in bin  19  : 6.026204708853289e-12 , number of samples:  44\n",
      "tensor([0.9554, 0.9155, 0.8747, 0.9309, 0.9390, 0.8379, 0.8714, 0.8701, 0.8188,\n",
      "        0.8498, 0.8137, 0.8715, 0.8619, 0.8647, 0.8212, 0.9048, 0.8963, 0.8503,\n",
      "        0.7465], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005586453335126862\n",
      "19 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "19 bins with 1.2716777324676514 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03714634 0.03843282 0.03910286 0.03974266 0.04027902\n",
      " 0.04070082 0.04112842 0.04148997 0.04182794 0.04220093 0.04271838\n",
      " 0.0431485  0.04351169 0.04398953 0.04446644 0.04510581 0.04603227\n",
      " 0.04691925 0.0484722  0.05490025]\n",
      "uce in bin  1  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  2  : 5.889245254658837e-12 , number of samples:  43\n",
      "uce in bin  3  : 0.0 , number of samples:  42\n",
      "uce in bin  4  : 5.889245254658837e-12 , number of samples:  43\n",
      "uce in bin  5  : 0.0 , number of samples:  42\n",
      "uce in bin  6  : 0.0 , number of samples:  43\n",
      "uce in bin  7  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  8  : 0.0 , number of samples:  43\n",
      "uce in bin  9  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  10  : 5.889245254658837e-12 , number of samples:  43\n",
      "uce in bin  11  : 0.0 , number of samples:  42\n",
      "uce in bin  12  : 0.0 , number of samples:  43\n",
      "uce in bin  13  : 1.1504572468290508e-11 , number of samples:  42\n",
      "uce in bin  14  : 0.0 , number of samples:  43\n",
      "uce in bin  15  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  16  : 0.0 , number of samples:  43\n",
      "uce in bin  17  : 0.0 , number of samples:  42\n",
      "uce in bin  18  : 0.0 , number of samples:  43\n",
      "uce in bin  19  : 0.0 , number of samples:  42\n",
      "uce in bin  20  : 5.752286234145254e-12 , number of samples:  42\n",
      "tensor([0.9679, 0.9037, 0.8447, 0.9125, 0.9824, 0.8453, 0.8897, 0.8708, 0.8364,\n",
      "        0.8367, 0.8602, 0.8072, 0.8592, 0.8944, 0.8269, 0.7957, 0.9635, 0.8521,\n",
      "        0.8490, 0.7548], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.00640117796137929\n",
      "20 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "20 bins with 1.0953195095062256 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.0371107  0.03836454 0.03901603 0.03963196 0.04017686\n",
      " 0.04061612 0.04102954 0.04136473 0.04164109 0.04196217 0.04252083\n",
      " 0.04291208 0.04333641 0.04364066 0.04410909 0.04459873 0.04527837\n",
      " 0.04611907 0.0470507  0.04859396 0.05490025]\n",
      "uce in bin  1  : 1.0956735518874439e-11 , number of samples:  40\n",
      "uce in bin  2  : 0.0 , number of samples:  40\n",
      "uce in bin  3  : 1.1230654427263342e-11 , number of samples:  41\n",
      "uce in bin  4  : 0.0 , number of samples:  40\n",
      "uce in bin  5  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  6  : 0.0 , number of samples:  40\n",
      "uce in bin  7  : 0.0 , number of samples:  41\n",
      "uce in bin  8  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  9  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  10  : 0.0 , number of samples:  40\n",
      "uce in bin  11  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  12  : 0.0 , number of samples:  40\n",
      "uce in bin  13  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  14  : 0.0 , number of samples:  40\n",
      "uce in bin  15  : 0.0 , number of samples:  41\n",
      "uce in bin  16  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  17  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  18  : 0.0 , number of samples:  40\n",
      "uce in bin  19  : 0.0 , number of samples:  41\n",
      "uce in bin  20  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  21  : 5.478367759437219e-12 , number of samples:  40\n",
      "tensor([0.9715, 0.8940, 0.8656, 0.8911, 1.0129, 0.8270, 0.8999, 0.8218, 0.8653,\n",
      "        0.8300, 0.8431, 0.8453, 0.8582, 0.8656, 0.8523, 0.8734, 0.7511, 0.9846,\n",
      "        0.8521, 0.8543, 0.7473], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.003710352029884234\n",
      "21 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "21 bins with 0.9264362454414368 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03699935 0.03827366 0.03888163 0.0395275  0.04008555\n",
      " 0.04045991 0.04087854 0.0412123  0.0415174  0.04187584 0.04220093\n",
      " 0.04266999 0.04309418 0.04343626 0.0437853  0.04433504 0.04470373\n",
      " 0.04554641 0.04622195 0.04714209 0.04875836 0.05490025]\n",
      "uce in bin  1  : 5.2044492847291846e-12 , number of samples:  38\n",
      "uce in bin  2  : 0.0 , number of samples:  39\n",
      "uce in bin  3  : 0.0 , number of samples:  38\n",
      "uce in bin  4  : 0.0 , number of samples:  39\n",
      "uce in bin  5  : 0.0 , number of samples:  39\n",
      "uce in bin  6  : 5.2044492847291846e-12 , number of samples:  38\n",
      "uce in bin  7  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  8  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  9  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  10  : 0.0 , number of samples:  39\n",
      "uce in bin  11  : 1.0682817477847273e-11 , number of samples:  39\n",
      "uce in bin  12  : 0.0 , number of samples:  38\n",
      "uce in bin  13  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  14  : 1.0408898569458369e-11 , number of samples:  38\n",
      "uce in bin  15  : 1.0682817477847273e-11 , number of samples:  39\n",
      "uce in bin  16  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  17  : 1.0408898569458369e-11 , number of samples:  38\n",
      "uce in bin  18  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  19  : 0.0 , number of samples:  39\n",
      "uce in bin  20  : 0.0 , number of samples:  38\n",
      "uce in bin  21  : 0.0 , number of samples:  39\n",
      "uce in bin  22  : 5.2044492847291846e-12 , number of samples:  38\n",
      "tensor([0.9787, 0.8988, 0.8824, 0.8647, 1.0102, 0.8534, 0.8803, 0.8677, 0.8711,\n",
      "        0.8563, 0.8156, 0.8618, 0.7478, 0.8986, 0.8704, 0.8540, 0.8680, 0.7948,\n",
      "        0.9661, 0.8577, 0.8392, 0.7434], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005499077815329656\n",
      "22 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "22 bins with 0.6275407075881958 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03693046 0.03816176 0.03879927 0.03946559 0.03993529\n",
      " 0.04033316 0.04072777 0.041114   0.04143014 0.04170835 0.04200198\n",
      " 0.04249719 0.04286387 0.04323085 0.04352613 0.04391286 0.04440021\n",
      " 0.04483973 0.04573644 0.04628374 0.04724101 0.04888271 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  36\n",
      "uce in bin  2  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  3  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  4  : 0.0 , number of samples:  37\n",
      "uce in bin  5  : 0.0 , number of samples:  37\n",
      "uce in bin  6  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  7  : 0.0 , number of samples:  37\n",
      "uce in bin  8  : 0.0 , number of samples:  37\n",
      "uce in bin  9  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  10  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  11  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  12  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  13  : 0.0 , number of samples:  37\n",
      "uce in bin  14  : 0.0 , number of samples:  37\n",
      "uce in bin  15  : 0.0 , number of samples:  37\n",
      "uce in bin  16  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  17  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  18  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  19  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  20  : 0.0 , number of samples:  37\n",
      "uce in bin  21  : 0.0 , number of samples:  37\n",
      "uce in bin  22  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  23  : 0.0 , number of samples:  36\n",
      "tensor([0.9703, 0.9100, 0.9035, 0.8787, 0.9526, 0.9213, 0.8422, 0.8868, 0.8250,\n",
      "        0.8798, 0.8079, 0.8546, 0.8444, 0.8448, 0.8595, 0.8946, 0.8223, 0.8433,\n",
      "        0.8394, 0.9497, 0.8582, 0.8268, 0.7486], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.0033119442377937958\n",
      "23 bins with tensor([7.0284e-05], device='cuda:0') UCE\n",
      "23 bins with 0.7472270727157593 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03688534 0.03811063 0.03877927 0.0393443  0.03981887\n",
      " 0.04027902 0.04064623 0.04102954 0.04132751 0.04157097 0.04189624\n",
      " 0.04220093 0.04264931 0.04299221 0.04336798 0.04364066 0.04405021\n",
      " 0.04446644 0.04495535 0.04584211 0.04642986 0.04726971 0.04896568\n",
      " 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  35\n",
      "uce in bin  2  : 0.0 , number of samples:  35\n",
      "uce in bin  3  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  4  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  5  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  6  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  7  : 0.0 , number of samples:  35\n",
      "uce in bin  8  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  9  : 0.0 , number of samples:  35\n",
      "uce in bin  10  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  11  : 9.587143579015134e-12 , number of samples:  35\n",
      "uce in bin  12  : 0.0 , number of samples:  36\n",
      "uce in bin  13  : 0.0 , number of samples:  35\n",
      "uce in bin  14  : 0.0 , number of samples:  35\n",
      "uce in bin  15  : 0.0 , number of samples:  36\n",
      "uce in bin  16  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  17  : 0.0 , number of samples:  36\n",
      "uce in bin  18  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  19  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  20  : 0.0 , number of samples:  36\n",
      "uce in bin  21  : 0.0 , number of samples:  35\n",
      "uce in bin  22  : 9.861062487404038e-12 , number of samples:  36\n",
      "uce in bin  23  : 0.0 , number of samples:  35\n",
      "uce in bin  24  : 4.793571789507567e-12 , number of samples:  35\n",
      "tensor([0.9752, 0.9184, 0.8728, 0.9039, 0.9315, 0.9404, 0.8535, 0.8900, 0.8175,\n",
      "        0.8924, 0.8481, 0.8301, 0.8695, 0.7607, 0.8869, 0.8652, 0.8884, 0.8201,\n",
      "        0.8183, 0.9197, 0.9254, 0.8222, 0.8236, 0.7530], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.006843351729912683\n",
      "24 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "24 bins with 0.8543988466262817 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03974266 0.04148997 0.0431485  0.04510581 0.05490025]\n",
      "uce in bin  1  : 2.3283062977608182e-11 , number of samples:  170\n",
      "uce in bin  2  : 2.3283062977608182e-11 , number of samples:  170\n",
      "uce in bin  3  : 0.0 , number of samples:  170\n",
      "uce in bin  4  : 2.3283062977608182e-11 , number of samples:  170\n",
      "uce in bin  5  : 0.0 , number of samples:  169\n",
      "tensor([0.9057, 0.8973, 0.8350, 0.8441, 0.8532], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.0073337585490662605\n",
      "5 bins with tensor([9.9582e-05], device='cuda:0') UCE\n",
      "5 bins with 1.912156581878662 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.0393443  0.04102954 0.04220093 0.04364066 0.04584211\n",
      " 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  141\n",
      "uce in bin  2  : 0.0 , number of samples:  142\n",
      "uce in bin  3  : 1.9448205199057433e-11 , number of samples:  142\n",
      "uce in bin  4  : 1.931124704590559e-11 , number of samples:  141\n",
      "uce in bin  5  : 3.889641039811487e-11 , number of samples:  142\n",
      "uce in bin  6  : 3.862249409181118e-11 , number of samples:  141\n",
      "tensor([0.9153, 0.9041, 0.8477, 0.8476, 0.8638, 0.8295], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.004964306936017238\n",
      "6 bins with tensor([8.9276e-05], device='cuda:0') UCE\n",
      "6 bins with 1.9457603693008423 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03901603 0.04061612 0.04164109 0.04291208 0.04410909\n",
      " 0.04611907 0.05490025]\n",
      "uce in bin  1  : 1.657206316618698e-11 , number of samples:  121\n",
      "uce in bin  2  : 3.314412633237396e-11 , number of samples:  121\n",
      "uce in bin  3  : 0.0 , number of samples:  122\n",
      "uce in bin  4  : 0.0 , number of samples:  121\n",
      "uce in bin  5  : 0.0 , number of samples:  122\n",
      "uce in bin  6  : 1.657206316618698e-11 , number of samples:  121\n",
      "uce in bin  7  : 3.314412633237396e-11 , number of samples:  121\n",
      "tensor([0.9077, 0.9140, 0.8630, 0.8396, 0.8586, 0.8755, 0.8168],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.004389879904920235\n",
      "7 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "7 bins with 1.9630870819091797 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03877927 0.04027902 0.04132751 0.04220093 0.04336798\n",
      " 0.04446644 0.04642986 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  106\n",
      "uce in bin  2  : 1.4517675256398022e-11 , number of samples:  106\n",
      "uce in bin  3  : 0.0 , number of samples:  106\n",
      "uce in bin  4  : 1.4654633409549866e-11 , number of samples:  107\n",
      "uce in bin  5  : 1.4517675256398022e-11 , number of samples:  106\n",
      "uce in bin  6  : 0.0 , number of samples:  106\n",
      "uce in bin  7  : 1.4517675256398022e-11 , number of samples:  106\n",
      "uce in bin  8  : 1.4517675256398022e-11 , number of samples:  106\n",
      "tensor([0.9195, 0.9258, 0.8544, 0.8571, 0.8415, 0.8584, 0.8905, 0.7986],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.009560416219756007\n",
      "8 bins with tensor([9.3410e-05], device='cuda:0') UCE\n",
      "8 bins with 1.3480178117752075 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03853986 0.04001301 0.04102954 0.04178748 0.04280239\n",
      " 0.04364066 0.04477942 0.04667186 0.05490025]\n",
      "uce in bin  1  : 1.2874164408149813e-11 , number of samples:  94\n",
      "uce in bin  2  : 0.0 , number of samples:  94\n",
      "uce in bin  3  : 1.3011123428663396e-11 , number of samples:  95\n",
      "uce in bin  4  : 0.0 , number of samples:  94\n",
      "uce in bin  5  : 1.3011123428663396e-11 , number of samples:  95\n",
      "uce in bin  6  : 0.0 , number of samples:  94\n",
      "uce in bin  7  : 0.0 , number of samples:  95\n",
      "uce in bin  8  : 0.0 , number of samples:  94\n",
      "uce in bin  9  : 2.5748328816299626e-11 , number of samples:  94\n",
      "tensor([0.9195, 0.9274, 0.8836, 0.8559, 0.8366, 0.8505, 0.8503, 0.8897, 0.8007],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.009096165740629658\n",
      "9 bins with tensor([7.2382e-05], device='cuda:0') UCE\n",
      "9 bins with 1.2659004926681519 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03843282 0.03974266 0.04070082 0.04148997 0.04220093\n",
      " 0.0431485  0.04398953 0.04510581 0.04691925 0.05490025]\n",
      "uce in bin  1  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  2  : 0.0 , number of samples:  85\n",
      "uce in bin  3  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  4  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  5  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  6  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  7  : 2.3283062977608182e-11 , number of samples:  85\n",
      "uce in bin  8  : 0.0 , number of samples:  85\n",
      "uce in bin  9  : 1.1641531488804091e-11 , number of samples:  85\n",
      "uce in bin  10  : 1.1504572468290508e-11 , number of samples:  84\n",
      "tensor([0.9339, 0.8803, 0.9149, 0.8801, 0.8366, 0.8335, 0.8773, 0.8111, 0.9079,\n",
      "        0.8009], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005077945388620719\n",
      "10 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "10 bins with 1.6452933549880981 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03827366 0.0395275  0.04045991 0.0412123  0.04187584\n",
      " 0.04266999 0.04343626 0.04433504 0.04554641 0.04714209 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  77\n",
      "uce in bin  2  : 1.054585845733369e-11 , number of samples:  77\n",
      "uce in bin  3  : 0.0 , number of samples:  77\n",
      "uce in bin  4  : 1.0819776498360856e-11 , number of samples:  79\n",
      "uce in bin  5  : 1.0408898569458369e-11 , number of samples:  76\n",
      "uce in bin  6  : 1.054585845733369e-11 , number of samples:  77\n",
      "uce in bin  7  : 1.054585845733369e-11 , number of samples:  77\n",
      "uce in bin  8  : 1.0682817477847273e-11 , number of samples:  78\n",
      "uce in bin  9  : 0.0 , number of samples:  77\n",
      "uce in bin  10  : 2.109171691466738e-11 , number of samples:  77\n",
      "uce in bin  11  : 0.0 , number of samples:  77\n",
      "tensor([0.9365, 0.8733, 0.9352, 0.8739, 0.8635, 0.8390, 0.8264, 0.8621, 0.8313,\n",
      "        0.9134, 0.7909], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.007587010622955859\n",
      "11 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "11 bins with 1.8972257375717163 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03811063 0.0393443  0.04027902 0.04102954 0.04157097\n",
      " 0.04220093 0.04299221 0.04364066 0.04446644 0.04584211 0.04726971\n",
      " 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  70\n",
      "uce in bin  2  : 0.0 , number of samples:  71\n",
      "uce in bin  3  : 1.9448205199057433e-11 , number of samples:  71\n",
      "uce in bin  4  : 9.724102599528717e-12 , number of samples:  71\n",
      "uce in bin  5  : 1.9448205199057433e-11 , number of samples:  71\n",
      "uce in bin  6  : 0.0 , number of samples:  71\n",
      "uce in bin  7  : 1.9174287158030268e-11 , number of samples:  70\n",
      "uce in bin  8  : 0.0 , number of samples:  71\n",
      "uce in bin  9  : 0.0 , number of samples:  71\n",
      "uce in bin  10  : 1.9448205199057433e-11 , number of samples:  71\n",
      "uce in bin  11  : 9.724102599528717e-12 , number of samples:  71\n",
      "uce in bin  12  : 9.587143579015134e-12 , number of samples:  70\n",
      "tensor([0.9453, 0.8885, 0.9360, 0.8724, 0.8566, 0.8390, 0.8165, 0.8762, 0.8551,\n",
      "        0.8720, 0.8738, 0.7874], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.0074315088568255305\n",
      "12 bins with tensor([8.4986e-05], device='cuda:0') UCE\n",
      "12 bins with 1.40370774269104 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03788432 0.03915853 0.04011369 0.04076396 0.04139863\n",
      " 0.04190108 0.04262602 0.04329034 0.04386971 0.0446565  0.04599188\n",
      " 0.04745675 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  65\n",
      "uce in bin  2  : 8.902347609085481e-12 , number of samples:  65\n",
      "uce in bin  3  : 0.0 , number of samples:  66\n",
      "uce in bin  4  : 8.902347609085481e-12 , number of samples:  65\n",
      "uce in bin  5  : 0.0 , number of samples:  65\n",
      "uce in bin  6  : 0.0 , number of samples:  66\n",
      "uce in bin  7  : 1.7804695218170963e-11 , number of samples:  65\n",
      "uce in bin  8  : 0.0 , number of samples:  66\n",
      "uce in bin  9  : 0.0 , number of samples:  65\n",
      "uce in bin  10  : 1.7804695218170963e-11 , number of samples:  65\n",
      "uce in bin  11  : 0.0 , number of samples:  66\n",
      "uce in bin  12  : 8.902347609085481e-12 , number of samples:  65\n",
      "uce in bin  13  : 8.902347609085481e-12 , number of samples:  65\n",
      "tensor([0.9434, 0.8920, 0.9465, 0.8599, 0.8560, 0.8574, 0.8504, 0.8371, 0.8554,\n",
      "        0.8603, 0.8628, 0.8841, 0.7820], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.007287979678949341\n",
      "13 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "13 bins with 2.0863447189331055 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03771835 0.03901603 0.03988922 0.04061612 0.04117621\n",
      " 0.04164109 0.04220093 0.04291208 0.04347522 0.04410909 0.04487395\n",
      " 0.04611907 0.04760478 0.05490025]\n",
      "uce in bin  1  : 8.217551639155829e-12 , number of samples:  60\n",
      "uce in bin  2  : 0.0 , number of samples:  61\n",
      "uce in bin  3  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  4  : 8.217551639155829e-12 , number of samples:  60\n",
      "uce in bin  5  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  6  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  7  : 0.0 , number of samples:  61\n",
      "uce in bin  8  : 1.6435103278311658e-11 , number of samples:  60\n",
      "uce in bin  9  : 0.0 , number of samples:  61\n",
      "uce in bin  10  : 0.0 , number of samples:  61\n",
      "uce in bin  11  : 8.217551639155829e-12 , number of samples:  60\n",
      "uce in bin  12  : 8.354510659669412e-12 , number of samples:  61\n",
      "uce in bin  13  : 1.6709021319338824e-11 , number of samples:  61\n",
      "uce in bin  14  : 1.6435103278311658e-11 , number of samples:  60\n",
      "tensor([0.9473, 0.8722, 0.9349, 0.8932, 0.8834, 0.8426, 0.8522, 0.8271, 0.8544,\n",
      "        0.8628, 0.8497, 0.8991, 0.8574, 0.7780], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005041862459620461\n",
      "14 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "14 bins with 1.746590256690979 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03758804 0.03883939 0.03974266 0.04038315 0.04102954\n",
      " 0.04148997 0.04190926 0.04260738 0.0431485  0.04364066 0.04436997\n",
      " 0.04510581 0.0462356  0.04782094 0.05490025]\n",
      "uce in bin  1  : 1.533942937947952e-11 , number of samples:  56\n",
      "uce in bin  2  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  3  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  4  : 0.0 , number of samples:  56\n",
      "uce in bin  5  : 0.0 , number of samples:  57\n",
      "uce in bin  6  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  7  : 0.0 , number of samples:  56\n",
      "uce in bin  8  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  9  : 7.80667457761508e-12 , number of samples:  57\n",
      "uce in bin  10  : 7.66971468973976e-12 , number of samples:  56\n",
      "uce in bin  11  : 0.0 , number of samples:  57\n",
      "uce in bin  12  : 0.0 , number of samples:  57\n",
      "uce in bin  13  : 1.533942937947952e-11 , number of samples:  56\n",
      "uce in bin  14  : 0.0 , number of samples:  57\n",
      "uce in bin  15  : 1.533942937947952e-11 , number of samples:  56\n",
      "tensor([0.9525, 0.8999, 0.8713, 0.9614, 0.8665, 0.8645, 0.8401, 0.8180, 0.8466,\n",
      "        0.8678, 0.8601, 0.8054, 0.9511, 0.8329, 0.7801], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005359812712413259\n",
      "15 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "15 bins with 1.8147494792938232 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03739283 0.03877927 0.03959142 0.04027902 0.04081613\n",
      " 0.04132751 0.04174127 0.04220093 0.0428364  0.04336798 0.04382173\n",
      " 0.04446644 0.04530898 0.04642986 0.04793808 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  53\n",
      "uce in bin  2  : 0.0 , number of samples:  53\n",
      "uce in bin  3  : 0.0 , number of samples:  53\n",
      "uce in bin  4  : 7.258837628199011e-12 , number of samples:  53\n",
      "uce in bin  5  : 0.0 , number of samples:  53\n",
      "uce in bin  6  : 0.0 , number of samples:  53\n",
      "uce in bin  7  : 0.0 , number of samples:  53\n",
      "uce in bin  8  : 0.0 , number of samples:  54\n",
      "uce in bin  9  : 0.0 , number of samples:  53\n",
      "uce in bin  10  : 1.4517675256398022e-11 , number of samples:  53\n",
      "uce in bin  11  : 7.258837628199011e-12 , number of samples:  53\n",
      "uce in bin  12  : 1.4517675256398022e-11 , number of samples:  53\n",
      "uce in bin  13  : 7.258837628199011e-12 , number of samples:  53\n",
      "uce in bin  14  : 0.0 , number of samples:  53\n",
      "uce in bin  15  : 1.4517675256398022e-11 , number of samples:  53\n",
      "uce in bin  16  : 7.258837628199011e-12 , number of samples:  53\n",
      "tensor([0.9667, 0.8759, 0.8596, 0.9853, 0.8535, 0.8552, 0.8919, 0.8222, 0.8298,\n",
      "        0.8527, 0.8562, 0.8605, 0.8042, 0.9657, 0.8229, 0.7761],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.00444475699623581\n",
      "16 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "16 bins with 1.7984544038772583 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03735686 0.0387038  0.03949024 0.04013795 0.0406526\n",
      " 0.04114018 0.0415368  0.04192781 0.04257943 0.0430803  0.04349529\n",
      " 0.04402716 0.04462811 0.04568613 0.04651846 0.0480996  0.05490025]\n",
      "uce in bin  1  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  2  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  3  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  4  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  5  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  6  : 0.0 , number of samples:  50\n",
      "uce in bin  7  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  8  : 0.0 , number of samples:  50\n",
      "uce in bin  9  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  10  : 0.0 , number of samples:  50\n",
      "uce in bin  11  : 0.0 , number of samples:  50\n",
      "uce in bin  12  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  13  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  14  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  15  : 6.847959699296524e-12 , number of samples:  50\n",
      "uce in bin  16  : 0.0 , number of samples:  50\n",
      "uce in bin  17  : 1.3422001357565883e-11 , number of samples:  49\n",
      "tensor([0.9643, 0.8832, 0.8894, 0.9815, 0.8441, 0.8659, 0.8721, 0.8274, 0.8322,\n",
      "        0.8150, 0.8914, 0.8933, 0.8382, 0.8077, 0.9294, 0.8533, 0.7611],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.004361058381618932\n",
      "17 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "17 bins with 1.7386164665222168 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.0372903  0.03853986 0.0393443  0.04001301 0.04052238\n",
      " 0.04102954 0.04141849 0.04178748 0.04220093 0.04280239 0.0432357\n",
      " 0.04364066 0.04426047 0.04477942 0.04584211 0.04667186 0.04816676\n",
      " 0.05490025]\n",
      "uce in bin  1  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  2  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  3  : 0.0 , number of samples:  47\n",
      "uce in bin  4  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  5  : 6.574041658269358e-12 , number of samples:  48\n",
      "uce in bin  6  : 0.0 , number of samples:  47\n",
      "uce in bin  7  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  8  : 0.0 , number of samples:  47\n",
      "uce in bin  9  : 0.0 , number of samples:  48\n",
      "uce in bin  10  : 0.0 , number of samples:  47\n",
      "uce in bin  11  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  12  : 6.4370822040749065e-12 , number of samples:  47\n",
      "uce in bin  13  : 0.0 , number of samples:  47\n",
      "uce in bin  14  : 1.3148083316538717e-11 , number of samples:  48\n",
      "uce in bin  15  : 0.0 , number of samples:  47\n",
      "uce in bin  16  : 0.0 , number of samples:  47\n",
      "uce in bin  17  : 0.0 , number of samples:  47\n",
      "uce in bin  18  : 0.0 , number of samples:  47\n",
      "tensor([0.9431, 0.8983, 0.9078, 0.9459, 0.8836, 0.8836, 0.8336, 0.8773, 0.8318,\n",
      "        0.8414, 0.8459, 0.8551, 0.8286, 0.8704, 0.8892, 0.8902, 0.8493, 0.7543],\n",
      "       device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.007391966937575489\n",
      "18 bins with tensor([8.7796e-05], device='cuda:0') UCE\n",
      "18 bins with 1.305459976196289 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03717165 0.03847128 0.03919853 0.03984631 0.04035464\n",
      " 0.04086252 0.04128456 0.04160371 0.04195645 0.04255719 0.04295224\n",
      " 0.04340825 0.0438094  0.04439156 0.04492533 0.04594383 0.04680784\n",
      " 0.04827194 0.05490025]\n",
      "uce in bin  1  : 1.2052409417706578e-11 , number of samples:  44\n",
      "uce in bin  2  : 0.0 , number of samples:  45\n",
      "uce in bin  3  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  4  : 0.0 , number of samples:  44\n",
      "uce in bin  5  : 0.0 , number of samples:  45\n",
      "uce in bin  6  : 0.0 , number of samples:  45\n",
      "uce in bin  7  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  8  : 0.0 , number of samples:  44\n",
      "uce in bin  9  : 0.0 , number of samples:  45\n",
      "uce in bin  10  : 0.0 , number of samples:  45\n",
      "uce in bin  11  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  12  : 0.0 , number of samples:  44\n",
      "uce in bin  13  : 0.0 , number of samples:  45\n",
      "uce in bin  14  : 0.0 , number of samples:  45\n",
      "uce in bin  15  : 1.8489491188100615e-11 , number of samples:  45\n",
      "uce in bin  16  : 0.0 , number of samples:  44\n",
      "uce in bin  17  : 6.163163729366872e-12 , number of samples:  45\n",
      "uce in bin  18  : 0.0 , number of samples:  45\n",
      "uce in bin  19  : 6.026204708853289e-12 , number of samples:  44\n",
      "tensor([0.9554, 0.9155, 0.8747, 0.9309, 0.9390, 0.8379, 0.8714, 0.8701, 0.8188,\n",
      "        0.8498, 0.8137, 0.8715, 0.8619, 0.8647, 0.8212, 0.9048, 0.8963, 0.8503,\n",
      "        0.7465], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005586453335126862\n",
      "19 bins with tensor([0.0001], device='cuda:0') UCE\n",
      "19 bins with 2.0801641941070557 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03714634 0.03843282 0.03910286 0.03974266 0.04027902\n",
      " 0.04070082 0.04112842 0.04148997 0.04182794 0.04220093 0.04271838\n",
      " 0.0431485  0.04351169 0.04398953 0.04446644 0.04510581 0.04603227\n",
      " 0.04691925 0.0484722  0.05490025]\n",
      "uce in bin  1  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  2  : 5.889245254658837e-12 , number of samples:  43\n",
      "uce in bin  3  : 0.0 , number of samples:  42\n",
      "uce in bin  4  : 5.889245254658837e-12 , number of samples:  43\n",
      "uce in bin  5  : 0.0 , number of samples:  42\n",
      "uce in bin  6  : 0.0 , number of samples:  43\n",
      "uce in bin  7  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  8  : 0.0 , number of samples:  43\n",
      "uce in bin  9  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  10  : 5.889245254658837e-12 , number of samples:  43\n",
      "uce in bin  11  : 0.0 , number of samples:  42\n",
      "uce in bin  12  : 0.0 , number of samples:  43\n",
      "uce in bin  13  : 1.1504572468290508e-11 , number of samples:  42\n",
      "uce in bin  14  : 0.0 , number of samples:  43\n",
      "uce in bin  15  : 5.752286234145254e-12 , number of samples:  42\n",
      "uce in bin  16  : 0.0 , number of samples:  43\n",
      "uce in bin  17  : 0.0 , number of samples:  42\n",
      "uce in bin  18  : 0.0 , number of samples:  43\n",
      "uce in bin  19  : 0.0 , number of samples:  42\n",
      "uce in bin  20  : 5.752286234145254e-12 , number of samples:  42\n",
      "tensor([0.9679, 0.9037, 0.8447, 0.9125, 0.9824, 0.8453, 0.8897, 0.8708, 0.8364,\n",
      "        0.8367, 0.8602, 0.8072, 0.8592, 0.8944, 0.8269, 0.7957, 0.9635, 0.8521,\n",
      "        0.8490, 0.7548], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.00640117796137929\n",
      "20 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "20 bins with 2.640756607055664 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.0371107  0.03836454 0.03901603 0.03963196 0.04017686\n",
      " 0.04061612 0.04102954 0.04136473 0.04164109 0.04196217 0.04252083\n",
      " 0.04291208 0.04333641 0.04364066 0.04410909 0.04459873 0.04527837\n",
      " 0.04611907 0.0470507  0.04859396 0.05490025]\n",
      "uce in bin  1  : 1.0956735518874439e-11 , number of samples:  40\n",
      "uce in bin  2  : 0.0 , number of samples:  40\n",
      "uce in bin  3  : 1.1230654427263342e-11 , number of samples:  41\n",
      "uce in bin  4  : 0.0 , number of samples:  40\n",
      "uce in bin  5  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  6  : 0.0 , number of samples:  40\n",
      "uce in bin  7  : 0.0 , number of samples:  41\n",
      "uce in bin  8  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  9  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  10  : 0.0 , number of samples:  40\n",
      "uce in bin  11  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  12  : 0.0 , number of samples:  40\n",
      "uce in bin  13  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  14  : 0.0 , number of samples:  40\n",
      "uce in bin  15  : 0.0 , number of samples:  41\n",
      "uce in bin  16  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  17  : 5.615327213631671e-12 , number of samples:  41\n",
      "uce in bin  18  : 0.0 , number of samples:  40\n",
      "uce in bin  19  : 0.0 , number of samples:  41\n",
      "uce in bin  20  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  21  : 5.478367759437219e-12 , number of samples:  40\n",
      "tensor([0.9715, 0.8940, 0.8656, 0.8911, 1.0129, 0.8270, 0.8999, 0.8218, 0.8653,\n",
      "        0.8300, 0.8431, 0.8453, 0.8582, 0.8656, 0.8523, 0.8734, 0.7511, 0.9846,\n",
      "        0.8521, 0.8543, 0.7473], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.003710352029884234\n",
      "21 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "21 bins with 1.6910380125045776 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03699935 0.03827366 0.03888163 0.0395275  0.04008555\n",
      " 0.04045991 0.04087854 0.0412123  0.0415174  0.04187584 0.04220093\n",
      " 0.04266999 0.04309418 0.04343626 0.0437853  0.04433504 0.04470373\n",
      " 0.04554641 0.04622195 0.04714209 0.04875836 0.05490025]\n",
      "uce in bin  1  : 5.2044492847291846e-12 , number of samples:  38\n",
      "uce in bin  2  : 0.0 , number of samples:  39\n",
      "uce in bin  3  : 0.0 , number of samples:  38\n",
      "uce in bin  4  : 0.0 , number of samples:  39\n",
      "uce in bin  5  : 0.0 , number of samples:  39\n",
      "uce in bin  6  : 5.2044492847291846e-12 , number of samples:  38\n",
      "uce in bin  7  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  8  : 5.478367759437219e-12 , number of samples:  40\n",
      "uce in bin  9  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  10  : 0.0 , number of samples:  39\n",
      "uce in bin  11  : 1.0682817477847273e-11 , number of samples:  39\n",
      "uce in bin  12  : 0.0 , number of samples:  38\n",
      "uce in bin  13  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  14  : 1.0408898569458369e-11 , number of samples:  38\n",
      "uce in bin  15  : 1.0682817477847273e-11 , number of samples:  39\n",
      "uce in bin  16  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  17  : 1.0408898569458369e-11 , number of samples:  38\n",
      "uce in bin  18  : 5.3414087389236364e-12 , number of samples:  39\n",
      "uce in bin  19  : 0.0 , number of samples:  39\n",
      "uce in bin  20  : 0.0 , number of samples:  38\n",
      "uce in bin  21  : 0.0 , number of samples:  39\n",
      "uce in bin  22  : 5.2044492847291846e-12 , number of samples:  38\n",
      "tensor([0.9787, 0.8988, 0.8824, 0.8647, 1.0102, 0.8534, 0.8803, 0.8677, 0.8711,\n",
      "        0.8563, 0.8156, 0.8618, 0.7478, 0.8986, 0.8704, 0.8540, 0.8680, 0.7948,\n",
      "        0.9661, 0.8577, 0.8392, 0.7434], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.005499077815329656\n",
      "22 bins with tensor([0.0002], device='cuda:0') UCE\n",
      "22 bins with 0.920252799987793 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03693046 0.03816176 0.03879927 0.03946559 0.03993529\n",
      " 0.04033316 0.04072777 0.041114   0.04143014 0.04170835 0.04200198\n",
      " 0.04249719 0.04286387 0.04323085 0.04352613 0.04391286 0.04440021\n",
      " 0.04483973 0.04573644 0.04628374 0.04724101 0.04888271 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  36\n",
      "uce in bin  2  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  3  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  4  : 0.0 , number of samples:  37\n",
      "uce in bin  5  : 0.0 , number of samples:  37\n",
      "uce in bin  6  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  7  : 0.0 , number of samples:  37\n",
      "uce in bin  8  : 0.0 , number of samples:  37\n",
      "uce in bin  9  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  10  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  11  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  12  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  13  : 0.0 , number of samples:  37\n",
      "uce in bin  14  : 0.0 , number of samples:  37\n",
      "uce in bin  15  : 0.0 , number of samples:  37\n",
      "uce in bin  16  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  17  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  18  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  19  : 1.0134980528431203e-11 , number of samples:  37\n",
      "uce in bin  20  : 0.0 , number of samples:  37\n",
      "uce in bin  21  : 0.0 , number of samples:  37\n",
      "uce in bin  22  : 5.067490264215602e-12 , number of samples:  37\n",
      "uce in bin  23  : 0.0 , number of samples:  36\n",
      "tensor([0.9703, 0.9100, 0.9035, 0.8787, 0.9526, 0.9213, 0.8422, 0.8868, 0.8250,\n",
      "        0.8798, 0.8079, 0.8546, 0.8444, 0.8448, 0.8595, 0.8946, 0.8223, 0.8433,\n",
      "        0.8394, 0.9497, 0.8582, 0.8268, 0.7486], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.0033119442377937958\n",
      "23 bins with tensor([8.8186e-05], device='cuda:0') UCE\n",
      "23 bins with 1.3383427858352661 ENCE\n",
      "Before scaling - UCE: 0.046\n",
      "Optimal scaler: 0.870\n",
      "After single scaling- UCE: 0.012\n",
      "[0.03131546 0.03688534 0.03811063 0.03877927 0.0393443  0.03981887\n",
      " 0.04027902 0.04064623 0.04102954 0.04132751 0.04157097 0.04189624\n",
      " 0.04220093 0.04264931 0.04299221 0.04336798 0.04364066 0.04405021\n",
      " 0.04446644 0.04495535 0.04584211 0.04642986 0.04726971 0.04896568\n",
      " 0.05490025]\n",
      "uce in bin  1  : 0.0 , number of samples:  35\n",
      "uce in bin  2  : 0.0 , number of samples:  35\n",
      "uce in bin  3  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  4  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  5  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  6  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  7  : 0.0 , number of samples:  35\n",
      "uce in bin  8  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  9  : 0.0 , number of samples:  35\n",
      "uce in bin  10  : 4.930531243702019e-12 , number of samples:  36\n",
      "uce in bin  11  : 9.587143579015134e-12 , number of samples:  35\n",
      "uce in bin  12  : 0.0 , number of samples:  36\n",
      "uce in bin  13  : 0.0 , number of samples:  35\n",
      "uce in bin  14  : 0.0 , number of samples:  35\n",
      "uce in bin  15  : 0.0 , number of samples:  36\n",
      "uce in bin  16  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  17  : 0.0 , number of samples:  36\n",
      "uce in bin  18  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  19  : 4.793571789507567e-12 , number of samples:  35\n",
      "uce in bin  20  : 0.0 , number of samples:  36\n",
      "uce in bin  21  : 0.0 , number of samples:  35\n",
      "uce in bin  22  : 9.861062487404038e-12 , number of samples:  36\n",
      "uce in bin  23  : 0.0 , number of samples:  35\n",
      "uce in bin  24  : 4.793571789507567e-12 , number of samples:  35\n",
      "tensor([0.9752, 0.9184, 0.8728, 0.9039, 0.9315, 0.9404, 0.8535, 0.8900, 0.8175,\n",
      "        0.8924, 0.8481, 0.8301, 0.8695, 0.7607, 0.8869, 0.8652, 0.8884, 0.8201,\n",
      "        0.8183, 0.9197, 0.9254, 0.8222, 0.8236, 0.7530], device='cuda:0')\n",
      "After bins scaling by uce - UCE: 0.006843351729912683\n",
      "24 bins with tensor([9.9935e-05], device='cuda:0') UCE\n",
      "24 bins with 0.9548129439353943 ENCE\n",
      "9 bins, UCE: 0.007445315830409527 0.0017079883255064487\n",
      "9 bins, ENCE: 1.498825192451477\n"
     ]
    }
   ],
   "source": [
    "# bins_T, S, bin_boundaries, uce = set_scaler(err_calib, uncert_calib, num_bins=15)\n",
    "\n",
    "uce_s_bins_list = []\n",
    "err_s_bins_list = []\n",
    "uncert_s_bins_list = []\n",
    "ence_bins_list = []\n",
    "for i in range(len(err_test)):\n",
    "    for b in range(5, 25):\n",
    "        n_bins = b\n",
    "        bins_T, S, bin_boundaries, uce_calib = set_scaler(err_calib, uncert_calib, num_bins=n_bins, cross_validate='uce')\n",
    "        uce, uncert_test_after = scale_bins(err_test[i], uncert_test[i], bins_T, bin_boundaries, num_bins=n_bins)\n",
    "        uce_s_bins, err_s_bins, uncert_s_bins, _, uce_per_bin = uceloss(err_test[i]**2, uncert_test_after**2, n_bins=15)\n",
    "        ence_bins = enceloss(err_test[i]**2, uncert_test_after**2, n_bins=15, single=True)\n",
    "        \n",
    "        print(f'{n_bins} bins with {uce_s_bins} UCE')\n",
    "        print(f'{n_bins} bins with {ence_bins} ENCE')\n",
    "    \n",
    "        if n_bins == 5:\n",
    "            best_uce = uce_s_bins\n",
    "            # best_uce = uce_calib\n",
    "            ence = ence_bins\n",
    "            best_err_s_bins = err_s_bins\n",
    "            best_uncert_s_bins = uncert_s_bins\n",
    "            mean_uce = best_uce\n",
    "            best_n_bins = 5\n",
    "            best_bins_T = bins_T\n",
    "        else:\n",
    "            mean_uce = uce_s_bins\n",
    "            # mean_uce = uce_calib\n",
    "            if mean_uce < best_uce:\n",
    "                best_n_bins = n_bins\n",
    "                best_uce = mean_uce\n",
    "                ence = ence_bins\n",
    "                best_err_s_bins = err_s_bins\n",
    "                best_uncert_s_bins = uncert_s_bins\n",
    "                best_bins_T = bins_T\n",
    "    \n",
    "    uce_s_bins_list.append(best_uce.cpu())\n",
    "    # uce_s_bins_list.append(torch.tensor(best_uce))\n",
    "    err_s_bins_list.append(best_err_s_bins.cpu())\n",
    "    uncert_s_bins_list.append(best_uncert_s_bins.cpu())\n",
    "    ence_bins_list.append(ence.cpu())\n",
    "    # uce_s_bins_list.append(uce_s_bins.cpu())\n",
    "    # err_s_bins_list.append(err_s_bins.cpu())\n",
    "    # uncert_s_bins_list.append(uncert_s_bins.cpu())\n",
    "\n",
    "print(f'{best_n_bins} bins, UCE:', (torch.stack(uce_s_bins_list)*100).mean().item(), (torch.stack(uce_s_bins_list)*100).var().sqrt().item())\n",
    "print(f'{best_n_bins} bins, ENCE:', (torch.stack(ence_bins_list)).mean().item())\n",
    "\n",
    "save_path = 'C:/lior/studies/master/projects/calibration/regression calibration/well-calibrated-regression-uncertainty/var_and_mse_calib/'\n",
    "with open(save_path + f'{base_model}_gaussian_oct_s_bins.pickle', 'wb') as handle:\n",
    "    pickle.dump({'s_bins': best_bins_T\n",
    "                 ,'s': S}\n",
    "                , handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calc_optimal_q(target_calib, mu_calib, uncert_calib, err_calib=None, alpha=0.1, gc=False, single=False):\n",
    "\n",
    "    if single:\n",
    "        s_t = torch.abs(target_calib-mu_calib)[:, 0].unsqueeze(-1) / uncert_calib\n",
    "    else:\n",
    "        s_t = torch.abs(target_calib-mu_calib) / uncert_calib\n",
    "    if gc:\n",
    "        # errors = (err_calib**2).float().mean()  # err()\n",
    "        # avg_uncert = (uncert_calib**2).mean()  # uncert()\n",
    "        # S = (errors / avg_uncert).sqrt()\n",
    "        S = (err_calib**2 / uncert_calib**2).mean().sqrt()\n",
    "        # print(S)\n",
    "        # q = 1.64485 * torch.sqrt((s_t**2).mean()).item()\n",
    "        if alpha == 0.1:\n",
    "            q = 1.64485 * S.item()\n",
    "        elif alpha == 0.05:\n",
    "            q = 1.95996 * S.item()\n",
    "        else:\n",
    "            print(\"Choose another value of alpha!! (0.1 / 0.05)\")\n",
    "        # s_t_sorted, _ = torch.sort(s_t, dim=0)\n",
    "        # q_index = math.ceil((len(s_t_sorted)) * (1 - alpha))\n",
    "        # q = s_t_sorted[q_index].item()\n",
    "    else:\n",
    "        s_t_sorted, _ = torch.sort(s_t, dim=0)\n",
    "        # q_index = math.ceil((len(s_t_sorted) + 1) * (1 - alpha))\n",
    "        q_index = math.ceil((len(s_t_sorted)) * (1 - alpha))\n",
    "        q = s_t_sorted[q_index].item()\n",
    "        # q = torch.quantile(s_t, (1 - alpha))\n",
    "    \n",
    "    return q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conformal prediction\n",
    "def histedges_equalN(x, n_bins=15):\n",
    "    npt = len(x)\n",
    "    return np.interp(np.linspace(0, npt, n_bins + 1),\n",
    "                    np.arange(npt),\n",
    "                    np.sort(x))\n",
    "\n",
    "def set_scaler_conformal(target_calib, mu_calib, uncert_calib, err_calib=None, init_temp=2.5, log=True, num_bins=15, outlier=0.0, by_uncert=True, gc=False):\n",
    "    \"\"\"\n",
    "    Tune single scaler for the model (using the validation set) with cross-validation on NLL\n",
    "    \"\"\"\n",
    "        \n",
    "    if gc:\n",
    "        printed_type = 'GC'\n",
    "    else:\n",
    "        printed_type = 'CP'\n",
    "            \n",
    "    # Calculate optimal q\n",
    "    q = calc_optimal_q(target_calib, mu_calib, uncert_calib, err_calib=err_calib, alpha=0.05, gc=gc)\n",
    "    \n",
    "    after_single_scaling_avg_len = avg_len(uncert_calib, q, single=True)\n",
    "    print('Optimal scaler {} (val): {:.3f}'.format(printed_type, q))\n",
    "    print('After single scaling- Avg Length {} (val): {}'.format(printed_type, after_single_scaling_avg_len))\n",
    "    \n",
    "    after_single_scaling_avg_cov = avg_cov(mu_calib, q * uncert_calib, target_calib)\n",
    "    print('After single scaling- Avg Cov {} (val): {}'.format(printed_type, after_single_scaling_avg_cov))\n",
    "    \n",
    "    init_scaler = q\n",
    "    \n",
    "    n_bins = num_bins\n",
    "    \n",
    "    bins_q = init_scaler*torch.ones(n_bins)\n",
    "    \n",
    "    if by_uncert:\n",
    "        n, bin_boundaries = np.histogram(uncert_calib.squeeze(-1).cpu().detach(), histedges_equalN(uncert_calib.squeeze(-1).cpu().detach(), n_bins=n_bins))\n",
    "    else:  \n",
    "        n, bin_boundaries = np.histogram(mu_calib.squeeze(-1).cpu().detach(), histedges_equalN(mu_calib.squeeze(-1).cpu().detach(), n_bins=n_bins))\n",
    "    # print(bin_boundaries)\n",
    "    \n",
    "    # if by_uncert:\n",
    "    #     bin_boundaries = torch.linspace(uncert_calib.min().item(), uncert_calib.max().item(), n_bins + 1, device=device)\n",
    "    # else:\n",
    "    #     bin_boundaries = torch.linspace(mu_calib.min().item(), mu_calib.max().item(), n_bins + 1, device=device)\n",
    "\n",
    "    T_opt_buce = init_temp*torch.ones(uncert_calib.shape[0]).cuda()\n",
    "    T_buce = init_temp*torch.ones(uncert_calib.shape[0]).cuda()\n",
    "    buce_temperature = T_buce\n",
    "    \n",
    "    bin = 0\n",
    "    \n",
    "    # bin_boundaries = torch.linspace(uncert_calib.min().item(), uncert_calib.max().item(), n_bins + 1, device=device)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        if by_uncert:\n",
    "            in_bin = uncert_calib.gt(bin_lower.item()) * uncert_calib.le(bin_upper.item())\n",
    "        else:\n",
    "            in_bin = mu_calib.gt(bin_lower.item()) * mu_calib.le(bin_upper.item())\n",
    "        prop_in_bin = in_bin.float().mean()  # |Bm| / n\n",
    "        if prop_in_bin.item() > outlier:\n",
    "            if gc:\n",
    "                # q_bin = calc_optimal_q(target_calib.mean(dim=1, keepdim=True)[in_bin], mu_calib.mean(dim=1, keepdim=True)[in_bin], uncert_calib[in_bin], alpha=0.1, gc=gc, mean=False)\n",
    "                errors_in_bin = (err_calib[in_bin]**2).float().mean()  # err()\n",
    "                avg_uncert_in_bin = (uncert_calib[in_bin]**2).mean()  # uncert()\n",
    "                S_bin = (errors_in_bin / avg_uncert_in_bin).sqrt()\n",
    "                q_bin =  1.64485 * S_bin\n",
    "            else:\n",
    "                q_bin = calc_optimal_q(target_calib[in_bin], mu_calib[in_bin], uncert_calib[in_bin], err_calib=err_calib[in_bin], alpha=0.05, gc=gc)\n",
    "            bins_q[bin] = q_bin\n",
    "            b_avg_len_val = avg_len(uncert_calib[in_bin], q_bin, single=True)\n",
    "                                    \n",
    "            samples = uncert_calib[in_bin].shape[0]\n",
    "            print(f'Avg Length {printed_type} (val) in bin ', bin+1, ' :', (b_avg_len_val).item(), ', number of samples: ', samples)\n",
    "            \n",
    "            # b_avg_cov_val = avg_cov(mu_calib.mean(dim=1, keepdim=True)[in_bin], q_bin * uncert_calib[in_bin], target_calib.mean(dim=1, keepdim=True)[in_bin], mean=False)\n",
    "            b_avg_cov_val = avg_cov(mu_calib[in_bin], q_bin * uncert_calib[in_bin], target_calib[in_bin])\n",
    "            print(f'Avg Cov {printed_type} (val) in bin ', bin+1, ' :', (b_avg_cov_val), ', number of samples: ', samples)\n",
    "\n",
    "        bin += 1\n",
    "\n",
    "    print(f'q values {printed_type}:', bins_q)\n",
    "    uncert_calib_after = uncert_calib.clone()\n",
    "    for inx, (bin_lower, bin_upper) in enumerate(zip(bin_lowers, bin_uppers)):\n",
    "        if by_uncert:\n",
    "            in_bin = uncert_calib.gt(bin_lower.item()) * uncert_calib.le(bin_upper.item())\n",
    "        else:\n",
    "            in_bin = mu_calib.gt(bin_lower.item()) * mu_calib.le(bin_upper.item())\n",
    "        uncert_calib_after[in_bin] = bins_q[inx] * uncert_calib[in_bin]\n",
    "    current_avg_len = (2 * uncert_calib_after).mean()\n",
    "    print(f'After bins scaling {printed_type} (val) by - Avg Length:', current_avg_len.item())\n",
    "    \n",
    "    avg_cov_val = avg_cov(mu_calib, uncert_calib_after, target_calib)\n",
    "    print(f'After bins scaling {printed_type} (val) by - Avg Cov:', avg_cov_val)\n",
    "    \n",
    "    return bins_q, q, bin_boundaries, current_avg_len.item()\n",
    "\n",
    "def avg_cov(mu, uncert, target, mean=False):\n",
    "    total_cov = 0.0\n",
    "    if mean:\n",
    "        mu_mean = mu.mean(dim=1, keepdim=True)\n",
    "        target_mean = target.mean(dim=1, keepdim=True)\n",
    "    else:\n",
    "        mu_mean = mu\n",
    "        target_mean = target\n",
    "    \n",
    "    for mu_single, uncert_single, target_single in zip(mu, uncert, target):\n",
    "        if mu_single - uncert_single <= target_single <= mu_single + uncert_single:\n",
    "            total_cov += 1.0\n",
    "            \n",
    "    return total_cov / len(mu_mean)\n",
    "\n",
    "def scale_bins_conformal(mu_test, uncert_test, bins_q, bin_boundaries, num_bins=15, by_uncert=True):\n",
    "    \n",
    "    uncert_test_after = uncert_test.clone()\n",
    "    \n",
    "    # bin_boundaries = torch.linspace(uncert_test.min().item(), uncert_test.max().item(), n_bins + 1, device=device)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    \n",
    "    bin = 0\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        if by_uncert:\n",
    "            in_bin  = uncert_test.gt(bin_lower.item()) * uncert_test.le(bin_upper.item())\n",
    "        else:\n",
    "            in_bin  = mu_test.gt(bin_lower.item()) * mu_test.le(bin_upper.item())\n",
    "        if any(in_bin):\n",
    "            uncert_test_after[in_bin] = bins_q[bin] * uncert_test[in_bin]\n",
    "        bin += 1\n",
    "    avg_len_bins = (2 * uncert_test_after).mean()\n",
    "    \n",
    "    return avg_len_bins, uncert_test_after\n",
    "\n",
    "def scale_bins_single_conformal(uncert_test, q):\n",
    "    \n",
    "    # Calculate Avg Length before temperature scaling\n",
    "    before_scaling_avg_len = (2 * uncert_test).mean()\n",
    "    print('Before scaling - Avg Length: %.3f' % (before_scaling_avg_len))\n",
    "        \n",
    "    # Calculate Avg Length after single scaling\n",
    "    after_single_scaling_avg_len = avg_len(uncert_test, q, single=True)\n",
    "    print('Optimal scaler: %.3f' % q)\n",
    "    print(f'After single scaling- Avg Length: {after_single_scaling_avg_len}')\n",
    "    \n",
    "    return after_single_scaling_avg_len, before_scaling_avg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.05993583798408508 , number of samples:  425\n",
      "Avg Cov CP (val) in bin  1  : 0.9529411764705882 , number of samples:  425\n",
      "Avg Length CP (val) in bin  2  : 0.05431250110268593 , number of samples:  424\n",
      "Avg Cov CP (val) in bin  2  : 0.9528301886792453 , number of samples:  424\n",
      "q values CP: tensor([1.3456, 1.2448])\n",
      "After bins scaling CP (val) by - Avg Length: 0.057128969579935074\n",
      "After bins scaling CP (val) by - Avg Cov: 0.951764705882353\n",
      "Test 2 bins with Avg Length 0.05675027146935463\n",
      "Test 2 bins after bins with Cov Length 0.9352941176470588\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.060233209282159805 , number of samples:  283\n",
      "Avg Cov CP (val) in bin  1  : 0.9540636042402827 , number of samples:  283\n",
      "Avg Length CP (val) in bin  2  : 0.054065946489572525 , number of samples:  283\n",
      "Avg Cov CP (val) in bin  2  : 0.9540636042402827 , number of samples:  283\n",
      "Avg Length CP (val) in bin  3  : 0.0558854304254055 , number of samples:  283\n",
      "Avg Cov CP (val) in bin  3  : 0.9540636042402827 , number of samples:  283\n",
      "q values CP: tensor([1.3422, 1.2415, 1.2746])\n",
      "After bins scaling CP (val) by - Avg Length: 0.056730154901742935\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9529411764705882\n",
      "Test 3 bins with Avg Length 0.05632064491510391\n",
      "Test 3 bins after bins with Cov Length 0.9352941176470588\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.06175829470157623 , number of samples:  212\n",
      "Avg Cov CP (val) in bin  1  : 0.9575471698113207 , number of samples:  212\n",
      "Avg Length CP (val) in bin  2  : 0.05998812988400459 , number of samples:  213\n",
      "Avg Cov CP (val) in bin  2  : 0.9577464788732394 , number of samples:  213\n",
      "Avg Length CP (val) in bin  3  : 0.05508606135845184 , number of samples:  212\n",
      "Avg Cov CP (val) in bin  3  : 0.9575471698113207 , number of samples:  212\n",
      "Avg Length CP (val) in bin  4  : 0.05428275093436241 , number of samples:  212\n",
      "Avg Cov CP (val) in bin  4  : 0.9575471698113207 , number of samples:  212\n",
      "q values CP: tensor([1.3601, 1.3733, 1.2746, 1.2323])\n",
      "After bins scaling CP (val) by - Avg Length: 0.057782132178545\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9564705882352941\n",
      "Test 4 bins with Avg Length 0.057392656803131104\n",
      "Test 4 bins after bins with Cov Length 0.9388235294117647\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.061854392290115356 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  1  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  2  : 0.05602623522281647 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  2  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  3  : 0.05351828411221504 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  3  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  4  : 0.05756310373544693 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  4  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  5  : 0.05417650192975998 , number of samples:  169\n",
      "Avg Cov CP (val) in bin  5  : 0.9585798816568047 , number of samples:  169\n",
      "q values CP: tensor([1.3601, 1.2663, 1.2448, 1.3154, 1.2323])\n",
      "After bins scaling CP (val) by - Avg Length: 0.056632671505212784\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9576470588235294\n",
      "Test 5 bins with Avg Length 0.056273240596055984\n",
      "Test 5 bins after bins with Cov Length 0.9352941176470588\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.061087965965270996 , number of samples:  141\n",
      "Avg Cov CP (val) in bin  1  : 0.9574468085106383 , number of samples:  141\n",
      "Avg Length CP (val) in bin  2  : 0.05953117087483406 , number of samples:  142\n",
      "Avg Cov CP (val) in bin  2  : 0.9577464788732394 , number of samples:  142\n",
      "Avg Length CP (val) in bin  3  : 0.0639372393488884 , number of samples:  142\n",
      "Avg Cov CP (val) in bin  3  : 0.9577464788732394 , number of samples:  142\n",
      "Avg Length CP (val) in bin  4  : 0.05272990092635155 , number of samples:  141\n",
      "Avg Cov CP (val) in bin  4  : 0.9574468085106383 , number of samples:  141\n",
      "Avg Length CP (val) in bin  5  : 0.05594741553068161 , number of samples:  142\n",
      "Avg Cov CP (val) in bin  5  : 0.9577464788732394 , number of samples:  142\n",
      "Avg Length CP (val) in bin  6  : 0.05618180334568024 , number of samples:  141\n",
      "Avg Cov CP (val) in bin  6  : 0.9574468085106383 , number of samples:  141\n",
      "q values CP: tensor([1.3422, 1.3456, 1.4570, 1.2203, 1.2878, 1.2698])\n",
      "After bins scaling CP (val) by - Avg Length: 0.058241646736860275\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9564705882352941\n",
      "Test 6 bins with Avg Length 0.05792840197682381\n",
      "Test 6 bins after bins with Cov Length 0.9376470588235294\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.062336597591638565 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  1  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  2  : 0.059580713510513306 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  2  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  3  : 0.0607588067650795 , number of samples:  122\n",
      "Avg Cov CP (val) in bin  3  : 0.9590163934426229 , number of samples:  122\n",
      "Avg Length CP (val) in bin  4  : 0.053066451102495193 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  4  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  5  : 0.05613425746560097 , number of samples:  122\n",
      "Avg Cov CP (val) in bin  5  : 0.9590163934426229 , number of samples:  122\n",
      "Avg Length CP (val) in bin  6  : 0.05538715794682503 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  6  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  7  : 0.05633670836687088 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  7  : 0.9586776859504132 , number of samples:  121\n",
      "q values CP: tensor([1.3601, 1.3456, 1.3733, 1.2415, 1.2844, 1.2746, 1.2698])\n",
      "After bins scaling CP (val) by - Avg Length: 0.057659972459077835\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9576470588235294\n",
      "Test 7 bins with Avg Length 0.05730101093649864\n",
      "Test 7 bins after bins with Cov Length 0.9411764705882353\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.06243978440761566 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  1  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  2  : 0.0633469969034195 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  2  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  3  : 0.05342280864715576 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  3  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  4  : 0.06948550045490265 , number of samples:  107\n",
      "Avg Cov CP (val) in bin  4  : 0.9626168224299065 , number of samples:  107\n",
      "Avg Length CP (val) in bin  5  : 0.05232684314250946 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  5  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  6  : 0.0664934292435646 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  6  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  7  : 0.05075450241565704 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  7  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  8  : 0.05857199802994728 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  8  : 0.9622641509433962 , number of samples:  106\n",
      "q values CP: tensor([1.3601, 1.4106, 1.2204, 1.5940, 1.2203, 1.5267, 1.1665, 1.3136])\n",
      "After bins scaling CP (val) by - Avg Length: 0.05961543694138527\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9611764705882353\n",
      "Test 8 bins with Avg Length 0.059828855097293854\n",
      "Test 8 bins after bins with Cov Length 0.9423529411764706\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.0627712607383728 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  1  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  2  : 0.06319689005613327 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  2  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  3  : 0.06488512456417084 , number of samples:  95\n",
      "Avg Cov CP (val) in bin  3  : 0.968421052631579 , number of samples:  95\n",
      "Avg Length CP (val) in bin  4  : 0.07065267860889435 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  4  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  5  : 0.062142953276634216 , number of samples:  95\n",
      "Avg Cov CP (val) in bin  5  : 0.968421052631579 , number of samples:  95\n",
      "Avg Length CP (val) in bin  6  : 0.05415961518883705 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  6  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  7  : 0.06653372198343277 , number of samples:  95\n",
      "Avg Cov CP (val) in bin  7  : 0.968421052631579 , number of samples:  95\n",
      "Avg Length CP (val) in bin  8  : 0.053233735263347626 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  8  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  9  : 0.062380000948905945 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  9  : 0.9680851063829787 , number of samples:  94\n",
      "q values CP: tensor([1.3601, 1.4106, 1.4853, 1.5940, 1.4570, 1.2400, 1.5267, 1.2323, 1.3938])\n",
      "After bins scaling CP (val) by - Avg Length: 0.062220968306064606\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9670588235294117\n",
      "Test 9 bins with Avg Length 0.061839375644922256\n",
      "Test 9 bins after bins with Cov Length 0.9505882352941176\n",
      "Before scaling - Avg Length: 0.044\n",
      "Optimal scaler: 1.288\n",
      "After single scaling- Avg Length: 0.05653418228030205\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.05993583798408508 , number of samples:  425\n",
      "Avg Cov CP (val) in bin  1  : 0.9529411764705882 , number of samples:  425\n",
      "Avg Length CP (val) in bin  2  : 0.05431250110268593 , number of samples:  424\n",
      "Avg Cov CP (val) in bin  2  : 0.9528301886792453 , number of samples:  424\n",
      "q values CP: tensor([1.3456, 1.2448])\n",
      "After bins scaling CP (val) by - Avg Length: 0.057128969579935074\n",
      "After bins scaling CP (val) by - Avg Cov: 0.951764705882353\n",
      "Test 2 bins with Avg Length 0.056758806109428406\n",
      "Test 2 bins after bins with Cov Length 0.9329411764705883\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.060233209282159805 , number of samples:  283\n",
      "Avg Cov CP (val) in bin  1  : 0.9540636042402827 , number of samples:  283\n",
      "Avg Length CP (val) in bin  2  : 0.054065946489572525 , number of samples:  283\n",
      "Avg Cov CP (val) in bin  2  : 0.9540636042402827 , number of samples:  283\n",
      "Avg Length CP (val) in bin  3  : 0.0558854304254055 , number of samples:  283\n",
      "Avg Cov CP (val) in bin  3  : 0.9540636042402827 , number of samples:  283\n",
      "q values CP: tensor([1.3422, 1.2415, 1.2746])\n",
      "After bins scaling CP (val) by - Avg Length: 0.056730154901742935\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9529411764705882\n",
      "Test 3 bins with Avg Length 0.05630945414304733\n",
      "Test 3 bins after bins with Cov Length 0.9329411764705883\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.06175829470157623 , number of samples:  212\n",
      "Avg Cov CP (val) in bin  1  : 0.9575471698113207 , number of samples:  212\n",
      "Avg Length CP (val) in bin  2  : 0.05998812988400459 , number of samples:  213\n",
      "Avg Cov CP (val) in bin  2  : 0.9577464788732394 , number of samples:  213\n",
      "Avg Length CP (val) in bin  3  : 0.05508606135845184 , number of samples:  212\n",
      "Avg Cov CP (val) in bin  3  : 0.9575471698113207 , number of samples:  212\n",
      "Avg Length CP (val) in bin  4  : 0.05428275093436241 , number of samples:  212\n",
      "Avg Cov CP (val) in bin  4  : 0.9575471698113207 , number of samples:  212\n",
      "q values CP: tensor([1.3601, 1.3733, 1.2746, 1.2323])\n",
      "After bins scaling CP (val) by - Avg Length: 0.057782132178545\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9564705882352941\n",
      "Test 4 bins with Avg Length 0.057407528162002563\n",
      "Test 4 bins after bins with Cov Length 0.9411764705882353\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.061854392290115356 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  1  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  2  : 0.05602623522281647 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  2  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  3  : 0.05351828411221504 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  3  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  4  : 0.05756310373544693 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  4  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  5  : 0.05417650192975998 , number of samples:  169\n",
      "Avg Cov CP (val) in bin  5  : 0.9585798816568047 , number of samples:  169\n",
      "q values CP: tensor([1.3601, 1.2663, 1.2448, 1.3154, 1.2323])\n",
      "After bins scaling CP (val) by - Avg Length: 0.056632671505212784\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9576470588235294\n",
      "Test 5 bins with Avg Length 0.05629480630159378\n",
      "Test 5 bins after bins with Cov Length 0.9317647058823529\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.061087965965270996 , number of samples:  141\n",
      "Avg Cov CP (val) in bin  1  : 0.9574468085106383 , number of samples:  141\n",
      "Avg Length CP (val) in bin  2  : 0.05953117087483406 , number of samples:  142\n",
      "Avg Cov CP (val) in bin  2  : 0.9577464788732394 , number of samples:  142\n",
      "Avg Length CP (val) in bin  3  : 0.0639372393488884 , number of samples:  142\n",
      "Avg Cov CP (val) in bin  3  : 0.9577464788732394 , number of samples:  142\n",
      "Avg Length CP (val) in bin  4  : 0.05272990092635155 , number of samples:  141\n",
      "Avg Cov CP (val) in bin  4  : 0.9574468085106383 , number of samples:  141\n",
      "Avg Length CP (val) in bin  5  : 0.05594741553068161 , number of samples:  142\n",
      "Avg Cov CP (val) in bin  5  : 0.9577464788732394 , number of samples:  142\n",
      "Avg Length CP (val) in bin  6  : 0.05618180334568024 , number of samples:  141\n",
      "Avg Cov CP (val) in bin  6  : 0.9574468085106383 , number of samples:  141\n",
      "q values CP: tensor([1.3422, 1.3456, 1.4570, 1.2203, 1.2878, 1.2698])\n",
      "After bins scaling CP (val) by - Avg Length: 0.058241646736860275\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9564705882352941\n",
      "Test 6 bins with Avg Length 0.05797402560710907\n",
      "Test 6 bins after bins with Cov Length 0.9411764705882353\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.062336597591638565 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  1  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  2  : 0.059580713510513306 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  2  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  3  : 0.0607588067650795 , number of samples:  122\n",
      "Avg Cov CP (val) in bin  3  : 0.9590163934426229 , number of samples:  122\n",
      "Avg Length CP (val) in bin  4  : 0.053066451102495193 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  4  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  5  : 0.05613425746560097 , number of samples:  122\n",
      "Avg Cov CP (val) in bin  5  : 0.9590163934426229 , number of samples:  122\n",
      "Avg Length CP (val) in bin  6  : 0.05538715794682503 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  6  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  7  : 0.05633670836687088 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  7  : 0.9586776859504132 , number of samples:  121\n",
      "q values CP: tensor([1.3601, 1.3456, 1.3733, 1.2415, 1.2844, 1.2746, 1.2698])\n",
      "After bins scaling CP (val) by - Avg Length: 0.057659972459077835\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9576470588235294\n",
      "Test 7 bins with Avg Length 0.05729613080620766\n",
      "Test 7 bins after bins with Cov Length 0.9376470588235294\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.06243978440761566 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  1  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  2  : 0.0633469969034195 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  2  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  3  : 0.05342280864715576 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  3  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  4  : 0.06948550045490265 , number of samples:  107\n",
      "Avg Cov CP (val) in bin  4  : 0.9626168224299065 , number of samples:  107\n",
      "Avg Length CP (val) in bin  5  : 0.05232684314250946 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  5  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  6  : 0.0664934292435646 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  6  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  7  : 0.05075450241565704 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  7  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  8  : 0.05857199802994728 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  8  : 0.9622641509433962 , number of samples:  106\n",
      "q values CP: tensor([1.3601, 1.4106, 1.2204, 1.5940, 1.2203, 1.5267, 1.1665, 1.3136])\n",
      "After bins scaling CP (val) by - Avg Length: 0.05961543694138527\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9611764705882353\n",
      "Test 8 bins with Avg Length 0.05985504761338234\n",
      "Test 8 bins after bins with Cov Length 0.94\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.0627712607383728 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  1  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  2  : 0.06319689005613327 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  2  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  3  : 0.06488512456417084 , number of samples:  95\n",
      "Avg Cov CP (val) in bin  3  : 0.968421052631579 , number of samples:  95\n",
      "Avg Length CP (val) in bin  4  : 0.07065267860889435 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  4  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  5  : 0.062142953276634216 , number of samples:  95\n",
      "Avg Cov CP (val) in bin  5  : 0.968421052631579 , number of samples:  95\n",
      "Avg Length CP (val) in bin  6  : 0.05415961518883705 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  6  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  7  : 0.06653372198343277 , number of samples:  95\n",
      "Avg Cov CP (val) in bin  7  : 0.968421052631579 , number of samples:  95\n",
      "Avg Length CP (val) in bin  8  : 0.053233735263347626 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  8  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  9  : 0.062380000948905945 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  9  : 0.9680851063829787 , number of samples:  94\n",
      "q values CP: tensor([1.3601, 1.4106, 1.4853, 1.5940, 1.4570, 1.2400, 1.5267, 1.2323, 1.3938])\n",
      "After bins scaling CP (val) by - Avg Length: 0.062220968306064606\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9670588235294117\n",
      "Test 9 bins with Avg Length 0.06196923926472664\n",
      "Test 9 bins after bins with Cov Length 0.9576470588235294\n",
      "Before scaling - Avg Length: 0.044\n",
      "Optimal scaler: 1.288\n",
      "After single scaling- Avg Length: 0.05653000995516777\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.05993583798408508 , number of samples:  425\n",
      "Avg Cov CP (val) in bin  1  : 0.9529411764705882 , number of samples:  425\n",
      "Avg Length CP (val) in bin  2  : 0.05431250110268593 , number of samples:  424\n",
      "Avg Cov CP (val) in bin  2  : 0.9528301886792453 , number of samples:  424\n",
      "q values CP: tensor([1.3456, 1.2448])\n",
      "After bins scaling CP (val) by - Avg Length: 0.057128969579935074\n",
      "After bins scaling CP (val) by - Avg Cov: 0.951764705882353\n",
      "Test 2 bins with Avg Length 0.056764911860227585\n",
      "Test 2 bins after bins with Cov Length 0.9329411764705883\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.060233209282159805 , number of samples:  283\n",
      "Avg Cov CP (val) in bin  1  : 0.9540636042402827 , number of samples:  283\n",
      "Avg Length CP (val) in bin  2  : 0.054065946489572525 , number of samples:  283\n",
      "Avg Cov CP (val) in bin  2  : 0.9540636042402827 , number of samples:  283\n",
      "Avg Length CP (val) in bin  3  : 0.0558854304254055 , number of samples:  283\n",
      "Avg Cov CP (val) in bin  3  : 0.9540636042402827 , number of samples:  283\n",
      "q values CP: tensor([1.3422, 1.2415, 1.2746])\n",
      "After bins scaling CP (val) by - Avg Length: 0.056730154901742935\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9529411764705882\n",
      "Test 3 bins with Avg Length 0.05632273107767105\n",
      "Test 3 bins after bins with Cov Length 0.9317647058823529\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.06175829470157623 , number of samples:  212\n",
      "Avg Cov CP (val) in bin  1  : 0.9575471698113207 , number of samples:  212\n",
      "Avg Length CP (val) in bin  2  : 0.05998812988400459 , number of samples:  213\n",
      "Avg Cov CP (val) in bin  2  : 0.9577464788732394 , number of samples:  213\n",
      "Avg Length CP (val) in bin  3  : 0.05508606135845184 , number of samples:  212\n",
      "Avg Cov CP (val) in bin  3  : 0.9575471698113207 , number of samples:  212\n",
      "Avg Length CP (val) in bin  4  : 0.05428275093436241 , number of samples:  212\n",
      "Avg Cov CP (val) in bin  4  : 0.9575471698113207 , number of samples:  212\n",
      "q values CP: tensor([1.3601, 1.3733, 1.2746, 1.2323])\n",
      "After bins scaling CP (val) by - Avg Length: 0.057782132178545\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9564705882352941\n",
      "Test 4 bins with Avg Length 0.057411208748817444\n",
      "Test 4 bins after bins with Cov Length 0.9376470588235294\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.061854392290115356 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  1  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  2  : 0.05602623522281647 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  2  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  3  : 0.05351828411221504 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  3  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  4  : 0.05756310373544693 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  4  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  5  : 0.05417650192975998 , number of samples:  169\n",
      "Avg Cov CP (val) in bin  5  : 0.9585798816568047 , number of samples:  169\n",
      "q values CP: tensor([1.3601, 1.2663, 1.2448, 1.3154, 1.2323])\n",
      "After bins scaling CP (val) by - Avg Length: 0.056632671505212784\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9576470588235294\n",
      "Test 5 bins with Avg Length 0.056283000856637955\n",
      "Test 5 bins after bins with Cov Length 0.9317647058823529\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.061087965965270996 , number of samples:  141\n",
      "Avg Cov CP (val) in bin  1  : 0.9574468085106383 , number of samples:  141\n",
      "Avg Length CP (val) in bin  2  : 0.05953117087483406 , number of samples:  142\n",
      "Avg Cov CP (val) in bin  2  : 0.9577464788732394 , number of samples:  142\n",
      "Avg Length CP (val) in bin  3  : 0.0639372393488884 , number of samples:  142\n",
      "Avg Cov CP (val) in bin  3  : 0.9577464788732394 , number of samples:  142\n",
      "Avg Length CP (val) in bin  4  : 0.05272990092635155 , number of samples:  141\n",
      "Avg Cov CP (val) in bin  4  : 0.9574468085106383 , number of samples:  141\n",
      "Avg Length CP (val) in bin  5  : 0.05594741553068161 , number of samples:  142\n",
      "Avg Cov CP (val) in bin  5  : 0.9577464788732394 , number of samples:  142\n",
      "Avg Length CP (val) in bin  6  : 0.05618180334568024 , number of samples:  141\n",
      "Avg Cov CP (val) in bin  6  : 0.9574468085106383 , number of samples:  141\n",
      "q values CP: tensor([1.3422, 1.3456, 1.4570, 1.2203, 1.2878, 1.2698])\n",
      "After bins scaling CP (val) by - Avg Length: 0.058241646736860275\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9564705882352941\n",
      "Test 6 bins with Avg Length 0.05794670432806015\n",
      "Test 6 bins after bins with Cov Length 0.9376470588235294\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.062336597591638565 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  1  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  2  : 0.059580713510513306 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  2  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  3  : 0.0607588067650795 , number of samples:  122\n",
      "Avg Cov CP (val) in bin  3  : 0.9590163934426229 , number of samples:  122\n",
      "Avg Length CP (val) in bin  4  : 0.053066451102495193 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  4  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  5  : 0.05613425746560097 , number of samples:  122\n",
      "Avg Cov CP (val) in bin  5  : 0.9590163934426229 , number of samples:  122\n",
      "Avg Length CP (val) in bin  6  : 0.05538715794682503 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  6  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  7  : 0.05633670836687088 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  7  : 0.9586776859504132 , number of samples:  121\n",
      "q values CP: tensor([1.3601, 1.3456, 1.3733, 1.2415, 1.2844, 1.2746, 1.2698])\n",
      "After bins scaling CP (val) by - Avg Length: 0.057659972459077835\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9576470588235294\n",
      "Test 7 bins with Avg Length 0.05733811855316162\n",
      "Test 7 bins after bins with Cov Length 0.9352941176470588\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.06243978440761566 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  1  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  2  : 0.0633469969034195 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  2  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  3  : 0.05342280864715576 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  3  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  4  : 0.06948550045490265 , number of samples:  107\n",
      "Avg Cov CP (val) in bin  4  : 0.9626168224299065 , number of samples:  107\n",
      "Avg Length CP (val) in bin  5  : 0.05232684314250946 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  5  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  6  : 0.0664934292435646 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  6  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  7  : 0.05075450241565704 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  7  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  8  : 0.05857199802994728 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  8  : 0.9622641509433962 , number of samples:  106\n",
      "q values CP: tensor([1.3601, 1.4106, 1.2204, 1.5940, 1.2203, 1.5267, 1.1665, 1.3136])\n",
      "After bins scaling CP (val) by - Avg Length: 0.05961543694138527\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9611764705882353\n",
      "Test 8 bins with Avg Length 0.05974747985601425\n",
      "Test 8 bins after bins with Cov Length 0.9435294117647058\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.0627712607383728 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  1  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  2  : 0.06319689005613327 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  2  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  3  : 0.06488512456417084 , number of samples:  95\n",
      "Avg Cov CP (val) in bin  3  : 0.968421052631579 , number of samples:  95\n",
      "Avg Length CP (val) in bin  4  : 0.07065267860889435 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  4  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  5  : 0.062142953276634216 , number of samples:  95\n",
      "Avg Cov CP (val) in bin  5  : 0.968421052631579 , number of samples:  95\n",
      "Avg Length CP (val) in bin  6  : 0.05415961518883705 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  6  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  7  : 0.06653372198343277 , number of samples:  95\n",
      "Avg Cov CP (val) in bin  7  : 0.968421052631579 , number of samples:  95\n",
      "Avg Length CP (val) in bin  8  : 0.053233735263347626 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  8  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  9  : 0.062380000948905945 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  9  : 0.9680851063829787 , number of samples:  94\n",
      "q values CP: tensor([1.3601, 1.4106, 1.4853, 1.5940, 1.4570, 1.2400, 1.5267, 1.2323, 1.3938])\n",
      "After bins scaling CP (val) by - Avg Length: 0.062220968306064606\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9670588235294117\n",
      "Test 9 bins with Avg Length 0.06195376440882683\n",
      "Test 9 bins after bins with Cov Length 0.9541176470588235\n",
      "Before scaling - Avg Length: 0.044\n",
      "Optimal scaler: 1.288\n",
      "After single scaling- Avg Length: 0.05654557794332504\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.05993583798408508 , number of samples:  425\n",
      "Avg Cov CP (val) in bin  1  : 0.9529411764705882 , number of samples:  425\n",
      "Avg Length CP (val) in bin  2  : 0.05431250110268593 , number of samples:  424\n",
      "Avg Cov CP (val) in bin  2  : 0.9528301886792453 , number of samples:  424\n",
      "q values CP: tensor([1.3456, 1.2448])\n",
      "After bins scaling CP (val) by - Avg Length: 0.057128969579935074\n",
      "After bins scaling CP (val) by - Avg Cov: 0.951764705882353\n",
      "Test 2 bins with Avg Length 0.05675320699810982\n",
      "Test 2 bins after bins with Cov Length 0.9388235294117647\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.060233209282159805 , number of samples:  283\n",
      "Avg Cov CP (val) in bin  1  : 0.9540636042402827 , number of samples:  283\n",
      "Avg Length CP (val) in bin  2  : 0.054065946489572525 , number of samples:  283\n",
      "Avg Cov CP (val) in bin  2  : 0.9540636042402827 , number of samples:  283\n",
      "Avg Length CP (val) in bin  3  : 0.0558854304254055 , number of samples:  283\n",
      "Avg Cov CP (val) in bin  3  : 0.9540636042402827 , number of samples:  283\n",
      "q values CP: tensor([1.3422, 1.2415, 1.2746])\n",
      "After bins scaling CP (val) by - Avg Length: 0.056730154901742935\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9529411764705882\n",
      "Test 3 bins with Avg Length 0.05628415197134018\n",
      "Test 3 bins after bins with Cov Length 0.9376470588235294\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.06175829470157623 , number of samples:  212\n",
      "Avg Cov CP (val) in bin  1  : 0.9575471698113207 , number of samples:  212\n",
      "Avg Length CP (val) in bin  2  : 0.05998812988400459 , number of samples:  213\n",
      "Avg Cov CP (val) in bin  2  : 0.9577464788732394 , number of samples:  213\n",
      "Avg Length CP (val) in bin  3  : 0.05508606135845184 , number of samples:  212\n",
      "Avg Cov CP (val) in bin  3  : 0.9575471698113207 , number of samples:  212\n",
      "Avg Length CP (val) in bin  4  : 0.05428275093436241 , number of samples:  212\n",
      "Avg Cov CP (val) in bin  4  : 0.9575471698113207 , number of samples:  212\n",
      "q values CP: tensor([1.3601, 1.3733, 1.2746, 1.2323])\n",
      "After bins scaling CP (val) by - Avg Length: 0.057782132178545\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9564705882352941\n",
      "Test 4 bins with Avg Length 0.057391732931137085\n",
      "Test 4 bins after bins with Cov Length 0.94\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.061854392290115356 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  1  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  2  : 0.05602623522281647 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  2  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  3  : 0.05351828411221504 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  3  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  4  : 0.05756310373544693 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  4  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  5  : 0.05417650192975998 , number of samples:  169\n",
      "Avg Cov CP (val) in bin  5  : 0.9585798816568047 , number of samples:  169\n",
      "q values CP: tensor([1.3601, 1.2663, 1.2448, 1.3154, 1.2323])\n",
      "After bins scaling CP (val) by - Avg Length: 0.056632671505212784\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9576470588235294\n",
      "Test 5 bins with Avg Length 0.05627541244029999\n",
      "Test 5 bins after bins with Cov Length 0.9352941176470588\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.061087965965270996 , number of samples:  141\n",
      "Avg Cov CP (val) in bin  1  : 0.9574468085106383 , number of samples:  141\n",
      "Avg Length CP (val) in bin  2  : 0.05953117087483406 , number of samples:  142\n",
      "Avg Cov CP (val) in bin  2  : 0.9577464788732394 , number of samples:  142\n",
      "Avg Length CP (val) in bin  3  : 0.0639372393488884 , number of samples:  142\n",
      "Avg Cov CP (val) in bin  3  : 0.9577464788732394 , number of samples:  142\n",
      "Avg Length CP (val) in bin  4  : 0.05272990092635155 , number of samples:  141\n",
      "Avg Cov CP (val) in bin  4  : 0.9574468085106383 , number of samples:  141\n",
      "Avg Length CP (val) in bin  5  : 0.05594741553068161 , number of samples:  142\n",
      "Avg Cov CP (val) in bin  5  : 0.9577464788732394 , number of samples:  142\n",
      "Avg Length CP (val) in bin  6  : 0.05618180334568024 , number of samples:  141\n",
      "Avg Cov CP (val) in bin  6  : 0.9574468085106383 , number of samples:  141\n",
      "q values CP: tensor([1.3422, 1.3456, 1.4570, 1.2203, 1.2878, 1.2698])\n",
      "After bins scaling CP (val) by - Avg Length: 0.058241646736860275\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9564705882352941\n",
      "Test 6 bins with Avg Length 0.05796470120549202\n",
      "Test 6 bins after bins with Cov Length 0.9435294117647058\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.062336597591638565 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  1  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  2  : 0.059580713510513306 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  2  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  3  : 0.0607588067650795 , number of samples:  122\n",
      "Avg Cov CP (val) in bin  3  : 0.9590163934426229 , number of samples:  122\n",
      "Avg Length CP (val) in bin  4  : 0.053066451102495193 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  4  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  5  : 0.05613425746560097 , number of samples:  122\n",
      "Avg Cov CP (val) in bin  5  : 0.9590163934426229 , number of samples:  122\n",
      "Avg Length CP (val) in bin  6  : 0.05538715794682503 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  6  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  7  : 0.05633670836687088 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  7  : 0.9586776859504132 , number of samples:  121\n",
      "q values CP: tensor([1.3601, 1.3456, 1.3733, 1.2415, 1.2844, 1.2746, 1.2698])\n",
      "After bins scaling CP (val) by - Avg Length: 0.057659972459077835\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9576470588235294\n",
      "Test 7 bins with Avg Length 0.05728291720151901\n",
      "Test 7 bins after bins with Cov Length 0.94\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.06243978440761566 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  1  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  2  : 0.0633469969034195 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  2  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  3  : 0.05342280864715576 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  3  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  4  : 0.06948550045490265 , number of samples:  107\n",
      "Avg Cov CP (val) in bin  4  : 0.9626168224299065 , number of samples:  107\n",
      "Avg Length CP (val) in bin  5  : 0.05232684314250946 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  5  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  6  : 0.0664934292435646 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  6  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  7  : 0.05075450241565704 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  7  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  8  : 0.05857199802994728 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  8  : 0.9622641509433962 , number of samples:  106\n",
      "q values CP: tensor([1.3601, 1.4106, 1.2204, 1.5940, 1.2203, 1.5267, 1.1665, 1.3136])\n",
      "After bins scaling CP (val) by - Avg Length: 0.05961543694138527\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9611764705882353\n",
      "Test 8 bins with Avg Length 0.059742968529462814\n",
      "Test 8 bins after bins with Cov Length 0.9447058823529412\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.0627712607383728 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  1  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  2  : 0.06319689005613327 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  2  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  3  : 0.06488512456417084 , number of samples:  95\n",
      "Avg Cov CP (val) in bin  3  : 0.968421052631579 , number of samples:  95\n",
      "Avg Length CP (val) in bin  4  : 0.07065267860889435 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  4  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  5  : 0.062142953276634216 , number of samples:  95\n",
      "Avg Cov CP (val) in bin  5  : 0.968421052631579 , number of samples:  95\n",
      "Avg Length CP (val) in bin  6  : 0.05415961518883705 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  6  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  7  : 0.06653372198343277 , number of samples:  95\n",
      "Avg Cov CP (val) in bin  7  : 0.968421052631579 , number of samples:  95\n",
      "Avg Length CP (val) in bin  8  : 0.053233735263347626 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  8  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  9  : 0.062380000948905945 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  9  : 0.9680851063829787 , number of samples:  94\n",
      "q values CP: tensor([1.3601, 1.4106, 1.4853, 1.5940, 1.4570, 1.2400, 1.5267, 1.2323, 1.3938])\n",
      "After bins scaling CP (val) by - Avg Length: 0.062220968306064606\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9670588235294117\n",
      "Test 9 bins with Avg Length 0.06177296116948128\n",
      "Test 9 bins after bins with Cov Length 0.9576470588235294\n",
      "Before scaling - Avg Length: 0.044\n",
      "Optimal scaler: 1.288\n",
      "After single scaling- Avg Length: 0.05652794986963272\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.05993583798408508 , number of samples:  425\n",
      "Avg Cov CP (val) in bin  1  : 0.9529411764705882 , number of samples:  425\n",
      "Avg Length CP (val) in bin  2  : 0.05431250110268593 , number of samples:  424\n",
      "Avg Cov CP (val) in bin  2  : 0.9528301886792453 , number of samples:  424\n",
      "q values CP: tensor([1.3456, 1.2448])\n",
      "After bins scaling CP (val) by - Avg Length: 0.057128969579935074\n",
      "After bins scaling CP (val) by - Avg Cov: 0.951764705882353\n",
      "Test 2 bins with Avg Length 0.05674417316913605\n",
      "Test 2 bins after bins with Cov Length 0.9352941176470588\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.060233209282159805 , number of samples:  283\n",
      "Avg Cov CP (val) in bin  1  : 0.9540636042402827 , number of samples:  283\n",
      "Avg Length CP (val) in bin  2  : 0.054065946489572525 , number of samples:  283\n",
      "Avg Cov CP (val) in bin  2  : 0.9540636042402827 , number of samples:  283\n",
      "Avg Length CP (val) in bin  3  : 0.0558854304254055 , number of samples:  283\n",
      "Avg Cov CP (val) in bin  3  : 0.9540636042402827 , number of samples:  283\n",
      "q values CP: tensor([1.3422, 1.2415, 1.2746])\n",
      "After bins scaling CP (val) by - Avg Length: 0.056730154901742935\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9529411764705882\n",
      "Test 3 bins with Avg Length 0.05628214776515961\n",
      "Test 3 bins after bins with Cov Length 0.9294117647058824\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.06175829470157623 , number of samples:  212\n",
      "Avg Cov CP (val) in bin  1  : 0.9575471698113207 , number of samples:  212\n",
      "Avg Length CP (val) in bin  2  : 0.05998812988400459 , number of samples:  213\n",
      "Avg Cov CP (val) in bin  2  : 0.9577464788732394 , number of samples:  213\n",
      "Avg Length CP (val) in bin  3  : 0.05508606135845184 , number of samples:  212\n",
      "Avg Cov CP (val) in bin  3  : 0.9575471698113207 , number of samples:  212\n",
      "Avg Length CP (val) in bin  4  : 0.05428275093436241 , number of samples:  212\n",
      "Avg Cov CP (val) in bin  4  : 0.9575471698113207 , number of samples:  212\n",
      "q values CP: tensor([1.3601, 1.3733, 1.2746, 1.2323])\n",
      "After bins scaling CP (val) by - Avg Length: 0.057782132178545\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9564705882352941\n",
      "Test 4 bins with Avg Length 0.057388246059417725\n",
      "Test 4 bins after bins with Cov Length 0.9376470588235294\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.061854392290115356 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  1  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  2  : 0.05602623522281647 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  2  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  3  : 0.05351828411221504 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  3  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  4  : 0.05756310373544693 , number of samples:  170\n",
      "Avg Cov CP (val) in bin  4  : 0.9588235294117647 , number of samples:  170\n",
      "Avg Length CP (val) in bin  5  : 0.05417650192975998 , number of samples:  169\n",
      "Avg Cov CP (val) in bin  5  : 0.9585798816568047 , number of samples:  169\n",
      "q values CP: tensor([1.3601, 1.2663, 1.2448, 1.3154, 1.2323])\n",
      "After bins scaling CP (val) by - Avg Length: 0.056632671505212784\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9576470588235294\n",
      "Test 5 bins with Avg Length 0.056271035224199295\n",
      "Test 5 bins after bins with Cov Length 0.9352941176470588\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.061087965965270996 , number of samples:  141\n",
      "Avg Cov CP (val) in bin  1  : 0.9574468085106383 , number of samples:  141\n",
      "Avg Length CP (val) in bin  2  : 0.05953117087483406 , number of samples:  142\n",
      "Avg Cov CP (val) in bin  2  : 0.9577464788732394 , number of samples:  142\n",
      "Avg Length CP (val) in bin  3  : 0.0639372393488884 , number of samples:  142\n",
      "Avg Cov CP (val) in bin  3  : 0.9577464788732394 , number of samples:  142\n",
      "Avg Length CP (val) in bin  4  : 0.05272990092635155 , number of samples:  141\n",
      "Avg Cov CP (val) in bin  4  : 0.9574468085106383 , number of samples:  141\n",
      "Avg Length CP (val) in bin  5  : 0.05594741553068161 , number of samples:  142\n",
      "Avg Cov CP (val) in bin  5  : 0.9577464788732394 , number of samples:  142\n",
      "Avg Length CP (val) in bin  6  : 0.05618180334568024 , number of samples:  141\n",
      "Avg Cov CP (val) in bin  6  : 0.9574468085106383 , number of samples:  141\n",
      "q values CP: tensor([1.3422, 1.3456, 1.4570, 1.2203, 1.2878, 1.2698])\n",
      "After bins scaling CP (val) by - Avg Length: 0.058241646736860275\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9564705882352941\n",
      "Test 6 bins with Avg Length 0.05795752629637718\n",
      "Test 6 bins after bins with Cov Length 0.9388235294117647\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.062336597591638565 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  1  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  2  : 0.059580713510513306 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  2  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  3  : 0.0607588067650795 , number of samples:  122\n",
      "Avg Cov CP (val) in bin  3  : 0.9590163934426229 , number of samples:  122\n",
      "Avg Length CP (val) in bin  4  : 0.053066451102495193 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  4  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  5  : 0.05613425746560097 , number of samples:  122\n",
      "Avg Cov CP (val) in bin  5  : 0.9590163934426229 , number of samples:  122\n",
      "Avg Length CP (val) in bin  6  : 0.05538715794682503 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  6  : 0.9586776859504132 , number of samples:  121\n",
      "Avg Length CP (val) in bin  7  : 0.05633670836687088 , number of samples:  121\n",
      "Avg Cov CP (val) in bin  7  : 0.9586776859504132 , number of samples:  121\n",
      "q values CP: tensor([1.3601, 1.3456, 1.3733, 1.2415, 1.2844, 1.2746, 1.2698])\n",
      "After bins scaling CP (val) by - Avg Length: 0.057659972459077835\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9576470588235294\n",
      "Test 7 bins with Avg Length 0.05729367956519127\n",
      "Test 7 bins after bins with Cov Length 0.9376470588235294\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.06243978440761566 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  1  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  2  : 0.0633469969034195 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  2  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  3  : 0.05342280864715576 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  3  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  4  : 0.06948550045490265 , number of samples:  107\n",
      "Avg Cov CP (val) in bin  4  : 0.9626168224299065 , number of samples:  107\n",
      "Avg Length CP (val) in bin  5  : 0.05232684314250946 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  5  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  6  : 0.0664934292435646 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  6  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  7  : 0.05075450241565704 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  7  : 0.9622641509433962 , number of samples:  106\n",
      "Avg Length CP (val) in bin  8  : 0.05857199802994728 , number of samples:  106\n",
      "Avg Cov CP (val) in bin  8  : 0.9622641509433962 , number of samples:  106\n",
      "q values CP: tensor([1.3601, 1.4106, 1.2204, 1.5940, 1.2203, 1.5267, 1.1665, 1.3136])\n",
      "After bins scaling CP (val) by - Avg Length: 0.05961543694138527\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9611764705882353\n",
      "Test 8 bins with Avg Length 0.0597381666302681\n",
      "Test 8 bins after bins with Cov Length 0.9411764705882353\n",
      "Optimal scaler CP (val): 1.288\n",
      "After single scaling- Avg Length CP (val): 0.05679744854569435\n",
      "After single scaling- Avg Cov CP (val): 0.951764705882353\n",
      "Avg Length CP (val) in bin  1  : 0.0627712607383728 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  1  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  2  : 0.06319689005613327 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  2  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  3  : 0.06488512456417084 , number of samples:  95\n",
      "Avg Cov CP (val) in bin  3  : 0.968421052631579 , number of samples:  95\n",
      "Avg Length CP (val) in bin  4  : 0.07065267860889435 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  4  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  5  : 0.062142953276634216 , number of samples:  95\n",
      "Avg Cov CP (val) in bin  5  : 0.968421052631579 , number of samples:  95\n",
      "Avg Length CP (val) in bin  6  : 0.05415961518883705 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  6  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  7  : 0.06653372198343277 , number of samples:  95\n",
      "Avg Cov CP (val) in bin  7  : 0.968421052631579 , number of samples:  95\n",
      "Avg Length CP (val) in bin  8  : 0.053233735263347626 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  8  : 0.9680851063829787 , number of samples:  94\n",
      "Avg Length CP (val) in bin  9  : 0.062380000948905945 , number of samples:  94\n",
      "Avg Cov CP (val) in bin  9  : 0.9680851063829787 , number of samples:  94\n",
      "q values CP: tensor([1.3601, 1.4106, 1.4853, 1.5940, 1.4570, 1.2400, 1.5267, 1.2323, 1.3938])\n",
      "After bins scaling CP (val) by - Avg Length: 0.062220968306064606\n",
      "After bins scaling CP (val) by - Avg Cov: 0.9670588235294117\n",
      "Test 9 bins with Avg Length 0.06182694062590599\n",
      "Test 9 bins after bins with Cov Length 0.9529411764705882\n",
      "Before scaling - Avg Length: 0.044\n",
      "Optimal scaler: 1.288\n",
      "After single scaling- Avg Length: 0.05651446804404259\n",
      "Test before, Avg Length: 0.04389818757772446\n",
      "Test after single, Avg Length: 0.056530434638261795\n",
      "5 bins, Avg Length: 0.0562794990837574\n",
      "Test before with Avg Cov: 0.8489411473274231\n",
      "Test after single with Avg Cov: 0.9376470446586609\n",
      "5 bins, Avg Cov: 0.9338823556900024\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "save_path = 'C:/lior/studies/master/projects/calibration/regression calibration/regression_calibration/reports/var_and_mse_calib/'\n",
    "# with open(save_path + f'{base_model}_gaussian_boneage_best_freeze_lr_3e-05_nll.pickle', 'rb') as handle:\n",
    "# with open(save_path + f'{base_model}_gaussian_boneage_493_conformal.pickle', 'rb') as handle:\n",
    "# with open(save_path + f'{base_model}_gaussian_endovis_199_new_conformal.pickle', 'rb') as handle:\n",
    "with open(save_path + f'{base_model}_gaussian_oct_new_conformal.pickle', 'rb') as handle:\n",
    "    calib_dict = pickle.load(handle)\n",
    "    err_calib = calib_dict['err'][0]\n",
    "    err_test = calib_dict['err'][1]\n",
    "    uncert_calib = calib_dict['uncert'][0]\n",
    "    uncert_test = calib_dict['uncert'][1]\n",
    "    uncert_calib_laves = calib_dict['uncert'][2]\n",
    "    uncert_test_laves = calib_dict['uncert'][3]\n",
    "    mu_calib = calib_dict['mu'][0]\n",
    "    mu_test_list = calib_dict['mu'][1]\n",
    "    target_calib = calib_dict['target'][0]\n",
    "    target_test_list = calib_dict['target'][1]\n",
    "    q = calib_dict['q']\n",
    "\n",
    "# Bins conformal prediction\n",
    "avg_len_before_list = []\n",
    "avg_len_single_list = []\n",
    "avg_len_q_bins_list = []\n",
    "\n",
    "avg_cov_before_list = []\n",
    "avg_cov_after_single_list = []\n",
    "avg_cov_after_bins_list = []\n",
    "\n",
    "target_calib = target_calib.mean(dim=1, keepdim=True)\n",
    "mu_calib = mu_calib.mean(dim=1, keepdim=True)\n",
    "mu_test_list = [mu_test.mean(dim=1, keepdim=True) for mu_test in mu_test_list]\n",
    "target_test_list = [target_test.mean(dim=1, keepdim=True) for target_test in target_test_list]\n",
    "# target_calib = target_calib[:, 0].unsqueeze(-1)\n",
    "# mu_calib = mu_calib[:, 0].unsqueeze(-1)\n",
    "# mu_test_list = [mu_test[:, 0].unsqueeze(-1) for mu_test in mu_test_list]\n",
    "# target_test_list = [target_test[:, 0].unsqueeze(-1) for target_test in target_test_list]\n",
    "\n",
    "for i in range(len(err_test)):\n",
    "    for b in range(2, 10):\n",
    "        n_bins = b\n",
    "        bins_q, q, bin_boundaries, avg_len_bins_val = set_scaler_conformal(target_calib, mu_calib, uncert_calib, num_bins=n_bins, by_uncert=False, gc=False, err_calib=err_calib)\n",
    "        avg_len_bins, uncert_test_after = scale_bins_conformal(mu_test_list[i], uncert_test[i], bins_q, bin_boundaries, num_bins=n_bins, by_uncert=False)\n",
    "        \n",
    "        avg_cov_after_bins = avg_cov(mu_test_list[i], uncert_test_after, target_test_list[i])\n",
    "        \n",
    "        print(f'Test {n_bins} bins with Avg Length {avg_len_bins}')\n",
    "        print(f'Test {n_bins} bins after bins with Cov Length {avg_cov_after_bins}')\n",
    "        \n",
    "        # bins_q_gc, q_gc, _, avg_len_bins_val_gc = set_scaler_conformal(target_calib, mu_calib, uncert_calib, num_bins=n_bins, by_uncert=False, gc=True)\n",
    "    \n",
    "        if n_bins == 2:\n",
    "            best_avg_len = avg_len_bins\n",
    "            mean_avg_len = best_avg_len\n",
    "            best_n_bins = 2\n",
    "            best_bins_q = bins_q\n",
    "            best_avg_cov = avg_cov_after_bins\n",
    "        else:\n",
    "            mean_avg_len = avg_len_bins\n",
    "            if mean_avg_len < best_avg_len:\n",
    "                best_n_bins = n_bins\n",
    "                best_avg_len = mean_avg_len\n",
    "                best_bins_q = bins_q\n",
    "                best_avg_cov = avg_cov_after_bins\n",
    "                \n",
    "    avg_len_single, avg_len_before = scale_bins_single_conformal(uncert_test[i], q)\n",
    "    \n",
    "    avg_cov_before = avg_cov(mu_test_list[i], uncert_test[i], target_test_list[i])\n",
    "    avg_cov_after_single = avg_cov(mu_test_list[i], q * uncert_test[i], target_test_list[i])\n",
    "    \n",
    "    avg_len_before_list.append(avg_len_before.cpu())\n",
    "    avg_len_single_list.append(avg_len_single.cpu())\n",
    "    avg_len_q_bins_list.append(best_avg_len.cpu())\n",
    "    \n",
    "    avg_cov_before_list.append(avg_cov_before)\n",
    "    avg_cov_after_single_list.append(avg_cov_after_single)\n",
    "    avg_cov_after_bins_list.append(best_avg_cov)\n",
    "    \n",
    "print(f'Test before, Avg Length:', torch.stack(avg_len_before_list).mean().item())\n",
    "print(f'Test after single, Avg Length:', torch.stack(avg_len_single_list).mean().item())\n",
    "print(f'{best_n_bins} bins, Avg Length:', torch.stack(avg_len_q_bins_list).mean().item())\n",
    "\n",
    "print(f'Test before with Avg Cov:', torch.tensor(avg_cov_before_list).mean().item())\n",
    "print(f'Test after single with Avg Cov:', torch.tensor(avg_cov_after_single_list).mean().item())\n",
    "print(f'{best_n_bins} bins, Avg Cov:', torch.tensor(avg_cov_after_bins_list).mean().item())\n",
    "      \n",
    "save_path = 'C:/lior/studies/master/projects/calibration/regression calibration/regression_calibration/reports/var_and_mse_calib/'\n",
    "with open(save_path + f'{base_model}_gaussian_endovis_q_bins_conformal_by_mu_10_bins.pickle', 'wb') as handle:\n",
    "    pickle.dump({'q_bins': bins_q\n",
    "                 ,'q': q}\n",
    "                , handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003966884221881628\n",
      "0.004064125940203667\n",
      "0.0038832565769553185\n",
      "0.0036435327492654324\n",
      "0.003968506120145321\n",
      "0.10895918309688568 0.0010628389427438378\n",
      "5.474307060241699\n"
     ]
    }
   ],
   "source": [
    "if base_model == 'resnet101':\n",
    "    uce_range = [0, 0.0044]\n",
    "elif base_model == 'densenet201':\n",
    "    uce_range = [0, 0.0012]\n",
    "elif base_model == 'efficientnetb4':\n",
    "    uce_range = [0, 0.0008]\n",
    "\n",
    "n_bins = 15\n",
    "uce_uncal_list = []\n",
    "err_uncal_list = []\n",
    "uncert_uncal_list = []\n",
    "ence_bins_list = []\n",
    "for i in range(len(err_test)):\n",
    "    print((uncert_test[i]**2).max().item())\n",
    "    # uce_uncal, err_uncal, uncert_uncal, _, uce_per_bin = uceloss(err_test[i]**2, uncert_test[i]**2, n_bins=n_bins, range=uce_range)\n",
    "    uce_uncal, err_uncal, uncert_uncal, _, uce_per_bin = uceloss(err_test[i]**2, uncert_test[i]**2, n_bins=n_bins)\n",
    "    ence_bins = enceloss(err_test[i]**2, uncert_test[i]**2, n_bins=15, single=True)\n",
    "    uce_uncal_list.append(uce_uncal.cpu())\n",
    "    err_uncal_list.append(err_uncal.cpu())\n",
    "    uncert_uncal_list.append(uncert_uncal.cpu())\n",
    "    ence_bins_list.append(ence_bins.cpu())\n",
    "\n",
    "print((torch.stack(uce_uncal_list)*100).mean().item(), (torch.stack(uce_uncal_list)*100).var().sqrt().item())\n",
    "print((torch.stack(ence_bins_list)).mean().item())\n",
    "# plot_uncert_multi(err_uncal_list, uncert_uncal_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0021111154928803444\n",
      "0.0020088106393814087\n",
      "0.002141239121556282\n",
      "0.0021693799644708633\n",
      "0.0020733776036649942\n",
      "0.01242920383810997 0.0028368011116981506\n",
      "1.787946105003357\n"
     ]
    }
   ],
   "source": [
    "if base_model == 'resnet101':\n",
    "    uce_range = [0, 0.0085]\n",
    "elif base_model == 'densenet201':\n",
    "    uce_range = [0, 0.016]\n",
    "elif base_model == 'efficientnetb4':\n",
    "    uce_range = [0, 0.01]\n",
    "\n",
    "n_bins = 15\n",
    "uce_s_list = []\n",
    "err_s_list = []\n",
    "uncert_s_list = []\n",
    "ence_bins_list = []\n",
    "for i in range(len(err_test)):\n",
    "    print((scaler_laves(uncert_test_laves[i])**2).max().item())\n",
    "    # uce_s, err_s, uncert_s, _, uce_per_bin = uceloss(err_test[i]**2, scaler_laves(uncert_test_laves[i])**2, n_bins=n_bins, range=uce_range)\n",
    "    uce_s, err_s, uncert_s, _, uce_per_bin = uceloss(err_test[i]**2, scaler_laves(uncert_test_laves[i])**2, n_bins=n_bins)\n",
    "    ence_bins = enceloss(err_test[i]**2, scaler_laves(uncert_test_laves[i])**2, n_bins=15, single=True)\n",
    "    uce_s_list.append(uce_s.cpu())\n",
    "    err_s_list.append(err_s.cpu())\n",
    "    uncert_s_list.append(uncert_s.cpu())\n",
    "    ence_bins_list.append(ence_bins.cpu())\n",
    "    \n",
    "\n",
    "print((torch.stack(uce_s_list)*100).mean().item(), (torch.stack(uce_s_list)*100).var().sqrt().item())\n",
    "print((torch.stack(ence_bins_list)).mean().item())\n",
    "# plot_uncert_multi(err_s_list, uncert_s_list)\n",
    "\n",
    "#fig, ax = plot_frequency(scaler_laves(uncert_test_laves[0]).cpu(), in_bin.cpu(), n_bins=n_bins)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0013094755122438073\n",
      "tensor(0.6561, device='cuda:0')\n",
      "0.001178077538497746\n",
      "tensor(0.6561, device='cuda:0')\n",
      "0.0011762042995542288\n",
      "tensor(0.6561, device='cuda:0')\n",
      "0.00127106171566993\n",
      "tensor(0.6561, device='cuda:0')\n",
      "0.0011983378790318966\n",
      "tensor(0.6561, device='cuda:0')\n",
      "0.056520432233810425 0.0008964310400187969\n",
      "4.202175140380859\n"
     ]
    }
   ],
   "source": [
    "#Ethan\n",
    "n_bins = 15\n",
    "uce_s_list = []\n",
    "err_s_list = []\n",
    "uncert_s_list = []\n",
    "ence_bins_list = []\n",
    "for i in range(len(err_test)):\n",
    "    print(((S*uncert_test[i])**2).max().item())\n",
    "    print(S)\n",
    "    uce_s, err_s, uncert_s, _, uce_per_bin = uceloss(err_test[i]**2, (S*uncert_test[i])**2, n_bins=n_bins)\n",
    "    ence_bins = enceloss(err_test[i]**2, (S*uncert_test[i])**2, n_bins=15, single=True)\n",
    "    uce_s_list.append(uce_s.cpu())\n",
    "    err_s_list.append(err_s.cpu())\n",
    "    uncert_s_list.append(uncert_s.cpu())\n",
    "    ence_bins_list.append(ence_bins.cpu())\n",
    "\n",
    "print((torch.stack(uce_s_list)*100).mean().item(), (torch.stack(uce_s_list)*100).var().sqrt().item())\n",
    "print((torch.stack(ence_bins_list)).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0020764425862580538\n",
      "0.002110564149916172\n",
      "0.002083806088194251\n",
      "0.002107511041685939\n",
      "0.0021611484698951244\n",
      "0.012718446552753448 0.001980116358026862\n",
      "1.259643793106079\n"
     ]
    }
   ],
   "source": [
    "if base_model == 'resnet101':\n",
    "    uce_range = [0, 0.0051]\n",
    "elif base_model == 'densenet201':\n",
    "    uce_range = [0, 0.007]\n",
    "elif base_model == 'efficientnetb4':\n",
    "    uce_range = [0, 0.005]\n",
    "\n",
    "n_bins = 15\n",
    "uce_aux_list = []\n",
    "err_aux_list = []\n",
    "uncert_aux_list = []\n",
    "ence_bins_list = []\n",
    "for i in range(len(err_test)):\n",
    "    print((aux(uncert_test[i])**2).max().item())\n",
    "    uce_aux, _, _, _, uce_per_bin = uceloss(err_test[i]**2, aux(uncert_test[i])**2, n_bins=n_bins)\n",
    "    ence_bins = enceloss(err_test[i]**2, aux(uncert_test[i])**2, n_bins=15, single=True)\n",
    "    # _, err_aux, uncert_aux, _, uce_per_bin = uceloss(err_test[i]**2, aux(uncert_test[i])**2, n_bins=n_bins, range=uce_range)\n",
    "    uce_aux_list.append(uce_aux.cpu())\n",
    "    ence_bins_list.append(ence_bins.cpu())\n",
    "    # err_aux_list.append(err_aux.cpu())\n",
    "    # uncert_aux_list.append(uncert_aux.cpu())\n",
    "\n",
    "print((torch.stack(uce_aux_list)*100).mean().item(), (torch.stack(uce_aux_list)*100).var().sqrt().item())\n",
    "print((torch.stack(ence_bins_list)).mean().item())\n",
    "# plot_uncert_multi(err_aux_list, uncert_aux_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['font.size'] = 8\n",
    "matplotlib.rcParams['text.latex.preamble'] = [\n",
    "    r'\\usepackage{bm}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_log(base_model):\n",
    "    with open(f\"results_levi_oct_{base_model}.log\", \"w\") as f:\n",
    "        print(\"MSE\", file=f)\n",
    "        print([(e**2).mean().item() for e in err_test], file=f)\n",
    "        print(\"mean\", np.mean([(e**2).mean().item() for e in err_test]), file=f)\n",
    "        print(\"std \", np.std([(e**2).mean().item() for e in err_test]), file=f)\n",
    "        print(\"\", file=f)\n",
    "        \n",
    "        print(\"uncal\", file=f)\n",
    "        print(\"NLL\", file=f)\n",
    "        nll = [nll_criterion_gaussian(mu_test_list[i], uncert_test[i].pow(2).log(), target_test_list[i]).item() for i in range(len(mu_test_list))]\n",
    "        print(nll, file=f)\n",
    "        print(\"mean\", np.mean(nll), file=f)\n",
    "        print(\"std \", np.std(nll), file=f)\n",
    "        print(\"UCE\", file=f)\n",
    "        print([u.item() for u in uce_uncal_list], file=f)\n",
    "        print(\"mean\", (torch.stack(uce_uncal_list)*100).mean().item(), file=f)\n",
    "        print(\"std \", (torch.stack(uce_uncal_list)*100).var().sqrt().item(), file=f)\n",
    "        print(\"\", file=f)\n",
    "        \n",
    "        print(\"aux\", file=f)\n",
    "        print(\"NLL\", file=f)\n",
    "        aux.train()\n",
    "        nll = [nll_criterion_gaussian(mu_test_list[i], aux(uncert_test[i]), target_test_list[i]).item() for i in range(len(mu_test_list))]\n",
    "        aux.eval()\n",
    "        print(nll, file=f)\n",
    "        print(\"mean\", np.mean(nll), file=f)\n",
    "        print(\"std \", np.std(nll), file=f)\n",
    "        print(\"UCE\", file=f)\n",
    "        print([u.item() for u in uce_aux_list], file=f)\n",
    "        print(\"mean\", (torch.stack(uce_aux_list)*100).mean().item(), file=f)\n",
    "        print(\"std \", (torch.stack(uce_aux_list)*100).var().sqrt().item(), file=f)\n",
    "        print(\"\", file=f)\n",
    "        \n",
    "        print(\"s\", file=f)\n",
    "        print(\"NLL\", file=f)\n",
    "        nll = [nll_criterion_gaussian(mu_test_list[i], scaler(uncert_test[i]).pow(2).log(), target_test_list[i]).item() for i in range(len(mu_test_list))]\n",
    "        print(nll, file=f)\n",
    "        print(\"mean\", np.mean(nll), file=f)\n",
    "        print(\"std \", np.std(nll), file=f)\n",
    "        print(\"UCE\", file=f)\n",
    "        print([u.item() for u in uce_s_list], file=f)\n",
    "        print(\"mean\", (torch.stack(uce_s_list)*100).mean().item(), file=f)\n",
    "        print(\"std \", (torch.stack(uce_s_list)*100).var().sqrt().item(), file=f)\n",
    "        print(\"S =\", scaler.S.item(), file=f)\n",
    "        print(\"\", file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "if base_model == 'resnet101':\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(6.8, 2.75))\n",
    "\n",
    "    alpha = 0.4\n",
    "    props = dict(boxstyle='round', facecolor='white', alpha=0.75)\n",
    "\n",
    "    err_uncal = torch.stack(err_uncal_list).mean(dim=0).cpu()\n",
    "    err_uncal_var = torch.stack(err_uncal_list).var(dim=0).sqrt().cpu()\n",
    "    uncert_uncal = torch.stack(uncert_uncal_list).mean(dim=0).cpu()\n",
    "    ax[0].plot([0, 0.003], [0, 0.003], 'k--')\n",
    "    ax[0].plot(uncert_uncal, err_uncal, marker='.', label='uncal')\n",
    "    ax[0].fill_between(uncert_uncal, err_uncal-err_uncal_var, err_uncal+err_uncal_var, alpha=alpha)\n",
    "    ax[0].set_ylabel(r'observed uncertainty', fontsize=11)\n",
    "    ax[0].set_xlabel(r'expected uncertainty', fontsize=11)\n",
    "    ax[0].set_xlim([-0.0002, 0.0032])\n",
    "    ax[0].set_ylim([-0.0002, 0.0032])\n",
    "    ax[0].set_xticks([0, 0.0015, 0.003])\n",
    "    ax[0].set_yticks([0, 0.0015, 0.003])\n",
    "    ax[0].set_aspect(1)\n",
    "    ax[0].set_title(r'uncalibrated')\n",
    "    textstr0 = r'UCE\\,=\\,{:.2f}'.format((torch.stack(uce_uncal_list)*100).mean().item())\n",
    "    ax[0].text(0.925, 0.075, textstr0, transform=ax[0].transAxes, fontsize=10,\n",
    "                    verticalalignment='bottom',\n",
    "                    horizontalalignment='right',\n",
    "                    bbox=props\n",
    "                    )\n",
    "\n",
    "    err_aux = torch.stack(err_aux_list).mean(dim=0).cpu()\n",
    "    err_aux_var = torch.stack(err_aux_list).var(dim=0).sqrt().cpu()\n",
    "    uncert_aux = torch.stack(uncert_aux_list).mean(dim=0).cpu()\n",
    "    ax[1].plot([0, 0.003], [0, 0.003], 'k--')\n",
    "    ax[1].plot(uncert_aux, err_aux, marker='.', label='uncal')\n",
    "    ax[1].fill_between(uncert_aux, err_aux-err_aux_var, err_aux+err_aux_var, alpha=alpha)\n",
    "    ax[1].set_ylabel(r'observed uncertainty', fontsize=11)\n",
    "    ax[1].set_xlabel(r'expected uncertainty', fontsize=11)\n",
    "    ax[1].set_xlim([0.0013, 0.0032])\n",
    "    ax[1].set_ylim([0.0013, 0.0032])\n",
    "    ax[1].set_xticks([0.0015, 0.003])\n",
    "    ax[1].set_yticks([0.0015, 0.003])\n",
    "    ax[1].set_aspect(1)\n",
    "    ax[1].set_title(r'aux scaling')\n",
    "    textstr1 = r'UCE\\,=\\,{:.2f}'.format((torch.stack(uce_aux_list)*100).mean().item())\n",
    "    ax[1].text(0.925, 0.075, textstr1, transform=ax[1].transAxes, fontsize=10,\n",
    "                    verticalalignment='bottom',\n",
    "                    horizontalalignment='right',\n",
    "                    bbox=props\n",
    "                    )\n",
    "\n",
    "    err_s = torch.stack(err_s_list).mean(dim=0).cpu()\n",
    "    err_s_var = torch.stack(err_s_list).var(dim=0).sqrt().cpu()\n",
    "    uncert_s = torch.stack(uncert_s_list).mean(dim=0).cpu()\n",
    "    ax[2].plot([0, 0.003], [0, 0.003], 'k--')\n",
    "    ax[2].plot(uncert_s, err_s, marker='.', label='uncal')\n",
    "    ax[2].fill_between(uncert_s, err_s-err_s_var, err_s+err_s_var, alpha=alpha)\n",
    "    ax[2].set_ylabel(r'observed uncertainty', fontsize=11)\n",
    "    ax[2].set_xlabel(r'expected uncertainty', fontsize=11)\n",
    "    ax[2].set_xlim([0.0013, 0.0032])\n",
    "    ax[2].set_ylim([0.0013, 0.0032])\n",
    "    ax[2].set_xticks([0.0015, 0.003])\n",
    "    ax[2].set_yticks([0.0015, 0.003])\n",
    "    ax[2].set_aspect(1)\n",
    "    ax[2].set_title(r'$ \\sigma $ scaling')\n",
    "    textstr2 = r'UCE\\,=\\,{:.2f}'.format((torch.stack(uce_s_list)*100).mean().item())\n",
    "    ax[2].text(0.925, 0.075, textstr2, transform=ax[2].transAxes, fontsize=10,\n",
    "                    verticalalignment='bottom',\n",
    "                    horizontalalignment='right',\n",
    "                    bbox=props\n",
    "                    )\n",
    "\n",
    "    ax[0].annotate(r'OCT/ResNet-101', xy=(0, 0.5), xytext=(-ax[0].yaxis.labelpad - 5, 0),\n",
    "                   xycoords=ax[0].yaxis.label, textcoords='offset points',\n",
    "                   size='large', ha='right', va='center', fontsize=10, rotation=90)\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n",
    "    fig.savefig(f\"results_levi_oct_{base_model}.pdf\", bbox_inches='tight', pad_inches=0.01)\n",
    "    save_log(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "if base_model == 'densenet201':\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(6.8, 2.75))\n",
    "\n",
    "    alpha = 0.4\n",
    "    props = dict(boxstyle='round', facecolor='white', alpha=0.75)\n",
    "\n",
    "    err_uncal = torch.stack(err_uncal_list).mean(dim=0).cpu()\n",
    "    err_uncal_var = torch.stack(err_uncal_list).var(dim=0).sqrt().cpu()\n",
    "    uncert_uncal = torch.stack(uncert_uncal_list).mean(dim=0).cpu()\n",
    "    ax[0].plot([0, 0.2], [0, 0.2], 'k--')\n",
    "    ax[0].plot(uncert_uncal, err_uncal, marker='.', label='uncal')\n",
    "    ax[0].fill_between(uncert_uncal, err_uncal-err_uncal_var, err_uncal+err_uncal_var, alpha=alpha)\n",
    "    ax[0].set_ylabel(r'observed uncertainty', fontsize=11)\n",
    "    ax[0].set_xlabel(r'expected uncertainty', fontsize=11)\n",
    "    ax[0].set_xlim([0.0004, 0.0024])\n",
    "    ax[0].set_ylim([0.0004, 0.0024])\n",
    "    ax[0].set_xticks([0.001, 0.002])\n",
    "    ax[0].set_yticks([0.001, 0.002])\n",
    "    ax[0].set_aspect(1)\n",
    "    ax[0].set_title(r'uncalibrated')\n",
    "    textstr0 = r'UCE\\,=\\,{:.2f}'.format((torch.stack(uce_uncal_list)*100).mean().item())\n",
    "    ax[0].text(0.925, 0.075, textstr0, transform=ax[0].transAxes, fontsize=10,\n",
    "                    verticalalignment='bottom',\n",
    "                    horizontalalignment='right',\n",
    "                    bbox=props\n",
    "                    )\n",
    "\n",
    "    err_aux = torch.stack(err_aux_list).mean(dim=0).cpu()\n",
    "    err_aux_var = torch.stack(err_aux_list).var(dim=0).sqrt().cpu()\n",
    "    uncert_aux = torch.stack(uncert_aux_list).mean(dim=0).cpu()\n",
    "    ax[1].plot([0, 0.2], [0, 0.2], 'k--')\n",
    "    ax[1].plot(uncert_aux, err_aux, marker='.', label='uncal')\n",
    "    ax[1].fill_between(uncert_aux, err_aux-err_aux_var, err_aux+err_aux_var, alpha=alpha)\n",
    "    ax[1].set_ylabel(r'observed uncertainty', fontsize=11)\n",
    "    ax[1].set_xlabel(r'expected uncertainty', fontsize=11)\n",
    "    ax[1].set_xlim([0.0008, 0.0023])\n",
    "    ax[1].set_ylim([0.0008, 0.0023])\n",
    "    ax[1].set_xticks([0.001, 0.002])\n",
    "    ax[1].set_yticks([0.001, 0.002])\n",
    "    ax[1].set_aspect(1)\n",
    "    ax[1].set_title(r'aux scaling')\n",
    "    textstr1 = r'UCE\\,=\\,{:.2f}'.format((torch.stack(uce_aux_list)*100).mean().item())\n",
    "    ax[1].text(0.925, 0.075, textstr1, transform=ax[1].transAxes, fontsize=10,\n",
    "                    verticalalignment='bottom',\n",
    "                    horizontalalignment='right',\n",
    "                    bbox=props\n",
    "                    )\n",
    "\n",
    "    err_s = torch.stack(err_s_list).mean(dim=0).cpu()\n",
    "    err_s_var = torch.stack(err_s_list).var(dim=0).sqrt().cpu()\n",
    "    uncert_s = torch.stack(uncert_s_list).mean(dim=0).cpu()\n",
    "    ax[2].plot([0, 0.2], [0, 0.2], 'k--')\n",
    "    ax[2].plot(uncert_s, err_s, marker='.', label='uncal')\n",
    "    ax[2].fill_between(uncert_s, err_s-err_s_var, err_s+err_s_var, alpha=alpha)\n",
    "    ax[2].set_ylabel(r'observed uncertainty', fontsize=11)\n",
    "    ax[2].set_xlabel(r'expected uncertainty', fontsize=11)\n",
    "    ax[2].set_xlim([0.0008, 0.0022])\n",
    "    ax[2].set_ylim([0.0008, 0.0022])\n",
    "    ax[2].set_xticks([0.001, 0.002])\n",
    "    ax[2].set_yticks([0.001, 0.002])\n",
    "    ax[2].set_aspect(1)\n",
    "    ax[2].set_title(r'$ \\sigma $ scaling')\n",
    "    textstr2 = r'UCE\\,=\\,{:.2f}'.format((torch.stack(uce_s_list)*100).mean().item())\n",
    "    ax[2].text(0.925, 0.075, textstr2, transform=ax[2].transAxes, fontsize=10,\n",
    "                    verticalalignment='bottom',\n",
    "                    horizontalalignment='right',\n",
    "                    bbox=props\n",
    "                    )\n",
    "\n",
    "    ax[0].annotate(r'OCT/DenseNet-201', xy=(0, 0.5), xytext=(-ax[0].yaxis.labelpad - 5, 0),\n",
    "                   xycoords=ax[0].yaxis.label, textcoords='offset points',\n",
    "                   size='large', ha='right', va='center', fontsize=10, rotation=90)\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n",
    "    fig.savefig(f\"results_levi_oct_{base_model}.pdf\", bbox_inches='tight', pad_inches=0.01)\n",
    "    save_log(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "/* Put everything inside the global mpl namespace */\nwindow.mpl = {};\n\n\nmpl.get_websocket_type = function() {\n    if (typeof(WebSocket) !== 'undefined') {\n        return WebSocket;\n    } else if (typeof(MozWebSocket) !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert('Your browser does not have WebSocket support. ' +\n              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n              'Firefox 4 and 5 are also supported but you ' +\n              'have to enable WebSockets in about:config.');\n    };\n}\n\nmpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = (this.ws.binaryType != undefined);\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById(\"mpl-warnings\");\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent = (\n                \"This browser does not support binary websocket messages. \" +\n                    \"Performance may be slow.\");\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = $('<div/>');\n    this._root_extra_style(this.root)\n    this.root.attr('style', 'display: inline-block');\n\n    $(parent_element).append(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen =  function () {\n            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n            fig.send_message(\"send_image_mode\", {});\n            if (mpl.ratio != 1) {\n                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n            }\n            fig.send_message(\"refresh\", {});\n        }\n\n    this.imageObj.onload = function() {\n            if (fig.image_mode == 'full') {\n                // Full images could contain transparency (where diff images\n                // almost always do), so we need to clear the canvas so that\n                // there is no ghosting.\n                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n            }\n            fig.context.drawImage(fig.imageObj, 0, 0);\n        };\n\n    this.imageObj.onunload = function() {\n        fig.ws.close();\n    }\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n}\n\nmpl.figure.prototype._init_header = function() {\n    var titlebar = $(\n        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n        'ui-helper-clearfix\"/>');\n    var titletext = $(\n        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n        'text-align: center; padding: 3px;\"/>');\n    titlebar.append(titletext)\n    this.root.append(titlebar);\n    this.header = titletext[0];\n}\n\n\n\nmpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n\n}\n\n\nmpl.figure.prototype._root_extra_style = function(canvas_div) {\n\n}\n\nmpl.figure.prototype._init_canvas = function() {\n    var fig = this;\n\n    var canvas_div = $('<div/>');\n\n    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n\n    function canvas_keyboard_event(event) {\n        return fig.key_event(event, event['data']);\n    }\n\n    canvas_div.keydown('key_press', canvas_keyboard_event);\n    canvas_div.keyup('key_release', canvas_keyboard_event);\n    this.canvas_div = canvas_div\n    this._canvas_extra_style(canvas_div)\n    this.root.append(canvas_div);\n\n    var canvas = $('<canvas/>');\n    canvas.addClass('mpl-canvas');\n    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n\n    this.canvas = canvas[0];\n    this.context = canvas[0].getContext(\"2d\");\n\n    var backingStore = this.context.backingStorePixelRatio ||\n\tthis.context.webkitBackingStorePixelRatio ||\n\tthis.context.mozBackingStorePixelRatio ||\n\tthis.context.msBackingStorePixelRatio ||\n\tthis.context.oBackingStorePixelRatio ||\n\tthis.context.backingStorePixelRatio || 1;\n\n    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband = $('<canvas/>');\n    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n\n    var pass_mouse_events = true;\n\n    canvas_div.resizable({\n        start: function(event, ui) {\n            pass_mouse_events = false;\n        },\n        resize: function(event, ui) {\n            fig.request_resize(ui.size.width, ui.size.height);\n        },\n        stop: function(event, ui) {\n            pass_mouse_events = true;\n            fig.request_resize(ui.size.width, ui.size.height);\n        },\n    });\n\n    function mouse_event_fn(event) {\n        if (pass_mouse_events)\n            return fig.mouse_event(event, event['data']);\n    }\n\n    rubberband.mousedown('button_press', mouse_event_fn);\n    rubberband.mouseup('button_release', mouse_event_fn);\n    // Throttle sequential mouse events to 1 every 20ms.\n    rubberband.mousemove('motion_notify', mouse_event_fn);\n\n    rubberband.mouseenter('figure_enter', mouse_event_fn);\n    rubberband.mouseleave('figure_leave', mouse_event_fn);\n\n    canvas_div.on(\"wheel\", function (event) {\n        event = event.originalEvent;\n        event['data'] = 'scroll'\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        mouse_event_fn(event);\n    });\n\n    canvas_div.append(canvas);\n    canvas_div.append(rubberband);\n\n    this.rubberband = rubberband;\n    this.rubberband_canvas = rubberband[0];\n    this.rubberband_context = rubberband[0].getContext(\"2d\");\n    this.rubberband_context.strokeStyle = \"#000000\";\n\n    this._resize_canvas = function(width, height) {\n        // Keep the size of the canvas, canvas container, and rubber band\n        // canvas in synch.\n        canvas_div.css('width', width)\n        canvas_div.css('height', height)\n\n        canvas.attr('width', width * mpl.ratio);\n        canvas.attr('height', height * mpl.ratio);\n        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n\n        rubberband.attr('width', width);\n        rubberband.attr('height', height);\n    }\n\n    // Set the figure to an initial 600x600px, this will subsequently be updated\n    // upon first draw.\n    this._resize_canvas(600, 600);\n\n    // Disable right mouse context menu.\n    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n        return false;\n    });\n\n    function set_focus () {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n}\n\nmpl.figure.prototype._init_toolbar = function() {\n    var fig = this;\n\n    var nav_element = $('<div/>');\n    nav_element.attr('style', 'width: 100%');\n    this.root.append(nav_element);\n\n    // Define a callback function for later on.\n    function toolbar_event(event) {\n        return fig.toolbar_button_onclick(event['data']);\n    }\n    function toolbar_mouse_event(event) {\n        return fig.toolbar_button_onmouseover(event['data']);\n    }\n\n    for(var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            // put a spacer in here.\n            continue;\n        }\n        var button = $('<button/>');\n        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n                        'ui-button-icon-only');\n        button.attr('role', 'button');\n        button.attr('aria-disabled', 'false');\n        button.click(method_name, toolbar_event);\n        button.mouseover(tooltip, toolbar_mouse_event);\n\n        var icon_img = $('<span/>');\n        icon_img.addClass('ui-button-icon-primary ui-icon');\n        icon_img.addClass(image);\n        icon_img.addClass('ui-corner-all');\n\n        var tooltip_span = $('<span/>');\n        tooltip_span.addClass('ui-button-text');\n        tooltip_span.html(tooltip);\n\n        button.append(icon_img);\n        button.append(tooltip_span);\n\n        nav_element.append(button);\n    }\n\n    var fmt_picker_span = $('<span/>');\n\n    var fmt_picker = $('<select/>');\n    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n    fmt_picker_span.append(fmt_picker);\n    nav_element.append(fmt_picker_span);\n    this.format_dropdown = fmt_picker[0];\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = $(\n            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n        fmt_picker.append(option);\n    }\n\n    // Add hover states to the ui-buttons\n    $( \".ui-button\" ).hover(\n        function() { $(this).addClass(\"ui-state-hover\");},\n        function() { $(this).removeClass(\"ui-state-hover\");}\n    );\n\n    var status_bar = $('<span class=\"mpl-message\"/>');\n    nav_element.append(status_bar);\n    this.message = status_bar[0];\n}\n\nmpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n}\n\nmpl.figure.prototype.send_message = function(type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n}\n\nmpl.figure.prototype.send_draw_message = function() {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n    }\n}\n\n\nmpl.figure.prototype.handle_save = function(fig, msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n}\n\n\nmpl.figure.prototype.handle_resize = function(fig, msg) {\n    var size = msg['size'];\n    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1]);\n        fig.send_message(\"refresh\", {});\n    };\n}\n\nmpl.figure.prototype.handle_rubberband = function(fig, msg) {\n    var x0 = msg['x0'] / mpl.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n    var x1 = msg['x1'] / mpl.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0, 0, fig.canvas.width, fig.canvas.height);\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n}\n\nmpl.figure.prototype.handle_figure_label = function(fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n}\n\nmpl.figure.prototype.handle_cursor = function(fig, msg) {\n    var cursor = msg['cursor'];\n    switch(cursor)\n    {\n    case 0:\n        cursor = 'pointer';\n        break;\n    case 1:\n        cursor = 'default';\n        break;\n    case 2:\n        cursor = 'crosshair';\n        break;\n    case 3:\n        cursor = 'move';\n        break;\n    }\n    fig.rubberband_canvas.style.cursor = cursor;\n}\n\nmpl.figure.prototype.handle_message = function(fig, msg) {\n    fig.message.textContent = msg['message'];\n}\n\nmpl.figure.prototype.handle_draw = function(fig, msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n}\n\nmpl.figure.prototype.handle_image_mode = function(fig, msg) {\n    fig.image_mode = msg['mode'];\n}\n\nmpl.figure.prototype.updated_canvas_event = function() {\n    // Called whenever the canvas gets updated.\n    this.send_message(\"ack\", {});\n}\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function(fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            /* FIXME: We get \"Resource interpreted as Image but\n             * transferred with MIME type text/plain:\" errors on\n             * Chrome.  But how to set the MIME type?  It doesn't seem\n             * to be part of the websocket stream */\n            evt.data.type = \"image/png\";\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src);\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                evt.data);\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig[\"handle_\" + msg_type];\n        } catch (e) {\n            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n            }\n        }\n    };\n}\n\n// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\nmpl.findpos = function(e) {\n    //this section is from http://www.quirksmode.org/js/events_properties.html\n    var targ;\n    if (!e)\n        e = window.event;\n    if (e.target)\n        targ = e.target;\n    else if (e.srcElement)\n        targ = e.srcElement;\n    if (targ.nodeType == 3) // defeat Safari bug\n        targ = targ.parentNode;\n\n    // jQuery normalizes the pageX and pageY\n    // pageX,Y are the mouse positions relative to the document\n    // offset() returns the position of the element relative to the document\n    var x = e.pageX - $(targ).offset().left;\n    var y = e.pageY - $(targ).offset().top;\n\n    return {\"x\": x, \"y\": y};\n};\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * http://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys (original) {\n  return Object.keys(original).reduce(function (obj, key) {\n    if (typeof original[key] !== 'object')\n        obj[key] = original[key]\n    return obj;\n  }, {});\n}\n\nmpl.figure.prototype.mouse_event = function(event, name) {\n    var canvas_pos = mpl.findpos(event)\n\n    if (name === 'button_press')\n    {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    var x = canvas_pos.x * mpl.ratio;\n    var y = canvas_pos.y * mpl.ratio;\n\n    this.send_message(name, {x: x, y: y, button: event.button,\n                             step: event.step,\n                             guiEvent: simpleKeys(event)});\n\n    /* This prevents the web browser from automatically changing to\n     * the text insertion cursor when the button is pressed.  We want\n     * to control all of the cursor setting manually through the\n     * 'cursor' event from matplotlib */\n    event.preventDefault();\n    return false;\n}\n\nmpl.figure.prototype._key_event_extra = function(event, name) {\n    // Handle any extra behaviour associated with a key event\n}\n\nmpl.figure.prototype.key_event = function(event, name) {\n\n    // Prevent repeat events\n    if (name == 'key_press')\n    {\n        if (event.which === this._key)\n            return;\n        else\n            this._key = event.which;\n    }\n    if (name == 'key_release')\n        this._key = null;\n\n    var value = '';\n    if (event.ctrlKey && event.which != 17)\n        value += \"ctrl+\";\n    if (event.altKey && event.which != 18)\n        value += \"alt+\";\n    if (event.shiftKey && event.which != 16)\n        value += \"shift+\";\n\n    value += 'k';\n    value += event.which.toString();\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, {key: value,\n                             guiEvent: simpleKeys(event)});\n    return false;\n}\n\nmpl.figure.prototype.toolbar_button_onclick = function(name) {\n    if (name == 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message(\"toolbar_button\", {name: name});\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n    this.message.textContent = tooltip;\n};\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n\nmpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.close = function() {\n        comm.close()\n    };\n    ws.send = function(m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function(msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(msg['content']['data'])\n    });\n    return ws;\n}\n\nmpl.mpl_figure_comm = function(comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = $(\"#\" + id);\n    var ws_proxy = comm_websocket_adapter(comm)\n\n    function ondownload(figure, format) {\n        window.open(figure.imageObj.src);\n    }\n\n    var fig = new mpl.figure(id, ws_proxy,\n                           ondownload,\n                           element.get(0));\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element.get(0);\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error(\"Failed to find cell for figure\", id, fig);\n        return;\n    }\n\n    var output_index = fig.cell_info[2]\n    var cell = fig.cell_info[0];\n\n};\n\nmpl.figure.prototype.handle_close = function(fig, msg) {\n    var width = fig.canvas.width/mpl.ratio\n    fig.root.unbind('remove')\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable()\n    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n    fig.close_ws(fig, msg);\n}\n\nmpl.figure.prototype.close_ws = function(fig, msg){\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n}\n\nmpl.figure.prototype.push_to_output = function(remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width/mpl.ratio\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n}\n\nmpl.figure.prototype.updated_canvas_event = function() {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message(\"ack\", {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () { fig.push_to_output() }, 1000);\n}\n\nmpl.figure.prototype._init_toolbar = function() {\n    var fig = this;\n\n    var nav_element = $('<div/>');\n    nav_element.attr('style', 'width: 100%');\n    this.root.append(nav_element);\n\n    // Define a callback function for later on.\n    function toolbar_event(event) {\n        return fig.toolbar_button_onclick(event['data']);\n    }\n    function toolbar_mouse_event(event) {\n        return fig.toolbar_button_onmouseover(event['data']);\n    }\n\n    for(var toolbar_ind in mpl.toolbar_items){\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) { continue; };\n\n        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n        button.click(method_name, toolbar_event);\n        button.mouseover(tooltip, toolbar_mouse_event);\n        nav_element.append(button);\n    }\n\n    // Add the status bar.\n    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n    nav_element.append(status_bar);\n    this.message = status_bar[0];\n\n    // Add the close button to the window.\n    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n    button.click(function (evt) { fig.handle_close(fig, {}); } );\n    button.mouseover('Stop Interaction', toolbar_mouse_event);\n    buttongrp.append(button);\n    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n    titlebar.prepend(buttongrp);\n}\n\nmpl.figure.prototype._root_extra_style = function(el){\n    var fig = this\n    el.on(\"remove\", function(){\n\tfig.close_ws(fig, {});\n    });\n}\n\nmpl.figure.prototype._canvas_extra_style = function(el){\n    // this is important to make the div 'focusable\n    el.attr('tabindex', 0)\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    }\n    else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n\n}\n\nmpl.figure.prototype._key_event_extra = function(event, name) {\n    var manager = IPython.notebook.keyboard_manager;\n    if (!manager)\n        manager = IPython.keyboard_manager;\n\n    // Check for shift+enter\n    if (event.shiftKey && event.which == 13) {\n        this.canvas_div.blur();\n        event.shiftKey = false;\n        // Send a \"J\" for go to next cell\n        event.which = 74;\n        event.keyCode = 74;\n        manager.command_mode();\n        manager.handle_keydown(event);\n    }\n}\n\nmpl.figure.prototype.handle_save = function(fig, msg) {\n    fig.ondownload(fig, null);\n}\n\n\nmpl.find_output_cell = function(html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i=0; i<ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code'){\n            for (var j=0; j<cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] == html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n}\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel != null) {\n    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"680\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if base_model == 'efficientnetb4':\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(6.8, 2.75))\n",
    "\n",
    "    alpha = 0.4\n",
    "    props = dict(boxstyle='round', facecolor='white', alpha=0.75)\n",
    "\n",
    "    err_uncal = torch.stack(err_uncal_list).mean(dim=0).cpu()\n",
    "    err_uncal_var = torch.stack(err_uncal_list).std(dim=0).cpu()\n",
    "    uncert_uncal = torch.stack(uncert_uncal_list).mean(dim=0).cpu()\n",
    "    ax[0].plot([0, 0.02], [0, 0.02], 'k--')\n",
    "    ax[0].plot(uncert_uncal, err_uncal, marker='.', label='uncal')\n",
    "    ax[0].fill_between(uncert_uncal, err_uncal-err_uncal_var, err_uncal+err_uncal_var, alpha=alpha)\n",
    "    ax[0].set_ylabel(r'observed uncertainty', fontsize=11)\n",
    "    ax[0].set_xlabel(r'expected uncertainty', fontsize=11)\n",
    "    ax[0].set_xlim([-0.0002, 0.0022])\n",
    "    ax[0].set_ylim([-0.0002, 0.0022])\n",
    "    ax[0].set_xticks([0, 0.001, 0.002])\n",
    "    ax[0].set_yticks([0, 0.001, 0.002])\n",
    "    ax[0].set_aspect(1)\n",
    "    ax[0].set_title(r'uncalibrated')\n",
    "    textstr0 = r'UCE\\,=\\,{:.2f}'.format((torch.stack(uce_uncal_list)*100).mean().item())\n",
    "    ax[0].text(0.925, 0.075, textstr0, transform=ax[0].transAxes, fontsize=10,\n",
    "                    verticalalignment='bottom',\n",
    "                    horizontalalignment='right',\n",
    "                    bbox=props\n",
    "                    )\n",
    "\n",
    "    err_aux = torch.stack(err_aux_list).mean(dim=0).cpu()\n",
    "    err_aux_var = torch.stack(err_aux_list).std(dim=0).cpu()\n",
    "    uncert_aux = torch.stack(uncert_aux_list).mean(dim=0).cpu()\n",
    "    ax[1].plot([0, 0.02], [0, 0.02], 'k--')\n",
    "    ax[1].plot(uncert_aux, err_aux, marker='.', label='uncal')\n",
    "    ax[1].fill_between(uncert_aux, err_aux-err_aux_var, err_aux+err_aux_var, alpha=alpha)\n",
    "    ax[1].set_ylabel(r'observed uncertainty', fontsize=11)\n",
    "    ax[1].set_xlabel(r'expected uncertainty', fontsize=11)\n",
    "    ax[1].set_xlim([0.0008, 0.0022])\n",
    "    ax[1].set_ylim([0.0008, 0.0022])\n",
    "    ax[1].set_xticks([0.001, 0.002])\n",
    "    ax[1].set_yticks([0.001, 0.002])\n",
    "    ax[1].set_aspect(1)\n",
    "    ax[1].set_title(r'aux scaling')\n",
    "    textstr1 = r'UCE\\,=\\,{:.2f}'.format((torch.stack(uce_aux_list)*100).mean().item())\n",
    "    ax[1].text(0.925, 0.075, textstr1, transform=ax[1].transAxes, fontsize=10,\n",
    "                    verticalalignment='bottom',\n",
    "                    horizontalalignment='right',\n",
    "                    bbox=props\n",
    "                    )\n",
    "\n",
    "    err_s = torch.stack(err_s_list).mean(dim=0).cpu()\n",
    "    err_s_var = torch.stack(err_s_list).std(dim=0).cpu()\n",
    "    uncert_s = torch.stack(uncert_s_list).mean(dim=0).cpu()\n",
    "    ax[2].plot([0, 0.02], [0, 0.02], 'k--')\n",
    "    ax[2].plot(uncert_s, err_s, marker='.', label='uncal')\n",
    "    ax[2].fill_between(uncert_s, err_s-err_s_var, err_s+err_s_var, alpha=alpha)\n",
    "    ax[2].set_ylabel(r'observed uncertainty', fontsize=11)\n",
    "    ax[2].set_xlabel(r'expected uncertainty', fontsize=11)\n",
    "    ax[2].set_xlim([0.0008, 0.0022])\n",
    "    ax[2].set_ylim([0.0008, 0.0022])\n",
    "    ax[2].set_xticks([0.001, 0.002])\n",
    "    ax[2].set_yticks([0.001, 0.002])\n",
    "    ax[2].set_aspect(1)\n",
    "    ax[2].set_title(r'$ \\sigma $ scaling')\n",
    "    textstr2 = r'UCE\\,=\\,{:.2f}'.format((torch.stack(uce_s_list)*100).mean().item())\n",
    "    ax[2].text(0.925, 0.075, textstr2, transform=ax[2].transAxes, fontsize=10,\n",
    "                    verticalalignment='bottom',\n",
    "                    horizontalalignment='right',\n",
    "                    bbox=props\n",
    "                    )\n",
    "\n",
    "    ax[0].annotate(r'OCT/EfficientNet-B4', xy=(0, 0.5), xytext=(-ax[0].yaxis.labelpad - 5, 0),\n",
    "                   xycoords=ax[0].yaxis.label, textcoords='offset points',\n",
    "                   size='large', ha='right', va='center', fontsize=10, rotation=90)\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n",
    "    fig.savefig(f\"results_levi_oct_{base_model}.pdf\", bbox_inches='tight', pad_inches=0.01)\n",
    "    save_log(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"uce_uncal_levi_oct_{base_model}\", np.array([i.detach().numpy() for i in uce_uncal_list]))\n",
    "np.save(f\"err_uncal_levi_oct_{base_model}\", np.array([i.detach().numpy() for i in err_uncal_list]))\n",
    "np.save(f\"uncert_uncal_levi_oct_{base_model}\", np.array([i.detach().numpy() for i in uncert_uncal_list]))\n",
    "\n",
    "np.save(f\"uce_s_levi_oct_{base_model}\", np.array([i.detach().numpy() for i in uce_s_list]))\n",
    "np.save(f\"err_s_levi_oct_{base_model}\", np.array([i.detach().numpy() for i in err_s_list]))\n",
    "np.save(f\"uncert_s_levi_oct_{base_model}\", np.array([i.detach().numpy() for i in uncert_s_list]))\n",
    "\n",
    "np.save(f\"uce_aux_levi_oct_{base_model}\", np.array([i.detach().numpy() for i in uce_aux_list]))\n",
    "np.save(f\"err_aux_levi_oct_{base_model}\", np.array([i.detach().numpy() for i in err_aux_list]))\n",
    "np.save(f\"uncert_aux_levi_oct_{base_model}\", np.array([i.detach().numpy() for i in uncert_aux_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "f846d00f0fb6a0b702eb39eb9cf35dbb748c60836e8617603a8317679456f00f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
